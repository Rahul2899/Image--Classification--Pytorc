{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNFajmsLlTHZJGE4FbGT/g3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rahul2899/Image--Classification--Pytorch/blob/main/Image_classification_using_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "iOno0XANN83O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "rsyLssWkN-dM",
        "outputId": "a935074a-da5b-4337-f196-25c7af15ca02"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor , Lambda , Compose\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "dyxhQm0xOIJh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Downloading data\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data =  datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train = False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "wKiSep7FQhl5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 20\n",
        "\n",
        "train_dataloader = DataLoader(training_data,batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data,batch_size=batch_size)"
      ],
      "metadata": {
        "id": "BqwQxNOhRwlc"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X,y in test_dataloader:\n",
        "  print(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zl_eTGwZUmLk",
        "outputId": "b46c71c5-6e81-4228-ac45-24caab57eb2b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([6, 4, 4, 8, 6, 5, 4, 9, 0, 2, 8, 4, 8, 6, 3, 6, 1, 4, 3, 3, 8, 4, 9, 9,\n",
            "        0, 7, 9, 5, 3, 1, 7, 2, 8, 4, 9, 6, 1, 6, 0, 5, 8, 1, 9, 3, 0, 8, 3, 8,\n",
            "        4, 2, 5, 6, 9, 0, 1, 4, 0, 7, 9, 0, 1, 3, 9, 5])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([1, 4, 1, 1, 4, 8, 3, 9, 5, 4, 4, 3, 7, 7, 7, 2, 3, 9, 1, 9, 4, 4, 0, 7,\n",
            "        6, 6, 7, 9, 0, 6, 4, 9, 0, 4, 0, 2, 7, 9, 6, 1, 1, 2, 0, 8, 8, 7, 4, 2,\n",
            "        7, 5, 7, 6, 1, 8, 1, 4, 9, 8, 9, 0, 1, 0, 6, 0])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([3, 0, 6, 4, 1, 9, 7, 1, 2, 2, 5, 3, 4, 1, 7, 4, 7, 0, 2, 8, 8, 1, 4, 9,\n",
            "        9, 6, 3, 4, 9, 3, 9, 8, 5, 3, 8, 4, 7, 1, 4, 1, 9, 6, 8, 3, 2, 4, 8, 1,\n",
            "        1, 5, 8, 6, 1, 6, 2, 5, 0, 9, 5, 3, 5, 0, 6, 5])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([4, 8, 3, 8, 0, 2, 9, 9, 1, 5, 3, 2, 6, 5, 3, 0, 3, 0, 7, 4, 0, 2, 1, 9,\n",
            "        5, 1, 7, 5, 5, 5, 9, 4, 8, 4, 6, 6, 4, 6, 4, 1, 1, 2, 2, 8, 4, 9, 0, 5,\n",
            "        8, 1, 0, 8, 3, 2, 4, 8, 3, 0, 9, 3, 4, 9, 7, 2])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([6, 2, 2, 8, 9, 6, 1, 4, 7, 7, 9, 7, 3, 2, 9, 2, 7, 3, 0, 2, 6, 7, 2, 3,\n",
            "        3, 1, 9, 5, 8, 2, 3, 5, 0, 0, 4, 5, 8, 3, 5, 0, 7, 7, 6, 0, 9, 5, 1, 4,\n",
            "        4, 5, 3, 0, 6, 1, 4, 6, 5, 4, 8, 5, 7, 3, 0, 8])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([3, 5, 2, 4, 9, 8, 5, 9, 8, 1, 9, 5, 0, 1, 5, 3, 3, 3, 3, 4, 4, 3, 6, 7,\n",
            "        8, 0, 9, 6, 3, 0, 4, 2, 7, 3, 5, 7, 3, 7, 8, 4, 6, 2, 2, 3, 1, 0, 7, 5,\n",
            "        6, 6, 4, 1, 1, 4, 7, 2, 3, 5, 5, 0, 4, 4, 4, 8])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([9, 9, 2, 6, 9, 8, 3, 5, 3, 1, 4, 5, 0, 1, 8, 5, 8, 6, 0, 7, 8, 9, 2, 2,\n",
            "        6, 3, 2, 2, 2, 8, 9, 1, 9, 7, 4, 5, 6, 3, 2, 4, 5, 6, 6, 5, 8, 6, 2, 2,\n",
            "        9, 4, 9, 8, 3, 0, 2, 7, 7, 5, 9, 7, 7, 3, 8, 7])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([5, 9, 9, 8, 2, 1, 0, 8, 0, 2, 6, 7, 9, 2, 2, 5, 4, 3, 2, 1, 1, 9, 6, 5,\n",
            "        5, 4, 9, 8, 9, 6, 5, 4, 6, 0, 5, 7, 8, 4, 8, 8, 7, 4, 9, 4, 9, 6, 9, 7,\n",
            "        3, 9, 9, 3, 6, 0, 2, 8, 7, 9, 4, 0, 0, 4, 1, 0])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([3, 8, 4, 8, 4, 4, 3, 3, 5, 7, 7, 8, 5, 6, 3, 2, 1, 8, 3, 8, 5, 4, 2, 3,\n",
            "        0, 8, 3, 3, 2, 9, 0, 9, 9, 0, 1, 8, 3, 0, 3, 8, 6, 8, 5, 1, 3, 0, 1, 9,\n",
            "        3, 5, 0, 6, 2, 3, 1, 5, 3, 2, 8, 5, 7, 8, 0, 1])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([1, 0, 6, 4, 5, 9, 0, 7, 2, 3, 6, 4, 6, 3, 6, 9, 4, 9, 0, 8, 3, 5, 6, 2,\n",
            "        0, 1, 3, 9, 4, 2, 5, 0, 5, 3, 2, 5, 0, 0, 0, 0, 0, 9, 1, 3, 4, 3, 5, 5,\n",
            "        6, 6, 1, 4, 9, 7, 4, 4, 7, 5, 7, 1, 6, 8, 7, 9])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([5, 7, 0, 2, 9, 2, 5, 0, 7, 6, 4, 5, 2, 9, 4, 3, 2, 5, 9, 2, 5, 9, 7, 3,\n",
            "        8, 3, 5, 6, 5, 3, 0, 7, 6, 9, 5, 1, 3, 6, 9, 3, 6, 2, 5, 3, 4, 9, 9, 1,\n",
            "        2, 2, 2, 4, 6, 8, 7, 9, 9, 4, 8, 8, 9, 0, 7, 0])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([4, 3, 8, 6, 4, 2, 0, 1, 4, 0, 2, 1, 5, 4, 6, 6, 0, 3, 4, 5, 6, 8, 7, 6,\n",
            "        0, 3, 1, 8, 8, 8, 9, 9, 5, 5, 8, 6, 5, 4, 4, 2, 5, 6, 9, 2, 9, 1, 0, 4,\n",
            "        6, 6, 9, 8, 0, 4, 9, 1, 9, 4, 7, 3, 5, 4, 3, 4])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([6, 1, 6, 2, 4, 3, 7, 8, 4, 5, 5, 9, 0, 6, 3, 4, 5, 5, 5, 7, 3, 1, 3, 3,\n",
            "        7, 0, 7, 7, 6, 8, 3, 5, 5, 8, 1, 9, 4, 0, 4, 2, 1, 6, 0, 1, 6, 5, 0, 8,\n",
            "        1, 1, 7, 5, 2, 5, 9, 0, 8, 3, 4, 4, 2, 7, 0, 7])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([6, 6, 2, 3, 7, 1, 6, 4, 3, 3, 0, 0, 6, 4, 8, 7, 0, 3, 6, 4, 7, 3, 3, 6,\n",
            "        0, 2, 4, 4, 1, 8, 1, 9, 1, 2, 6, 4, 2, 5, 3, 3, 5, 3, 5, 8, 3, 9, 7, 3,\n",
            "        0, 0, 1, 0, 1, 0, 7, 7, 4, 8, 9, 0, 1, 5, 4, 9])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([4, 7, 9, 9, 7, 0, 1, 0, 9, 9, 5, 1, 7, 2, 9, 1, 5, 6, 8, 1, 7, 3, 0, 8,\n",
            "        4, 7, 0, 8, 9, 8, 8, 4, 5, 6, 4, 5, 9, 0, 0, 5, 3, 7, 7, 4, 4, 7, 4, 5,\n",
            "        8, 3, 7, 2, 7, 3, 8, 8, 8, 7, 8, 6, 0, 5, 7, 9])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([8, 5, 6, 0, 6, 4, 4, 2, 8, 9, 9, 1, 9, 5, 8, 4, 4, 8, 4, 8, 7, 4, 8, 3,\n",
            "        0, 7, 8, 8, 3, 9, 9, 5, 9, 2, 6, 9, 7, 5, 7, 4, 9, 9, 2, 3, 9, 5, 3, 5,\n",
            "        6, 1, 2, 9, 1, 4, 8, 5, 1, 7, 9, 0, 3, 3, 6, 9])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([0, 4, 6, 0, 0, 2, 9, 7, 1, 9, 8, 5, 6, 8, 5, 9, 5, 2, 4, 2, 5, 2, 2, 5,\n",
            "        4, 2, 7, 1, 2, 6, 8, 2, 5, 6, 2, 6, 9, 5, 5, 1, 5, 2, 4, 4, 2, 4, 1, 9,\n",
            "        3, 7, 2, 7, 4, 2, 9, 7, 4, 6, 6, 1, 7, 1, 4, 7])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([6, 1, 7, 3, 0, 3, 6, 4, 9, 0, 4, 1, 7, 9, 0, 2, 7, 6, 6, 7, 1, 9, 5, 2,\n",
            "        9, 8, 6, 4, 0, 1, 3, 2, 2, 8, 1, 0, 8, 1, 8, 1, 0, 1, 4, 7, 3, 7, 7, 3,\n",
            "        3, 9, 9, 0, 8, 2, 5, 8, 9, 5, 3, 5, 4, 1, 6, 9])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([2, 6, 2, 6, 1, 8, 1, 3, 3, 0, 2, 1, 7, 0, 5, 4, 5, 3, 6, 2, 1, 6, 0, 7,\n",
            "        3, 6, 6, 3, 6, 1, 5, 2, 9, 0, 8, 0, 4, 4, 0, 1, 7, 5, 3, 3, 3, 2, 0, 3,\n",
            "        5, 2, 6, 2, 5, 1, 4, 6, 2, 1, 9, 3, 4, 6, 9, 5])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([8, 0, 6, 3, 6, 0, 8, 1, 2, 3, 3, 1, 5, 5, 3, 2, 6, 7, 1, 3, 2, 3, 6, 1,\n",
            "        2, 2, 8, 0, 8, 4, 7, 0, 3, 1, 3, 8, 3, 4, 1, 2, 0, 3, 6, 7, 7, 8, 3, 6,\n",
            "        9, 5, 6, 6, 9, 5, 4, 3, 8, 5, 3, 8, 3, 7, 9, 6])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([2, 5, 1, 0, 5, 2, 3, 5, 7, 9, 6, 0, 7, 1, 2, 0, 8, 2, 2, 2, 7, 8, 0, 2,\n",
            "        4, 4, 9, 7, 3, 2, 5, 4, 5, 1, 9, 5, 0, 5, 2, 4, 1, 7, 9, 0, 3, 3, 4, 9,\n",
            "        1, 0, 1, 9, 5, 6, 8, 2, 2, 1, 4, 0, 6, 7, 9, 0])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([1, 1, 4, 3, 6, 9, 8, 1, 3, 7, 3, 9, 9, 5, 4, 2, 3, 6, 8, 8, 5, 5, 1, 8,\n",
            "        8, 5, 7, 9, 9, 3, 4, 4, 2, 7, 9, 6, 6, 7, 5, 4, 7, 6, 1, 4, 2, 2, 6, 9,\n",
            "        0, 0, 5, 1, 1, 7, 8, 3, 6, 6, 2, 0, 2, 4, 9, 5])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([2, 4, 6, 4, 6, 1, 5, 2, 7, 8, 6, 7, 7, 0, 8, 4, 3, 6, 9, 1, 2, 1, 7, 4,\n",
            "        3, 4, 9, 9, 2, 2, 4, 3, 0, 5, 7, 5, 2, 7, 8, 9, 9, 2, 7, 8, 7, 7, 5, 8,\n",
            "        7, 6, 6, 9, 0, 1, 8, 7, 5, 4, 5, 3, 7, 6, 6, 5])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([5, 6, 9, 9, 1, 9, 5, 9, 4, 4, 1, 5, 8, 3, 5, 1, 8, 6, 5, 0, 2, 3, 7, 1,\n",
            "        1, 1, 8, 7, 5, 6, 3, 4, 7, 0, 0, 5, 3, 4, 8, 6, 5, 2, 7, 3, 2, 3, 2, 7,\n",
            "        8, 0, 9, 0, 9, 5, 8, 0, 7, 3, 9, 0, 9, 7, 3, 0])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([6, 5, 7, 8, 2, 3, 1, 9, 0, 2, 9, 1, 3, 4, 0, 3, 0, 6, 2, 3, 8, 6, 2, 9,\n",
            "        5, 6, 1, 8, 2, 4, 1, 6, 2, 9, 4, 6, 7, 9, 6, 3, 5, 4, 5, 9, 8, 5, 3, 0,\n",
            "        1, 2, 6, 4, 1, 9, 4, 4, 6, 5, 5, 4, 3, 2, 0, 1])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([4, 9, 9, 7, 6, 1, 2, 6, 6, 2, 6, 2, 5, 9, 4, 8, 2, 6, 1, 5, 9, 6, 1, 8,\n",
            "        9, 3, 1, 7, 1, 1, 1, 9, 1, 3, 8, 9, 9, 1, 9, 6, 0, 5, 8, 5, 5, 5, 3, 8,\n",
            "        9, 0, 7, 8, 2, 9, 2, 0, 1, 5, 0, 7, 8, 0, 0, 9])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([1, 1, 8, 2, 8, 7, 2, 0, 7, 2, 0, 0, 5, 1, 0, 8, 6, 3, 7, 2, 1, 9, 7, 4,\n",
            "        1, 3, 9, 2, 4, 0, 3, 7, 5, 1, 1, 9, 5, 1, 5, 4, 6, 6, 1, 5, 2, 1, 6, 6,\n",
            "        5, 7, 9, 4, 3, 4, 1, 7, 9, 0, 5, 7, 3, 3, 8, 4])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([1, 8, 2, 5, 4, 4, 8, 9, 2, 9, 3, 2, 6, 1, 1, 6, 6, 1, 4, 9, 8, 5, 9, 1,\n",
            "        5, 6, 9, 3, 2, 1, 7, 4, 9, 8, 8, 9, 5, 5, 3, 8, 2, 0, 3, 6, 1, 1, 9, 0,\n",
            "        9, 7, 5, 3, 2, 9, 5, 5, 4, 2, 9, 9, 3, 0, 6, 3])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([1, 7, 4, 9, 2, 8, 5, 8, 6, 0, 1, 3, 2, 2, 3, 6, 6, 0, 2, 8, 3, 2, 8, 6,\n",
            "        1, 8, 4, 5, 4, 2, 3, 9, 0, 4, 4, 2, 5, 4, 2, 7, 6, 7, 3, 3, 6, 9, 6, 8,\n",
            "        5, 6, 6, 3, 6, 7, 2, 5, 3, 1, 1, 9, 7, 5, 4, 2])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([1, 6, 4, 5, 9, 2, 5, 5, 3, 3, 0, 9, 2, 2, 2, 3, 2, 4, 9, 2, 3, 0, 4, 2,\n",
            "        0, 4, 1, 3, 7, 2, 4, 2, 2, 3, 2, 3, 0, 8, 3, 5, 1, 2, 8, 8, 2, 1, 2, 1,\n",
            "        1, 9, 6, 5, 9, 6, 8, 0, 3, 6, 3, 1, 3, 7, 5, 6])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([1, 1, 2, 0, 5, 5, 0, 1, 6, 5, 2, 8, 9, 7, 9, 1, 1, 3, 3, 5, 6, 7, 5, 9,\n",
            "        4, 9, 3, 6, 6, 0, 8, 5, 6, 5, 9, 8, 3, 8, 1, 3, 1, 3, 5, 6, 5, 4, 4, 9,\n",
            "        6, 7, 1, 4, 8, 3, 7, 7, 6, 7, 9, 4, 7, 7, 0, 1])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([4, 1, 4, 8, 2, 4, 7, 6, 7, 1, 8, 7, 5, 1, 3, 1, 0, 3, 4, 5, 4, 8, 6, 3,\n",
            "        4, 9, 3, 1, 5, 3, 0, 7, 0, 3, 4, 5, 1, 6, 6, 2, 8, 8, 9, 8, 6, 7, 2, 4,\n",
            "        2, 5, 1, 9, 6, 3, 8, 7, 1, 8, 1, 2, 0, 9, 2, 4])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([4, 4, 6, 1, 3, 5, 2, 9, 7, 5, 2, 7, 5, 5, 4, 4, 8, 0, 7, 0, 8, 0, 2, 1,\n",
            "        9, 7, 7, 3, 8, 0, 3, 0, 9, 8, 5, 6, 4, 8, 1, 5, 5, 7, 0, 1, 6, 1, 3, 2,\n",
            "        6, 4, 6, 1, 7, 6, 2, 2, 6, 1, 8, 2, 2, 6, 3, 0])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([8, 8, 4, 6, 2, 0, 7, 0, 8, 9, 1, 6, 6, 7, 0, 8, 1, 8, 2, 4, 6, 7, 5, 7,\n",
            "        9, 9, 3, 9, 4, 4, 6, 4, 1, 4, 8, 4, 2, 8, 6, 2, 2, 9, 1, 8, 0, 6, 2, 6,\n",
            "        0, 3, 6, 6, 1, 3, 6, 3, 3, 1, 7, 8, 1, 0, 7, 6])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([5, 0, 8, 2, 6, 5, 8, 7, 8, 4, 5, 9, 5, 5, 1, 2, 4, 7, 2, 9, 7, 8, 3, 7,\n",
            "        4, 6, 3, 8, 8, 4, 5, 1, 8, 2, 6, 2, 2, 9, 8, 9, 0, 2, 5, 9, 3, 5, 9, 8,\n",
            "        6, 3, 9, 5, 9, 3, 0, 8, 6, 0, 6, 3, 5, 8, 0, 6])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([1, 8, 6, 9, 0, 0, 7, 6, 6, 8, 7, 6, 8, 8, 2, 0, 3, 6, 7, 1, 3, 7, 4, 0,\n",
            "        7, 1, 6, 5, 2, 0, 7, 9, 0, 3, 8, 2, 1, 1, 8, 8, 3, 5, 7, 5, 6, 7, 4, 3,\n",
            "        9, 3, 8, 9, 0, 4, 0, 4, 5, 7, 0, 4, 3, 9, 5, 7])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([2, 2, 5, 8, 3, 1, 3, 5, 4, 9, 4, 3, 9, 9, 2, 0, 8, 0, 9, 1, 9, 9, 0, 7,\n",
            "        1, 4, 5, 0, 3, 8, 7, 4, 5, 5, 9, 3, 2, 0, 0, 9, 0, 5, 0, 1, 3, 7, 9, 1,\n",
            "        5, 9, 6, 0, 9, 7, 2, 9, 2, 1, 2, 7, 5, 1, 0, 7])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([3, 4, 7, 6, 4, 6, 8, 5, 7, 9, 5, 7, 3, 6, 3, 9, 3, 4, 1, 5, 6, 9, 7, 4,\n",
            "        0, 6, 5, 8, 0, 7, 7, 3, 2, 0, 4, 8, 2, 0, 6, 9, 8, 9, 2, 5, 0, 4, 0, 2,\n",
            "        6, 3, 1, 8, 7, 4, 1, 9, 1, 2, 8, 5, 6, 3, 0, 0])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([2, 6, 0, 7, 2, 1, 8, 4, 8, 7, 9, 4, 1, 6, 5, 7, 7, 3, 2, 5, 7, 3, 6, 7,\n",
            "        3, 2, 2, 9, 6, 7, 3, 9, 1, 2, 1, 9, 7, 2, 3, 3, 8, 1, 8, 3, 5, 0, 5, 3,\n",
            "        8, 5, 7, 4, 9, 0, 6, 8, 3, 2, 3, 3, 4, 3, 7, 8])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([7, 1, 3, 7, 8, 9, 5, 5, 2, 2, 4, 5, 0, 8, 0, 3, 6, 0, 8, 8, 9, 6, 9, 1,\n",
            "        5, 1, 2, 1, 3, 2, 2, 2, 4, 5, 7, 5, 9, 2, 0, 5, 7, 0, 5, 6, 5, 6, 6, 4,\n",
            "        0, 7, 1, 5, 2, 9, 8, 1, 7, 6, 4, 4, 0, 7, 1, 8])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([5, 7, 8, 5, 5, 1, 8, 5, 9, 7, 7, 6, 5, 2, 2, 1, 2, 4, 4, 1, 6, 3, 9, 1,\n",
            "        8, 2, 3, 7, 6, 9, 5, 7, 4, 3, 9, 5, 6, 2, 2, 7, 3, 9, 3, 0, 5, 9, 0, 9,\n",
            "        6, 6, 6, 5, 9, 1, 6, 5, 2, 0, 2, 3, 1, 1, 1, 7])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([6, 2, 6, 5, 9, 8, 7, 9, 3, 2, 7, 9, 2, 0, 1, 1, 1, 4, 8, 0, 8, 0, 9, 5,\n",
            "        6, 7, 0, 8, 4, 4, 4, 2, 2, 2, 5, 7, 2, 9, 9, 2, 2, 2, 0, 7, 4, 5, 2, 3,\n",
            "        3, 1, 9, 8, 1, 8, 6, 6, 3, 9, 1, 9, 7, 2, 9, 0])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([9, 3, 0, 4, 2, 3, 4, 6, 6, 9, 6, 1, 1, 0, 5, 6, 7, 0, 4, 1, 1, 9, 0, 0,\n",
            "        1, 9, 6, 7, 3, 5, 4, 1, 2, 0, 4, 0, 3, 0, 2, 3, 5, 9, 5, 8, 9, 3, 1, 7,\n",
            "        8, 9, 4, 1, 1, 9, 0, 7, 0, 0, 9, 6, 0, 2, 9, 6])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([8, 5, 5, 9, 3, 3, 5, 7, 1, 2, 3, 3, 5, 6, 6, 4, 1, 1, 9, 1, 6, 6, 6, 2,\n",
            "        2, 6, 6, 6, 3, 5, 0, 3, 0, 5, 1, 1, 8, 2, 5, 3, 5, 1, 4, 4, 3, 1, 2, 7,\n",
            "        9, 6, 3, 8, 5, 6, 6, 9, 1, 5, 7, 7, 4, 2, 2, 7])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([5, 4, 1, 5, 7, 7, 8, 2, 8, 3, 7, 4, 6, 2, 9, 9, 0, 0, 7, 3, 1, 0, 8, 2,\n",
            "        4, 4, 6, 7, 1, 8, 6, 0, 3, 4, 0, 3, 9, 8, 0, 0, 8, 3, 9, 2, 1, 5, 4, 5,\n",
            "        0, 8, 4, 2, 5, 9, 3, 0, 2, 7, 8, 5, 9, 5, 0, 0])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([6, 9, 7, 2, 9, 2, 2, 6, 4, 0, 1, 4, 3, 9, 4, 0, 3, 4, 4, 6, 9, 4, 7, 2,\n",
            "        5, 4, 3, 4, 5, 7, 0, 2, 1, 1, 8, 7, 3, 2, 6, 5, 2, 3, 8, 8, 8, 9, 3, 6,\n",
            "        9, 6, 0, 3, 6, 4, 2, 8, 8, 5, 9, 2, 7, 1, 9, 0])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([3, 3, 3, 2, 3, 9, 9, 5, 3, 2, 4, 2, 4, 6, 4, 5, 3, 4, 9, 8, 5, 8, 3, 4,\n",
            "        1, 4, 8, 9, 2, 6, 2, 3, 5, 0, 3, 5, 2, 5, 3, 9, 1, 2, 9, 8, 9, 3, 8, 8,\n",
            "        5, 5, 8, 4, 4, 0, 8, 3, 6, 4, 9, 6, 1, 0, 5, 1])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([4, 0, 9, 2, 6, 3, 6, 7, 4, 6, 4, 3, 8, 5, 1, 8, 3, 4, 2, 5, 6, 0, 7, 8,\n",
            "        7, 4, 4, 2, 2, 9, 3, 5, 0, 9, 9, 0, 1, 3, 7, 1, 9, 6, 5, 2, 6, 9, 5, 7,\n",
            "        9, 4, 2, 8, 3, 1, 7, 8, 8, 6, 8, 0, 5, 5, 7, 1])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([9, 6, 2, 1, 5, 1, 9, 6, 1, 6, 3, 2, 5, 3, 9, 3, 5, 4, 0, 6, 9, 5, 4, 2,\n",
            "        3, 8, 5, 8, 3, 6, 4, 1, 4, 9, 5, 8, 9, 7, 3, 6, 9, 5, 9, 1, 1, 1, 8, 4,\n",
            "        1, 4, 6, 9, 9, 8, 9, 7, 4, 4, 1, 9, 9, 1, 9, 3])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([2, 3, 7, 1, 1, 3, 6, 8, 3, 4, 3, 3, 8, 3, 7, 1, 0, 3, 8, 4, 7, 9, 8, 0,\n",
            "        3, 0, 4, 5, 7, 6, 7, 3, 5, 0, 2, 3, 3, 3, 0, 6, 4, 4, 4, 4, 4, 9, 9, 0,\n",
            "        7, 4, 0, 2, 2, 1, 9, 5, 9, 9, 0, 5, 8, 6, 7, 3])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([9, 5, 2, 8, 9, 5, 8, 0, 0, 3, 0, 6, 3, 7, 8, 0, 1, 2, 2, 3, 1, 1, 3, 2,\n",
            "        2, 5, 4, 3, 9, 3, 3, 2, 3, 7, 2, 9, 2, 1, 6, 7, 5, 5, 9, 2, 6, 9, 7, 9,\n",
            "        7, 4, 1, 8, 3, 3, 8, 0, 8, 7, 0, 7, 7, 9, 6, 3])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([0, 3, 7, 4, 1, 5, 2, 0, 5, 8, 6, 7, 0, 1, 0, 5, 6, 2, 1, 4, 1, 8, 7, 9,\n",
            "        9, 7, 3, 2, 2, 4, 7, 6, 3, 9, 6, 3, 9, 5, 1, 6, 9, 2, 7, 4, 3, 5, 7, 2,\n",
            "        7, 2, 8, 7, 5, 4, 5, 9, 4, 3, 5, 0, 2, 5, 5, 3])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([1, 9, 3, 7, 1, 0, 3, 4, 4, 2, 5, 7, 2, 1, 1, 7, 7, 7, 0, 1, 6, 8, 5, 2,\n",
            "        5, 3, 7, 8, 7, 7, 0, 8, 5, 6, 6, 5, 5, 6, 7, 7, 9, 7, 1, 0, 0, 8, 0, 4,\n",
            "        0, 6, 4, 5, 5, 0, 5, 3, 6, 4, 5, 0, 7, 1, 8, 7])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([1, 3, 2, 0, 6, 7, 3, 7, 4, 8, 0, 3, 9, 4, 0, 3, 0, 8, 7, 3, 3, 6, 5, 0,\n",
            "        1, 5, 0, 9, 9, 1, 3, 0, 6, 1, 6, 6, 5, 7, 2, 4, 0, 9, 2, 6, 8, 2, 8, 3,\n",
            "        7, 7, 3, 3, 9, 5, 7, 6, 0, 9, 4, 5, 0, 7, 2, 9])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([5, 5, 8, 7, 1, 9, 5, 6, 3, 6, 3, 0, 2, 7, 6, 4, 2, 5, 4, 1, 5, 7, 9, 7,\n",
            "        3, 9, 8, 0, 5, 1, 9, 6, 1, 0, 6, 8, 0, 7, 6, 9, 8, 8, 4, 4, 4, 1, 7, 7,\n",
            "        1, 1, 6, 7, 6, 3, 2, 8, 7, 8, 7, 9, 1, 1, 3, 8])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([9, 5, 9, 1, 0, 6, 3, 4, 4, 4, 7, 1, 3, 0, 1, 5, 4, 4, 9, 2, 4, 2, 2, 6,\n",
            "        7, 7, 6, 7, 1, 4, 0, 8, 3, 3, 5, 6, 0, 8, 3, 0, 2, 0, 1, 8, 4, 0, 2, 9,\n",
            "        5, 4, 4, 5, 2, 1, 6, 4, 6, 5, 8, 0, 7, 3, 2, 6])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([7, 2, 2, 3, 6, 6, 2, 0, 3, 2, 5, 1, 7, 5, 2, 5, 7, 7, 9, 9, 9, 2, 0, 9,\n",
            "        2, 0, 5, 5, 5, 0, 5, 0, 6, 6, 0, 6, 9, 9, 2, 4, 5, 4, 0, 1, 0, 8, 9, 5,\n",
            "        7, 3, 0, 2, 4, 1, 3, 8, 1, 8, 2, 0, 6, 9, 8, 5])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([1, 2, 4, 0, 9, 6, 8, 8, 0, 7, 1, 6, 9, 8, 9, 9, 4, 9, 6, 3, 3, 4, 5, 0,\n",
            "        8, 0, 4, 0, 3, 0, 0, 0, 3, 3, 5, 9, 4, 7, 1, 5, 4, 1, 6, 1, 7, 9, 4, 3,\n",
            "        4, 5, 2, 9, 4, 9, 8, 8, 7, 4, 2, 3, 9, 3, 6, 7])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([0, 2, 7, 0, 6, 1, 0, 5, 7, 0, 5, 9, 4, 3, 2, 8, 5, 8, 1, 9, 6, 7, 6, 7,\n",
            "        3, 6, 4, 5, 1, 8, 8, 8, 7, 4, 6, 5, 1, 5, 9, 6, 0, 9, 5, 8, 5, 7, 3, 9,\n",
            "        8, 3, 4, 6, 5, 7, 5, 1, 1, 5, 4, 1, 8, 5, 8, 2])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([9, 6, 3, 3, 4, 0, 2, 4, 1, 1, 6, 7, 3, 9, 0, 2, 8, 8, 8, 6, 7, 7, 1, 2,\n",
            "        6, 6, 1, 6, 0, 2, 5, 8, 2, 4, 2, 3, 1, 5, 5, 4, 4, 0, 5, 4, 7, 6, 3, 4,\n",
            "        5, 5, 7, 5, 7, 0, 1, 1, 9, 7, 5, 0, 1, 9, 6, 3])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([6, 5, 4, 3, 6, 5, 7, 2, 2, 2, 0, 5, 6, 6, 3, 7, 8, 6, 2, 6, 1, 1, 7, 5,\n",
            "        2, 5, 3, 4, 8, 5, 8, 8, 6, 1, 2, 3, 5, 6, 9, 0, 4, 5, 2, 3, 4, 9, 5, 5,\n",
            "        9, 4, 6, 4, 1, 1, 8, 9, 4, 4, 2, 3, 3, 0, 7, 1])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([8, 8, 5, 0, 0, 7, 7, 1, 0, 1, 4, 1, 9, 0, 4, 1, 1, 0, 7, 3, 7, 3, 9, 0,\n",
            "        1, 8, 9, 0, 0, 6, 0, 9, 1, 6, 1, 2, 7, 8, 0, 5, 6, 8, 2, 5, 5, 1, 5, 9,\n",
            "        1, 8, 5, 3, 1, 6, 6, 0, 7, 3, 5, 4, 8, 0, 7, 1])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([2, 3, 9, 8, 3, 8, 7, 7, 9, 7, 0, 9, 4, 0, 9, 6, 1, 9, 8, 6, 3, 7, 4, 9,\n",
            "        5, 4, 7, 1, 2, 1, 2, 3, 9, 2, 0, 5, 0, 0, 5, 5, 4, 0, 9, 9, 1, 6, 7, 7,\n",
            "        7, 4, 5, 1, 2, 0, 6, 3, 8, 9, 8, 4, 1, 0, 8, 3])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([9, 8, 8, 7, 8, 3, 0, 0, 7, 4, 8, 6, 9, 9, 4, 5, 7, 2, 2, 1, 5, 3, 4, 0,\n",
            "        5, 5, 0, 8, 4, 7, 8, 9, 4, 2, 1, 7, 4, 4, 4, 9, 4, 3, 6, 0, 7, 7, 8, 0,\n",
            "        9, 1, 2, 6, 2, 9, 7, 1, 9, 7, 3, 3, 1, 2, 3, 5])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([4, 3, 7, 4, 1, 4, 6, 6, 7, 5, 4, 6, 7, 9, 8, 1, 8, 1, 2, 2, 5, 5, 6, 1,\n",
            "        4, 6, 6, 1, 2, 0, 7, 6, 8, 8, 2, 8, 4, 5, 0, 0, 1, 7, 9, 7, 4, 9, 4, 0,\n",
            "        2, 8, 7, 1, 0, 8, 7, 6, 8, 4, 8, 2, 8, 0, 1, 5])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([3, 8, 1, 7, 4, 9, 3, 7, 9, 5, 1, 8, 3, 0, 9, 3, 6, 2, 4, 2, 7, 6, 2, 9,\n",
            "        8, 8, 1, 5, 7, 7, 1, 9, 5, 4, 1, 0, 7, 8, 7, 3, 7, 6, 2, 5, 5, 4, 6, 7,\n",
            "        2, 6, 3, 2, 0, 4, 7, 8, 6, 6, 0, 1, 5, 3, 8, 3])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([9, 7, 1, 7, 1, 0, 3, 8, 5, 0, 0, 6, 4, 1, 1, 2, 9, 0, 6, 2, 1, 3, 2, 7,\n",
            "        6, 1, 8, 5, 7, 2, 0, 5, 0, 4, 6, 2, 2, 5, 4, 1, 8, 2, 1, 5, 3, 8, 8, 9,\n",
            "        9, 0, 1, 8, 1, 4, 9, 0, 3, 1, 1, 4, 7, 8, 3, 4])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([9, 6, 6, 8, 3, 8, 2, 9, 4, 7, 7, 0, 3, 0, 2, 5, 7, 3, 7, 4, 6, 0, 9, 3,\n",
            "        6, 5, 4, 1, 2, 1, 8, 1, 9, 4, 8, 9, 9, 3, 3, 7, 0, 6, 6, 1, 6, 6, 6, 4,\n",
            "        2, 2, 7, 0, 6, 1, 2, 0, 0, 1, 6, 0, 3, 5, 7, 9])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([1, 6, 3, 7, 5, 1, 2, 7, 7, 5, 8, 0, 9, 1, 0, 1, 6, 9, 1, 6, 5, 3, 3, 0,\n",
            "        7, 1, 2, 7, 9, 3, 7, 4, 4, 4, 6, 7, 4, 7, 3, 1, 7, 8, 8, 7, 0, 1, 4, 0,\n",
            "        9, 7, 9, 9, 1, 2, 0, 4, 7, 4, 3, 4, 1, 7, 5, 7])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([0, 9, 0, 0, 3, 1, 4, 7, 9, 3, 6, 7, 8, 4, 7, 4, 0, 8, 3, 0, 1, 7, 9, 6,\n",
            "        9, 1, 4, 6, 7, 1, 0, 6, 3, 7, 3, 1, 8, 6, 5, 9, 5, 8, 1, 0, 9, 2, 6, 2,\n",
            "        1, 1, 4, 7, 3, 0, 7, 5, 8, 9, 5, 4, 0, 4, 7, 2])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([3, 8, 3, 8, 1, 1, 2, 4, 8, 1, 6, 8, 1, 8, 5, 3, 2, 7, 2, 2, 4, 9, 6, 0,\n",
            "        4, 9, 9, 6, 9, 9, 6, 7, 3, 4, 3, 3, 9, 4, 7, 7, 8, 1, 1, 6, 6, 5, 7, 9,\n",
            "        4, 7, 6, 7, 0, 0, 2, 9, 9, 7, 7, 5, 0, 1, 4, 3])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([4, 6, 4, 0, 9, 8, 7, 8, 4, 4, 8, 9, 7, 1, 6, 7, 9, 9, 0, 1, 5, 1, 1, 3,\n",
            "        6, 7, 9, 8, 3, 3, 8, 5, 2, 4, 3, 6, 8, 6, 9, 0, 6, 9, 0, 1, 6, 8, 1, 8,\n",
            "        2, 1, 8, 1, 7, 1, 9, 1, 8, 0, 9, 4, 1, 0, 8, 4])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([4, 6, 8, 2, 2, 5, 5, 0, 6, 6, 9, 8, 0, 1, 0, 0, 4, 8, 3, 4, 7, 7, 5, 9,\n",
            "        2, 5, 4, 4, 9, 9, 4, 8, 7, 6, 9, 3, 4, 0, 4, 8, 0, 1, 9, 2, 1, 6, 7, 1,\n",
            "        8, 5, 0, 4, 6, 4, 1, 1, 9, 8, 8, 9, 1, 2, 6, 0])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([5, 2, 5, 6, 8, 3, 6, 1, 8, 6, 1, 5, 0, 3, 3, 1, 9, 2, 8, 7, 8, 2, 3, 6,\n",
            "        2, 5, 0, 9, 0, 7, 1, 1, 7, 9, 6, 1, 6, 7, 5, 4, 6, 3, 3, 6, 1, 6, 0, 9,\n",
            "        9, 8, 2, 9, 6, 2, 5, 4, 7, 2, 6, 5, 6, 0, 9, 3])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([7, 0, 2, 3, 5, 6, 4, 3, 4, 6, 9, 8, 8, 3, 2, 0, 0, 3, 9, 2, 2, 8, 1, 9,\n",
            "        2, 4, 9, 3, 6, 2, 0, 6, 7, 0, 5, 0, 6, 3, 1, 3, 0, 9, 5, 4, 3, 7, 0, 6,\n",
            "        2, 9, 0, 7, 6, 5, 6, 8, 2, 1, 0, 6, 6, 5, 9, 3])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([5, 0, 6, 0, 7, 4, 6, 8, 3, 3, 8, 6, 3, 8, 9, 4, 0, 8, 8, 3, 8, 0, 7, 7,\n",
            "        0, 3, 6, 8, 1, 5, 9, 6, 2, 8, 9, 0, 1, 0, 5, 5, 2, 2, 8, 2, 3, 6, 7, 4,\n",
            "        5, 3, 7, 4, 5, 8, 8, 3, 9, 5, 0, 6, 2, 6, 3, 6])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([6, 9, 2, 5, 6, 5, 6, 3, 1, 7, 8, 0, 4, 7, 3, 3, 8, 6, 0, 9, 2, 8, 5, 4,\n",
            "        9, 6, 6, 4, 2, 0, 1, 1, 9, 3, 8, 2, 1, 9, 5, 8, 4, 8, 2, 3, 5, 3, 6, 4,\n",
            "        9, 2, 6, 2, 9, 8, 0, 5, 9, 2, 4, 5, 2, 1, 0, 7])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([4, 4, 2, 7, 4, 0, 6, 6, 1, 5, 4, 0, 1, 9, 9, 5, 6, 5, 2, 9, 6, 6, 4, 5,\n",
            "        4, 8, 9, 0, 9, 5, 5, 5, 7, 9, 3, 3, 8, 4, 3, 9, 3, 1, 0, 2, 5, 2, 8, 7,\n",
            "        9, 7, 7, 7, 9, 2, 0, 0, 6, 7, 6, 1, 8, 0, 3, 8])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([5, 0, 5, 6, 9, 1, 1, 2, 6, 8, 9, 7, 7, 5, 8, 6, 1, 4, 0, 1, 8, 4, 3, 4,\n",
            "        7, 9, 3, 7, 5, 5, 0, 9, 1, 2, 1, 2, 7, 6, 0, 9, 3, 2, 1, 1, 7, 8, 1, 6,\n",
            "        5, 9, 0, 0, 9, 5, 3, 8, 8, 2, 8, 5, 7, 0, 7, 0])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([9, 6, 9, 2, 9, 4, 8, 5, 2, 0, 1, 6, 6, 1, 7, 6, 1, 7, 7, 8, 5, 7, 0, 6,\n",
            "        4, 2, 1, 6, 8, 0, 0, 2, 7, 5, 9, 1, 0, 4, 3, 7, 6, 6, 3, 1, 8, 4, 7, 2,\n",
            "        5, 9, 3, 1, 8, 1, 9, 2, 9, 6, 2, 2, 1, 8, 3, 9])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([8, 2, 0, 4, 8, 4, 5, 1, 2, 2, 6, 4, 1, 8, 5, 7, 7, 7, 3, 5, 5, 7, 9, 9,\n",
            "        8, 2, 8, 2, 1, 3, 3, 4, 8, 9, 4, 0, 7, 6, 2, 8, 1, 0, 6, 1, 6, 5, 2, 9,\n",
            "        7, 2, 8, 7, 3, 7, 8, 1, 2, 1, 7, 4, 8, 8, 5, 0])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([2, 6, 6, 1, 2, 6, 5, 0, 1, 5, 5, 2, 5, 1, 9, 8, 7, 1, 2, 7, 0, 9, 3, 1,\n",
            "        9, 0, 4, 6, 6, 5, 9, 9, 4, 2, 7, 1, 8, 1, 4, 2, 3, 7, 8, 4, 6, 4, 5, 1,\n",
            "        2, 9, 3, 5, 8, 0, 1, 9, 6, 7, 3, 7, 4, 4, 0, 6])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([2, 1, 1, 3, 0, 7, 0, 5, 9, 8, 9, 3, 7, 9, 9, 4, 8, 8, 0, 1, 6, 4, 0, 6,\n",
            "        8, 1, 6, 1, 6, 3, 2, 7, 8, 7, 0, 4, 3, 4, 4, 5, 7, 9, 2, 5, 2, 4, 5, 0,\n",
            "        1, 7, 6, 7, 6, 0, 0, 0, 5, 1, 1, 2, 4, 6, 9, 8])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([1, 6, 1, 6, 8, 5, 4, 0, 4, 0, 4, 9, 3, 8, 5, 2, 8, 6, 2, 8, 0, 4, 4, 0,\n",
            "        8, 7, 5, 2, 8, 9, 2, 9, 5, 9, 2, 1, 0, 4, 1, 7, 7, 1, 7, 3, 5, 8, 7, 2,\n",
            "        5, 1, 5, 2, 0, 6, 0, 1, 2, 4, 4, 8, 0, 3, 2, 0])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([3, 5, 1, 3, 3, 0, 5, 1, 8, 3, 1, 8, 7, 8, 4, 2, 0, 0, 7, 8, 1, 3, 9, 0,\n",
            "        2, 8, 1, 4, 8, 8, 3, 0, 8, 5, 7, 5, 4, 7, 7, 6, 1, 8, 1, 9, 7, 0, 3, 1,\n",
            "        6, 5, 5, 3, 8, 9, 4, 0, 9, 5, 1, 7, 2, 1, 5, 2])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([8, 3, 3, 6, 7, 1, 3, 4, 4, 5, 7, 0, 6, 7, 3, 3, 7, 8, 8, 2, 5, 6, 9, 7,\n",
            "        0, 2, 9, 3, 0, 5, 5, 6, 9, 1, 4, 1, 5, 6, 4, 1, 4, 0, 3, 3, 6, 3, 0, 8,\n",
            "        6, 7, 5, 5, 7, 0, 7, 9, 4, 4, 2, 9, 1, 7, 1, 8])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([8, 8, 5, 8, 3, 8, 9, 3, 0, 0, 2, 1, 8, 4, 4, 0, 0, 9, 5, 3, 1, 5, 1, 3,\n",
            "        5, 0, 2, 6, 1, 5, 3, 0, 8, 6, 9, 6, 9, 6, 0, 4, 1, 6, 6, 4, 9, 1, 4, 9,\n",
            "        7, 8, 2, 6, 2, 9, 7, 8, 5, 6, 9, 6, 0, 0, 8, 1])\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([3, 2, 7, 5, 8, 4, 5, 6, 8, 9, 1, 9, 1, 8, 1, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhticra4U6qd",
        "outputId": "7b1d0bcc-4df3-4a36-bd58-3100aaea41b8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define our custom model\n",
        "\n",
        "class NeuralNetworks(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetworks,self).__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relue_stack = nn.Sequential(\n",
        "        nn.Linear(28*28,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,10)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relue_stack(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "2_6s76noVli0"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zd0bGAO_YSpU",
        "outputId": "90acf25b-5d27-4026-8249-6a2ec369dffe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetworks().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYYQOw4fY8vg",
        "outputId": "44c06fbb-45fc-49b3-f895-85ee2d79ab50"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetworks(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relue_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=1e-3)"
      ],
      "metadata": {
        "id": "_5rLPI_IZFB-"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # Compute prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "  avg_loss = running_loss / len(dataloader)\n",
        "  print(f\"Avg Training Loss: {avg_loss:>8f}\")\n"
      ],
      "metadata": {
        "id": "zajpruYAbiYh"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing loop\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "  size =len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0,0\n",
        "  with torch.no_grad():\n",
        "    for X,y in dataloader:\n",
        "      X,y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      loss = loss_fn(pred, y)\n",
        "      test_loss += loss.item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f}\\n\")"
      ],
      "metadata": {
        "id": "et9nQKM4dtUx"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "\n",
        "epoch = 100\n",
        "\n",
        "for t in range(epoch):\n",
        "  print(f\"Epoch {t+1}\\n----------------------------------\")\n",
        "  train(train_dataloader,model,loss_fn,optimizer)\n",
        "  test(test_dataloader,model,loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgtcTSygfhcu",
        "outputId": "2ee62955-8c5a-4cea-a32c-b0906144533a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "----------------------------------\n",
            "loss: 2.338334 [    0/60000]\n",
            "loss: 2.290407 [ 2000/60000]\n",
            "loss: 2.292837 [ 4000/60000]\n",
            "loss: 2.282280 [ 6000/60000]\n",
            "loss: 2.231304 [ 8000/60000]\n",
            "loss: 2.251463 [10000/60000]\n",
            "loss: 2.247780 [12000/60000]\n",
            "loss: 2.232702 [14000/60000]\n",
            "loss: 2.227078 [16000/60000]\n",
            "loss: 2.213232 [18000/60000]\n",
            "loss: 2.195012 [20000/60000]\n",
            "loss: 2.170395 [22000/60000]\n",
            "loss: 2.104631 [24000/60000]\n",
            "loss: 2.035517 [26000/60000]\n",
            "loss: 2.091084 [28000/60000]\n",
            "loss: 2.017138 [30000/60000]\n",
            "loss: 1.973577 [32000/60000]\n",
            "loss: 1.987720 [34000/60000]\n",
            "loss: 1.871657 [36000/60000]\n",
            "loss: 1.847136 [38000/60000]\n",
            "loss: 1.875476 [40000/60000]\n",
            "loss: 1.788864 [42000/60000]\n",
            "loss: 1.765358 [44000/60000]\n",
            "loss: 1.740481 [46000/60000]\n",
            "loss: 1.775701 [48000/60000]\n",
            "loss: 1.389306 [50000/60000]\n",
            "loss: 1.482876 [52000/60000]\n",
            "loss: 1.681431 [54000/60000]\n",
            "loss: 1.617462 [56000/60000]\n",
            "loss: 1.523976 [58000/60000]\n",
            "Avg Training Loss: 1.971831\n",
            "Test Error: \n",
            " Accuracy: 59.4%, Avg loss: 1.470034\n",
            "\n",
            "Epoch 2\n",
            "----------------------------------\n",
            "loss: 1.539577 [    0/60000]\n",
            "loss: 1.469073 [ 2000/60000]\n",
            "loss: 1.449684 [ 4000/60000]\n",
            "loss: 1.512950 [ 6000/60000]\n",
            "loss: 1.382032 [ 8000/60000]\n",
            "loss: 1.283413 [10000/60000]\n",
            "loss: 1.426635 [12000/60000]\n",
            "loss: 1.345903 [14000/60000]\n",
            "loss: 1.420101 [16000/60000]\n",
            "loss: 1.491898 [18000/60000]\n",
            "loss: 1.373333 [20000/60000]\n",
            "loss: 1.262027 [22000/60000]\n",
            "loss: 1.189757 [24000/60000]\n",
            "loss: 1.066532 [26000/60000]\n",
            "loss: 1.215711 [28000/60000]\n",
            "loss: 0.964120 [30000/60000]\n",
            "loss: 1.038479 [32000/60000]\n",
            "loss: 1.236115 [34000/60000]\n",
            "loss: 1.026052 [36000/60000]\n",
            "loss: 1.004086 [38000/60000]\n",
            "loss: 0.996593 [40000/60000]\n",
            "loss: 1.106059 [42000/60000]\n",
            "loss: 0.943454 [44000/60000]\n",
            "loss: 1.075032 [46000/60000]\n",
            "loss: 0.993805 [48000/60000]\n",
            "loss: 0.742852 [50000/60000]\n",
            "loss: 0.788790 [52000/60000]\n",
            "loss: 1.099454 [54000/60000]\n",
            "loss: 1.202098 [56000/60000]\n",
            "loss: 0.927585 [58000/60000]\n",
            "Avg Training Loss: 1.144389\n",
            "Test Error: \n",
            " Accuracy: 66.0%, Avg loss: 0.957836\n",
            "\n",
            "Epoch 3\n",
            "----------------------------------\n",
            "loss: 0.977699 [    0/60000]\n",
            "loss: 1.046203 [ 2000/60000]\n",
            "loss: 0.863297 [ 4000/60000]\n",
            "loss: 1.059191 [ 6000/60000]\n",
            "loss: 0.940422 [ 8000/60000]\n",
            "loss: 0.805653 [10000/60000]\n",
            "loss: 1.032270 [12000/60000]\n",
            "loss: 0.949511 [14000/60000]\n",
            "loss: 1.059961 [16000/60000]\n",
            "loss: 1.279931 [18000/60000]\n",
            "loss: 1.009328 [20000/60000]\n",
            "loss: 0.895465 [22000/60000]\n",
            "loss: 0.904324 [24000/60000]\n",
            "loss: 0.751442 [26000/60000]\n",
            "loss: 0.930722 [28000/60000]\n",
            "loss: 0.674322 [30000/60000]\n",
            "loss: 0.738382 [32000/60000]\n",
            "loss: 1.016162 [34000/60000]\n",
            "loss: 0.834338 [36000/60000]\n",
            "loss: 0.794805 [38000/60000]\n",
            "loss: 0.758528 [40000/60000]\n",
            "loss: 0.930093 [42000/60000]\n",
            "loss: 0.713384 [44000/60000]\n",
            "loss: 0.933970 [46000/60000]\n",
            "loss: 0.781824 [48000/60000]\n",
            "loss: 0.606592 [50000/60000]\n",
            "loss: 0.577620 [52000/60000]\n",
            "loss: 0.931080 [54000/60000]\n",
            "loss: 1.093774 [56000/60000]\n",
            "loss: 0.813254 [58000/60000]\n",
            "Avg Training Loss: 0.856018\n",
            "Test Error: \n",
            " Accuracy: 70.2%, Avg loss: 0.805166\n",
            "\n",
            "Epoch 4\n",
            "----------------------------------\n",
            "loss: 0.815149 [    0/60000]\n",
            "loss: 0.899423 [ 2000/60000]\n",
            "loss: 0.637595 [ 4000/60000]\n",
            "loss: 0.881624 [ 6000/60000]\n",
            "loss: 0.763391 [ 8000/60000]\n",
            "loss: 0.647829 [10000/60000]\n",
            "loss: 0.893579 [12000/60000]\n",
            "loss: 0.786504 [14000/60000]\n",
            "loss: 0.924576 [16000/60000]\n",
            "loss: 1.272047 [18000/60000]\n",
            "loss: 0.819055 [20000/60000]\n",
            "loss: 0.765978 [22000/60000]\n",
            "loss: 0.793427 [24000/60000]\n",
            "loss: 0.660756 [26000/60000]\n",
            "loss: 0.823631 [28000/60000]\n",
            "loss: 0.578061 [30000/60000]\n",
            "loss: 0.646785 [32000/60000]\n",
            "loss: 0.920955 [34000/60000]\n",
            "loss: 0.758925 [36000/60000]\n",
            "loss: 0.707376 [38000/60000]\n",
            "loss: 0.690714 [40000/60000]\n",
            "loss: 0.855746 [42000/60000]\n",
            "loss: 0.595963 [44000/60000]\n",
            "loss: 0.879109 [46000/60000]\n",
            "loss: 0.696076 [48000/60000]\n",
            "loss: 0.548749 [50000/60000]\n",
            "loss: 0.475079 [52000/60000]\n",
            "loss: 0.868367 [54000/60000]\n",
            "loss: 1.000730 [56000/60000]\n",
            "loss: 0.770938 [58000/60000]\n",
            "Avg Training Loss: 0.746890\n",
            "Test Error: \n",
            " Accuracy: 73.7%, Avg loss: 0.727859\n",
            "\n",
            "Epoch 5\n",
            "----------------------------------\n",
            "loss: 0.731836 [    0/60000]\n",
            "loss: 0.822895 [ 2000/60000]\n",
            "loss: 0.517816 [ 4000/60000]\n",
            "loss: 0.775851 [ 6000/60000]\n",
            "loss: 0.667855 [ 8000/60000]\n",
            "loss: 0.568290 [10000/60000]\n",
            "loss: 0.806743 [12000/60000]\n",
            "loss: 0.687045 [14000/60000]\n",
            "loss: 0.854723 [16000/60000]\n",
            "loss: 1.263416 [18000/60000]\n",
            "loss: 0.686356 [20000/60000]\n",
            "loss: 0.694664 [22000/60000]\n",
            "loss: 0.729182 [24000/60000]\n",
            "loss: 0.617403 [26000/60000]\n",
            "loss: 0.766170 [28000/60000]\n",
            "loss: 0.534876 [30000/60000]\n",
            "loss: 0.621210 [32000/60000]\n",
            "loss: 0.867011 [34000/60000]\n",
            "loss: 0.702106 [36000/60000]\n",
            "loss: 0.647591 [38000/60000]\n",
            "loss: 0.669649 [40000/60000]\n",
            "loss: 0.804804 [42000/60000]\n",
            "loss: 0.511491 [44000/60000]\n",
            "loss: 0.837244 [46000/60000]\n",
            "loss: 0.641799 [48000/60000]\n",
            "loss: 0.512076 [50000/60000]\n",
            "loss: 0.409692 [52000/60000]\n",
            "loss: 0.836100 [54000/60000]\n",
            "loss: 0.904811 [56000/60000]\n",
            "loss: 0.739625 [58000/60000]\n",
            "Avg Training Loss: 0.682115\n",
            "Test Error: \n",
            " Accuracy: 76.1%, Avg loss: 0.674313\n",
            "\n",
            "Epoch 6\n",
            "----------------------------------\n",
            "loss: 0.673794 [    0/60000]\n",
            "loss: 0.769016 [ 2000/60000]\n",
            "loss: 0.435800 [ 4000/60000]\n",
            "loss: 0.704399 [ 6000/60000]\n",
            "loss: 0.607382 [ 8000/60000]\n",
            "loss: 0.515320 [10000/60000]\n",
            "loss: 0.737270 [12000/60000]\n",
            "loss: 0.613594 [14000/60000]\n",
            "loss: 0.808492 [16000/60000]\n",
            "loss: 1.236217 [18000/60000]\n",
            "loss: 0.591318 [20000/60000]\n",
            "loss: 0.638407 [22000/60000]\n",
            "loss: 0.684746 [24000/60000]\n",
            "loss: 0.585301 [26000/60000]\n",
            "loss: 0.728402 [28000/60000]\n",
            "loss: 0.508000 [30000/60000]\n",
            "loss: 0.608024 [32000/60000]\n",
            "loss: 0.828930 [34000/60000]\n",
            "loss: 0.650106 [36000/60000]\n",
            "loss: 0.600935 [38000/60000]\n",
            "loss: 0.663371 [40000/60000]\n",
            "loss: 0.763676 [42000/60000]\n",
            "loss: 0.447509 [44000/60000]\n",
            "loss: 0.798184 [46000/60000]\n",
            "loss: 0.600052 [48000/60000]\n",
            "loss: 0.485805 [50000/60000]\n",
            "loss: 0.362387 [52000/60000]\n",
            "loss: 0.810067 [54000/60000]\n",
            "loss: 0.815094 [56000/60000]\n",
            "loss: 0.712402 [58000/60000]\n",
            "Avg Training Loss: 0.634515\n",
            "Test Error: \n",
            " Accuracy: 77.8%, Avg loss: 0.633595\n",
            "\n",
            "Epoch 7\n",
            "----------------------------------\n",
            "loss: 0.634187 [    0/60000]\n",
            "loss: 0.723367 [ 2000/60000]\n",
            "loss: 0.374416 [ 4000/60000]\n",
            "loss: 0.652809 [ 6000/60000]\n",
            "loss: 0.565899 [ 8000/60000]\n",
            "loss: 0.476526 [10000/60000]\n",
            "loss: 0.679168 [12000/60000]\n",
            "loss: 0.557837 [14000/60000]\n",
            "loss: 0.773763 [16000/60000]\n",
            "loss: 1.200735 [18000/60000]\n",
            "loss: 0.522328 [20000/60000]\n",
            "loss: 0.594631 [22000/60000]\n",
            "loss: 0.652061 [24000/60000]\n",
            "loss: 0.558258 [26000/60000]\n",
            "loss: 0.703472 [28000/60000]\n",
            "loss: 0.488365 [30000/60000]\n",
            "loss: 0.593831 [32000/60000]\n",
            "loss: 0.799292 [34000/60000]\n",
            "loss: 0.604309 [36000/60000]\n",
            "loss: 0.564447 [38000/60000]\n",
            "loss: 0.661658 [40000/60000]\n",
            "loss: 0.731125 [42000/60000]\n",
            "loss: 0.400627 [44000/60000]\n",
            "loss: 0.761629 [46000/60000]\n",
            "loss: 0.568432 [48000/60000]\n",
            "loss: 0.467314 [50000/60000]\n",
            "loss: 0.328144 [52000/60000]\n",
            "loss: 0.783923 [54000/60000]\n",
            "loss: 0.735664 [56000/60000]\n",
            "loss: 0.689525 [58000/60000]\n",
            "Avg Training Loss: 0.597783\n",
            "Test Error: \n",
            " Accuracy: 78.9%, Avg loss: 0.602390\n",
            "\n",
            "Epoch 8\n",
            "----------------------------------\n",
            "loss: 0.606470 [    0/60000]\n",
            "loss: 0.683030 [ 2000/60000]\n",
            "loss: 0.327923 [ 4000/60000]\n",
            "loss: 0.613715 [ 6000/60000]\n",
            "loss: 0.536728 [ 8000/60000]\n",
            "loss: 0.446496 [10000/60000]\n",
            "loss: 0.632658 [12000/60000]\n",
            "loss: 0.514939 [14000/60000]\n",
            "loss: 0.747163 [16000/60000]\n",
            "loss: 1.163474 [18000/60000]\n",
            "loss: 0.472257 [20000/60000]\n",
            "loss: 0.563574 [22000/60000]\n",
            "loss: 0.626845 [24000/60000]\n",
            "loss: 0.535025 [26000/60000]\n",
            "loss: 0.687780 [28000/60000]\n",
            "loss: 0.471528 [30000/60000]\n",
            "loss: 0.576171 [32000/60000]\n",
            "loss: 0.775251 [34000/60000]\n",
            "loss: 0.566222 [36000/60000]\n",
            "loss: 0.537267 [38000/60000]\n",
            "loss: 0.660295 [40000/60000]\n",
            "loss: 0.707833 [42000/60000]\n",
            "loss: 0.367912 [44000/60000]\n",
            "loss: 0.728660 [46000/60000]\n",
            "loss: 0.544710 [48000/60000]\n",
            "loss: 0.453765 [50000/60000]\n",
            "loss: 0.303689 [52000/60000]\n",
            "loss: 0.757251 [54000/60000]\n",
            "loss: 0.668162 [56000/60000]\n",
            "loss: 0.670610 [58000/60000]\n",
            "Avg Training Loss: 0.569225\n",
            "Test Error: \n",
            " Accuracy: 79.8%, Avg loss: 0.578273\n",
            "\n",
            "Epoch 9\n",
            "----------------------------------\n",
            "loss: 0.585530 [    0/60000]\n",
            "loss: 0.647123 [ 2000/60000]\n",
            "loss: 0.291512 [ 4000/60000]\n",
            "loss: 0.583812 [ 6000/60000]\n",
            "loss: 0.514720 [ 8000/60000]\n",
            "loss: 0.421865 [10000/60000]\n",
            "loss: 0.595475 [12000/60000]\n",
            "loss: 0.480744 [14000/60000]\n",
            "loss: 0.726599 [16000/60000]\n",
            "loss: 1.128588 [18000/60000]\n",
            "loss: 0.435246 [20000/60000]\n",
            "loss: 0.542505 [22000/60000]\n",
            "loss: 0.608431 [24000/60000]\n",
            "loss: 0.514581 [26000/60000]\n",
            "loss: 0.678429 [28000/60000]\n",
            "loss: 0.455157 [30000/60000]\n",
            "loss: 0.555811 [32000/60000]\n",
            "loss: 0.754387 [34000/60000]\n",
            "loss: 0.536553 [36000/60000]\n",
            "loss: 0.517787 [38000/60000]\n",
            "loss: 0.658535 [40000/60000]\n",
            "loss: 0.691365 [42000/60000]\n",
            "loss: 0.346262 [44000/60000]\n",
            "loss: 0.700910 [46000/60000]\n",
            "loss: 0.526720 [48000/60000]\n",
            "loss: 0.443774 [50000/60000]\n",
            "loss: 0.286174 [52000/60000]\n",
            "loss: 0.730145 [54000/60000]\n",
            "loss: 0.612086 [56000/60000]\n",
            "loss: 0.654757 [58000/60000]\n",
            "Avg Training Loss: 0.546694\n",
            "Test Error: \n",
            " Accuracy: 80.5%, Avg loss: 0.559238\n",
            "\n",
            "Epoch 10\n",
            "----------------------------------\n",
            "loss: 0.567624 [    0/60000]\n",
            "loss: 0.615218 [ 2000/60000]\n",
            "loss: 0.262478 [ 4000/60000]\n",
            "loss: 0.561056 [ 6000/60000]\n",
            "loss: 0.497373 [ 8000/60000]\n",
            "loss: 0.401377 [10000/60000]\n",
            "loss: 0.565584 [12000/60000]\n",
            "loss: 0.453338 [14000/60000]\n",
            "loss: 0.711021 [16000/60000]\n",
            "loss: 1.096008 [18000/60000]\n",
            "loss: 0.407147 [20000/60000]\n",
            "loss: 0.529966 [22000/60000]\n",
            "loss: 0.594183 [24000/60000]\n",
            "loss: 0.496179 [26000/60000]\n",
            "loss: 0.672515 [28000/60000]\n",
            "loss: 0.439510 [30000/60000]\n",
            "loss: 0.534987 [32000/60000]\n",
            "loss: 0.735739 [34000/60000]\n",
            "loss: 0.513180 [36000/60000]\n",
            "loss: 0.503508 [38000/60000]\n",
            "loss: 0.656270 [40000/60000]\n",
            "loss: 0.679988 [42000/60000]\n",
            "loss: 0.331821 [44000/60000]\n",
            "loss: 0.677724 [46000/60000]\n",
            "loss: 0.513023 [48000/60000]\n",
            "loss: 0.436470 [50000/60000]\n",
            "loss: 0.272859 [52000/60000]\n",
            "loss: 0.704104 [54000/60000]\n",
            "loss: 0.565233 [56000/60000]\n",
            "loss: 0.640543 [58000/60000]\n",
            "Avg Training Loss: 0.528599\n",
            "Test Error: \n",
            " Accuracy: 81.1%, Avg loss: 0.543940\n",
            "\n",
            "Epoch 11\n",
            "----------------------------------\n",
            "loss: 0.550915 [    0/60000]\n",
            "loss: 0.587844 [ 2000/60000]\n",
            "loss: 0.239017 [ 4000/60000]\n",
            "loss: 0.543106 [ 6000/60000]\n",
            "loss: 0.483559 [ 8000/60000]\n",
            "loss: 0.383863 [10000/60000]\n",
            "loss: 0.541683 [12000/60000]\n",
            "loss: 0.430849 [14000/60000]\n",
            "loss: 0.698688 [16000/60000]\n",
            "loss: 1.066939 [18000/60000]\n",
            "loss: 0.384584 [20000/60000]\n",
            "loss: 0.523482 [22000/60000]\n",
            "loss: 0.583406 [24000/60000]\n",
            "loss: 0.479580 [26000/60000]\n",
            "loss: 0.668743 [28000/60000]\n",
            "loss: 0.424083 [30000/60000]\n",
            "loss: 0.514820 [32000/60000]\n",
            "loss: 0.718402 [34000/60000]\n",
            "loss: 0.495210 [36000/60000]\n",
            "loss: 0.492745 [38000/60000]\n",
            "loss: 0.653911 [40000/60000]\n",
            "loss: 0.672308 [42000/60000]\n",
            "loss: 0.322582 [44000/60000]\n",
            "loss: 0.658071 [46000/60000]\n",
            "loss: 0.502214 [48000/60000]\n",
            "loss: 0.430999 [50000/60000]\n",
            "loss: 0.262280 [52000/60000]\n",
            "loss: 0.679625 [54000/60000]\n",
            "loss: 0.524925 [56000/60000]\n",
            "loss: 0.627331 [58000/60000]\n",
            "Avg Training Loss: 0.513765\n",
            "Test Error: \n",
            " Accuracy: 81.5%, Avg loss: 0.531351\n",
            "\n",
            "Epoch 12\n",
            "----------------------------------\n",
            "loss: 0.534050 [    0/60000]\n",
            "loss: 0.564274 [ 2000/60000]\n",
            "loss: 0.220277 [ 4000/60000]\n",
            "loss: 0.528857 [ 6000/60000]\n",
            "loss: 0.472782 [ 8000/60000]\n",
            "loss: 0.368846 [10000/60000]\n",
            "loss: 0.522265 [12000/60000]\n",
            "loss: 0.411740 [14000/60000]\n",
            "loss: 0.688210 [16000/60000]\n",
            "loss: 1.041514 [18000/60000]\n",
            "loss: 0.366513 [20000/60000]\n",
            "loss: 0.521137 [22000/60000]\n",
            "loss: 0.574881 [24000/60000]\n",
            "loss: 0.465022 [26000/60000]\n",
            "loss: 0.666235 [28000/60000]\n",
            "loss: 0.409543 [30000/60000]\n",
            "loss: 0.496616 [32000/60000]\n",
            "loss: 0.702464 [34000/60000]\n",
            "loss: 0.481683 [36000/60000]\n",
            "loss: 0.484322 [38000/60000]\n",
            "loss: 0.651439 [40000/60000]\n",
            "loss: 0.667226 [42000/60000]\n",
            "loss: 0.316524 [44000/60000]\n",
            "loss: 0.641717 [46000/60000]\n",
            "loss: 0.493318 [48000/60000]\n",
            "loss: 0.427380 [50000/60000]\n",
            "loss: 0.253044 [52000/60000]\n",
            "loss: 0.656387 [54000/60000]\n",
            "loss: 0.490118 [56000/60000]\n",
            "loss: 0.614976 [58000/60000]\n",
            "Avg Training Loss: 0.501348\n",
            "Test Error: \n",
            " Accuracy: 81.9%, Avg loss: 0.520781\n",
            "\n",
            "Epoch 13\n",
            "----------------------------------\n",
            "loss: 0.517273 [    0/60000]\n",
            "loss: 0.544749 [ 2000/60000]\n",
            "loss: 0.205417 [ 4000/60000]\n",
            "loss: 0.518771 [ 6000/60000]\n",
            "loss: 0.463727 [ 8000/60000]\n",
            "loss: 0.356053 [10000/60000]\n",
            "loss: 0.506430 [12000/60000]\n",
            "loss: 0.395722 [14000/60000]\n",
            "loss: 0.679440 [16000/60000]\n",
            "loss: 1.019765 [18000/60000]\n",
            "loss: 0.351258 [20000/60000]\n",
            "loss: 0.521562 [22000/60000]\n",
            "loss: 0.567730 [24000/60000]\n",
            "loss: 0.452009 [26000/60000]\n",
            "loss: 0.664139 [28000/60000]\n",
            "loss: 0.395647 [30000/60000]\n",
            "loss: 0.480865 [32000/60000]\n",
            "loss: 0.687891 [34000/60000]\n",
            "loss: 0.471354 [36000/60000]\n",
            "loss: 0.477897 [38000/60000]\n",
            "loss: 0.649181 [40000/60000]\n",
            "loss: 0.663635 [42000/60000]\n",
            "loss: 0.312922 [44000/60000]\n",
            "loss: 0.627212 [46000/60000]\n",
            "loss: 0.484973 [48000/60000]\n",
            "loss: 0.424949 [50000/60000]\n",
            "loss: 0.244582 [52000/60000]\n",
            "loss: 0.634727 [54000/60000]\n",
            "loss: 0.460156 [56000/60000]\n",
            "loss: 0.602989 [58000/60000]\n",
            "Avg Training Loss: 0.490782\n",
            "Test Error: \n",
            " Accuracy: 82.0%, Avg loss: 0.511786\n",
            "\n",
            "Epoch 14\n",
            "----------------------------------\n",
            "loss: 0.500986 [    0/60000]\n",
            "loss: 0.528856 [ 2000/60000]\n",
            "loss: 0.193617 [ 4000/60000]\n",
            "loss: 0.509589 [ 6000/60000]\n",
            "loss: 0.455611 [ 8000/60000]\n",
            "loss: 0.345049 [10000/60000]\n",
            "loss: 0.492436 [12000/60000]\n",
            "loss: 0.382291 [14000/60000]\n",
            "loss: 0.672256 [16000/60000]\n",
            "loss: 0.999990 [18000/60000]\n",
            "loss: 0.338286 [20000/60000]\n",
            "loss: 0.524503 [22000/60000]\n",
            "loss: 0.561632 [24000/60000]\n",
            "loss: 0.440457 [26000/60000]\n",
            "loss: 0.662179 [28000/60000]\n",
            "loss: 0.382714 [30000/60000]\n",
            "loss: 0.467847 [32000/60000]\n",
            "loss: 0.674789 [34000/60000]\n",
            "loss: 0.462363 [36000/60000]\n",
            "loss: 0.472218 [38000/60000]\n",
            "loss: 0.647446 [40000/60000]\n",
            "loss: 0.661973 [42000/60000]\n",
            "loss: 0.310591 [44000/60000]\n",
            "loss: 0.613078 [46000/60000]\n",
            "loss: 0.478118 [48000/60000]\n",
            "loss: 0.423846 [50000/60000]\n",
            "loss: 0.237171 [52000/60000]\n",
            "loss: 0.614175 [54000/60000]\n",
            "loss: 0.434560 [56000/60000]\n",
            "loss: 0.592277 [58000/60000]\n",
            "Avg Training Loss: 0.481655\n",
            "Test Error: \n",
            " Accuracy: 82.2%, Avg loss: 0.504067\n",
            "\n",
            "Epoch 15\n",
            "----------------------------------\n",
            "loss: 0.485211 [    0/60000]\n",
            "loss: 0.515626 [ 2000/60000]\n",
            "loss: 0.183856 [ 4000/60000]\n",
            "loss: 0.501747 [ 6000/60000]\n",
            "loss: 0.450279 [ 8000/60000]\n",
            "loss: 0.335140 [10000/60000]\n",
            "loss: 0.480404 [12000/60000]\n",
            "loss: 0.371766 [14000/60000]\n",
            "loss: 0.666134 [16000/60000]\n",
            "loss: 0.982635 [18000/60000]\n",
            "loss: 0.326694 [20000/60000]\n",
            "loss: 0.529227 [22000/60000]\n",
            "loss: 0.556765 [24000/60000]\n",
            "loss: 0.430124 [26000/60000]\n",
            "loss: 0.660198 [28000/60000]\n",
            "loss: 0.370584 [30000/60000]\n",
            "loss: 0.457401 [32000/60000]\n",
            "loss: 0.662763 [34000/60000]\n",
            "loss: 0.454325 [36000/60000]\n",
            "loss: 0.467024 [38000/60000]\n",
            "loss: 0.645820 [40000/60000]\n",
            "loss: 0.661512 [42000/60000]\n",
            "loss: 0.309310 [44000/60000]\n",
            "loss: 0.600018 [46000/60000]\n",
            "loss: 0.472065 [48000/60000]\n",
            "loss: 0.423667 [50000/60000]\n",
            "loss: 0.230172 [52000/60000]\n",
            "loss: 0.595245 [54000/60000]\n",
            "loss: 0.411975 [56000/60000]\n",
            "loss: 0.582378 [58000/60000]\n",
            "Avg Training Loss: 0.473689\n",
            "Test Error: \n",
            " Accuracy: 82.4%, Avg loss: 0.497316\n",
            "\n",
            "Epoch 16\n",
            "----------------------------------\n",
            "loss: 0.469842 [    0/60000]\n",
            "loss: 0.505104 [ 2000/60000]\n",
            "loss: 0.175936 [ 4000/60000]\n",
            "loss: 0.494617 [ 6000/60000]\n",
            "loss: 0.446960 [ 8000/60000]\n",
            "loss: 0.326504 [10000/60000]\n",
            "loss: 0.469983 [12000/60000]\n",
            "loss: 0.363374 [14000/60000]\n",
            "loss: 0.660744 [16000/60000]\n",
            "loss: 0.967753 [18000/60000]\n",
            "loss: 0.316027 [20000/60000]\n",
            "loss: 0.534921 [22000/60000]\n",
            "loss: 0.552400 [24000/60000]\n",
            "loss: 0.421110 [26000/60000]\n",
            "loss: 0.658332 [28000/60000]\n",
            "loss: 0.359285 [30000/60000]\n",
            "loss: 0.449499 [32000/60000]\n",
            "loss: 0.651376 [34000/60000]\n",
            "loss: 0.447031 [36000/60000]\n",
            "loss: 0.461815 [38000/60000]\n",
            "loss: 0.643990 [40000/60000]\n",
            "loss: 0.662110 [42000/60000]\n",
            "loss: 0.308686 [44000/60000]\n",
            "loss: 0.587773 [46000/60000]\n",
            "loss: 0.466443 [48000/60000]\n",
            "loss: 0.424262 [50000/60000]\n",
            "loss: 0.223643 [52000/60000]\n",
            "loss: 0.577433 [54000/60000]\n",
            "loss: 0.392438 [56000/60000]\n",
            "loss: 0.573454 [58000/60000]\n",
            "Avg Training Loss: 0.466627\n",
            "Test Error: \n",
            " Accuracy: 82.6%, Avg loss: 0.491335\n",
            "\n",
            "Epoch 17\n",
            "----------------------------------\n",
            "loss: 0.455387 [    0/60000]\n",
            "loss: 0.496282 [ 2000/60000]\n",
            "loss: 0.169405 [ 4000/60000]\n",
            "loss: 0.487789 [ 6000/60000]\n",
            "loss: 0.445172 [ 8000/60000]\n",
            "loss: 0.318956 [10000/60000]\n",
            "loss: 0.460895 [12000/60000]\n",
            "loss: 0.356534 [14000/60000]\n",
            "loss: 0.656235 [16000/60000]\n",
            "loss: 0.954629 [18000/60000]\n",
            "loss: 0.306175 [20000/60000]\n",
            "loss: 0.540916 [22000/60000]\n",
            "loss: 0.548488 [24000/60000]\n",
            "loss: 0.413185 [26000/60000]\n",
            "loss: 0.655984 [28000/60000]\n",
            "loss: 0.348728 [30000/60000]\n",
            "loss: 0.443827 [32000/60000]\n",
            "loss: 0.640446 [34000/60000]\n",
            "loss: 0.440419 [36000/60000]\n",
            "loss: 0.456401 [38000/60000]\n",
            "loss: 0.642343 [40000/60000]\n",
            "loss: 0.663397 [42000/60000]\n",
            "loss: 0.308334 [44000/60000]\n",
            "loss: 0.576399 [46000/60000]\n",
            "loss: 0.461683 [48000/60000]\n",
            "loss: 0.425471 [50000/60000]\n",
            "loss: 0.217705 [52000/60000]\n",
            "loss: 0.561017 [54000/60000]\n",
            "loss: 0.375184 [56000/60000]\n",
            "loss: 0.565536 [58000/60000]\n",
            "Avg Training Loss: 0.460281\n",
            "Test Error: \n",
            " Accuracy: 82.8%, Avg loss: 0.485948\n",
            "\n",
            "Epoch 18\n",
            "----------------------------------\n",
            "loss: 0.441498 [    0/60000]\n",
            "loss: 0.489138 [ 2000/60000]\n",
            "loss: 0.163846 [ 4000/60000]\n",
            "loss: 0.481315 [ 6000/60000]\n",
            "loss: 0.444393 [ 8000/60000]\n",
            "loss: 0.312047 [10000/60000]\n",
            "loss: 0.452725 [12000/60000]\n",
            "loss: 0.351076 [14000/60000]\n",
            "loss: 0.652452 [16000/60000]\n",
            "loss: 0.942855 [18000/60000]\n",
            "loss: 0.297179 [20000/60000]\n",
            "loss: 0.547258 [22000/60000]\n",
            "loss: 0.544315 [24000/60000]\n",
            "loss: 0.405897 [26000/60000]\n",
            "loss: 0.653311 [28000/60000]\n",
            "loss: 0.338321 [30000/60000]\n",
            "loss: 0.440131 [32000/60000]\n",
            "loss: 0.630417 [34000/60000]\n",
            "loss: 0.434799 [36000/60000]\n",
            "loss: 0.450892 [38000/60000]\n",
            "loss: 0.640409 [40000/60000]\n",
            "loss: 0.665523 [42000/60000]\n",
            "loss: 0.308112 [44000/60000]\n",
            "loss: 0.565874 [46000/60000]\n",
            "loss: 0.457147 [48000/60000]\n",
            "loss: 0.427034 [50000/60000]\n",
            "loss: 0.212338 [52000/60000]\n",
            "loss: 0.546248 [54000/60000]\n",
            "loss: 0.359756 [56000/60000]\n",
            "loss: 0.558010 [58000/60000]\n",
            "Avg Training Loss: 0.454508\n",
            "Test Error: \n",
            " Accuracy: 82.9%, Avg loss: 0.481029\n",
            "\n",
            "Epoch 19\n",
            "----------------------------------\n",
            "loss: 0.428758 [    0/60000]\n",
            "loss: 0.482606 [ 2000/60000]\n",
            "loss: 0.159260 [ 4000/60000]\n",
            "loss: 0.474614 [ 6000/60000]\n",
            "loss: 0.444157 [ 8000/60000]\n",
            "loss: 0.306135 [10000/60000]\n",
            "loss: 0.444772 [12000/60000]\n",
            "loss: 0.346467 [14000/60000]\n",
            "loss: 0.649152 [16000/60000]\n",
            "loss: 0.932411 [18000/60000]\n",
            "loss: 0.289180 [20000/60000]\n",
            "loss: 0.553936 [22000/60000]\n",
            "loss: 0.538918 [24000/60000]\n",
            "loss: 0.399222 [26000/60000]\n",
            "loss: 0.650730 [28000/60000]\n",
            "loss: 0.328362 [30000/60000]\n",
            "loss: 0.437714 [32000/60000]\n",
            "loss: 0.620592 [34000/60000]\n",
            "loss: 0.429427 [36000/60000]\n",
            "loss: 0.445736 [38000/60000]\n",
            "loss: 0.638218 [40000/60000]\n",
            "loss: 0.667796 [42000/60000]\n",
            "loss: 0.308025 [44000/60000]\n",
            "loss: 0.556049 [46000/60000]\n",
            "loss: 0.453206 [48000/60000]\n",
            "loss: 0.428804 [50000/60000]\n",
            "loss: 0.207222 [52000/60000]\n",
            "loss: 0.532613 [54000/60000]\n",
            "loss: 0.346149 [56000/60000]\n",
            "loss: 0.550488 [58000/60000]\n",
            "Avg Training Loss: 0.449199\n",
            "Test Error: \n",
            " Accuracy: 83.1%, Avg loss: 0.476519\n",
            "\n",
            "Epoch 20\n",
            "----------------------------------\n",
            "loss: 0.417165 [    0/60000]\n",
            "loss: 0.476741 [ 2000/60000]\n",
            "loss: 0.155569 [ 4000/60000]\n",
            "loss: 0.468539 [ 6000/60000]\n",
            "loss: 0.445117 [ 8000/60000]\n",
            "loss: 0.300847 [10000/60000]\n",
            "loss: 0.437833 [12000/60000]\n",
            "loss: 0.342706 [14000/60000]\n",
            "loss: 0.645835 [16000/60000]\n",
            "loss: 0.923928 [18000/60000]\n",
            "loss: 0.281617 [20000/60000]\n",
            "loss: 0.559679 [22000/60000]\n",
            "loss: 0.534126 [24000/60000]\n",
            "loss: 0.393297 [26000/60000]\n",
            "loss: 0.648443 [28000/60000]\n",
            "loss: 0.318829 [30000/60000]\n",
            "loss: 0.437135 [32000/60000]\n",
            "loss: 0.612604 [34000/60000]\n",
            "loss: 0.424399 [36000/60000]\n",
            "loss: 0.440788 [38000/60000]\n",
            "loss: 0.637318 [40000/60000]\n",
            "loss: 0.670602 [42000/60000]\n",
            "loss: 0.307167 [44000/60000]\n",
            "loss: 0.547026 [46000/60000]\n",
            "loss: 0.449442 [48000/60000]\n",
            "loss: 0.430864 [50000/60000]\n",
            "loss: 0.202349 [52000/60000]\n",
            "loss: 0.519800 [54000/60000]\n",
            "loss: 0.333773 [56000/60000]\n",
            "loss: 0.543819 [58000/60000]\n",
            "Avg Training Loss: 0.444290\n",
            "Test Error: \n",
            " Accuracy: 83.3%, Avg loss: 0.472392\n",
            "\n",
            "Epoch 21\n",
            "----------------------------------\n",
            "loss: 0.406677 [    0/60000]\n",
            "loss: 0.471979 [ 2000/60000]\n",
            "loss: 0.152106 [ 4000/60000]\n",
            "loss: 0.462693 [ 6000/60000]\n",
            "loss: 0.446505 [ 8000/60000]\n",
            "loss: 0.295944 [10000/60000]\n",
            "loss: 0.432089 [12000/60000]\n",
            "loss: 0.339022 [14000/60000]\n",
            "loss: 0.642890 [16000/60000]\n",
            "loss: 0.916765 [18000/60000]\n",
            "loss: 0.274149 [20000/60000]\n",
            "loss: 0.565589 [22000/60000]\n",
            "loss: 0.530011 [24000/60000]\n",
            "loss: 0.387677 [26000/60000]\n",
            "loss: 0.646404 [28000/60000]\n",
            "loss: 0.310577 [30000/60000]\n",
            "loss: 0.437463 [32000/60000]\n",
            "loss: 0.605349 [34000/60000]\n",
            "loss: 0.419656 [36000/60000]\n",
            "loss: 0.435228 [38000/60000]\n",
            "loss: 0.635603 [40000/60000]\n",
            "loss: 0.673740 [42000/60000]\n",
            "loss: 0.306249 [44000/60000]\n",
            "loss: 0.538701 [46000/60000]\n",
            "loss: 0.445942 [48000/60000]\n",
            "loss: 0.433272 [50000/60000]\n",
            "loss: 0.197892 [52000/60000]\n",
            "loss: 0.507936 [54000/60000]\n",
            "loss: 0.322850 [56000/60000]\n",
            "loss: 0.537394 [58000/60000]\n",
            "Avg Training Loss: 0.439708\n",
            "Test Error: \n",
            " Accuracy: 83.5%, Avg loss: 0.468516\n",
            "\n",
            "Epoch 22\n",
            "----------------------------------\n",
            "loss: 0.397185 [    0/60000]\n",
            "loss: 0.468046 [ 2000/60000]\n",
            "loss: 0.148674 [ 4000/60000]\n",
            "loss: 0.456714 [ 6000/60000]\n",
            "loss: 0.447916 [ 8000/60000]\n",
            "loss: 0.291576 [10000/60000]\n",
            "loss: 0.426103 [12000/60000]\n",
            "loss: 0.336205 [14000/60000]\n",
            "loss: 0.640490 [16000/60000]\n",
            "loss: 0.910349 [18000/60000]\n",
            "loss: 0.267160 [20000/60000]\n",
            "loss: 0.571063 [22000/60000]\n",
            "loss: 0.525733 [24000/60000]\n",
            "loss: 0.381282 [26000/60000]\n",
            "loss: 0.644632 [28000/60000]\n",
            "loss: 0.302748 [30000/60000]\n",
            "loss: 0.437913 [32000/60000]\n",
            "loss: 0.598671 [34000/60000]\n",
            "loss: 0.415328 [36000/60000]\n",
            "loss: 0.429824 [38000/60000]\n",
            "loss: 0.634283 [40000/60000]\n",
            "loss: 0.677897 [42000/60000]\n",
            "loss: 0.304678 [44000/60000]\n",
            "loss: 0.530722 [46000/60000]\n",
            "loss: 0.442891 [48000/60000]\n",
            "loss: 0.435724 [50000/60000]\n",
            "loss: 0.193788 [52000/60000]\n",
            "loss: 0.496242 [54000/60000]\n",
            "loss: 0.312847 [56000/60000]\n",
            "loss: 0.531503 [58000/60000]\n",
            "Avg Training Loss: 0.435395\n",
            "Test Error: \n",
            " Accuracy: 83.7%, Avg loss: 0.464820\n",
            "\n",
            "Epoch 23\n",
            "----------------------------------\n",
            "loss: 0.388695 [    0/60000]\n",
            "loss: 0.464864 [ 2000/60000]\n",
            "loss: 0.145794 [ 4000/60000]\n",
            "loss: 0.451135 [ 6000/60000]\n",
            "loss: 0.449515 [ 8000/60000]\n",
            "loss: 0.287369 [10000/60000]\n",
            "loss: 0.421059 [12000/60000]\n",
            "loss: 0.334206 [14000/60000]\n",
            "loss: 0.638535 [16000/60000]\n",
            "loss: 0.903919 [18000/60000]\n",
            "loss: 0.260820 [20000/60000]\n",
            "loss: 0.576582 [22000/60000]\n",
            "loss: 0.521901 [24000/60000]\n",
            "loss: 0.375072 [26000/60000]\n",
            "loss: 0.643012 [28000/60000]\n",
            "loss: 0.295138 [30000/60000]\n",
            "loss: 0.439319 [32000/60000]\n",
            "loss: 0.591924 [34000/60000]\n",
            "loss: 0.411039 [36000/60000]\n",
            "loss: 0.424726 [38000/60000]\n",
            "loss: 0.632765 [40000/60000]\n",
            "loss: 0.681052 [42000/60000]\n",
            "loss: 0.303463 [44000/60000]\n",
            "loss: 0.523416 [46000/60000]\n",
            "loss: 0.440123 [48000/60000]\n",
            "loss: 0.438123 [50000/60000]\n",
            "loss: 0.189424 [52000/60000]\n",
            "loss: 0.485643 [54000/60000]\n",
            "loss: 0.303832 [56000/60000]\n",
            "loss: 0.526143 [58000/60000]\n",
            "Avg Training Loss: 0.431324\n",
            "Test Error: \n",
            " Accuracy: 83.8%, Avg loss: 0.461327\n",
            "\n",
            "Epoch 24\n",
            "----------------------------------\n",
            "loss: 0.381444 [    0/60000]\n",
            "loss: 0.461858 [ 2000/60000]\n",
            "loss: 0.143157 [ 4000/60000]\n",
            "loss: 0.446484 [ 6000/60000]\n",
            "loss: 0.450878 [ 8000/60000]\n",
            "loss: 0.283454 [10000/60000]\n",
            "loss: 0.416132 [12000/60000]\n",
            "loss: 0.332835 [14000/60000]\n",
            "loss: 0.636999 [16000/60000]\n",
            "loss: 0.897553 [18000/60000]\n",
            "loss: 0.255241 [20000/60000]\n",
            "loss: 0.579805 [22000/60000]\n",
            "loss: 0.517749 [24000/60000]\n",
            "loss: 0.370368 [26000/60000]\n",
            "loss: 0.641260 [28000/60000]\n",
            "loss: 0.287769 [30000/60000]\n",
            "loss: 0.440946 [32000/60000]\n",
            "loss: 0.584928 [34000/60000]\n",
            "loss: 0.406549 [36000/60000]\n",
            "loss: 0.419936 [38000/60000]\n",
            "loss: 0.631375 [40000/60000]\n",
            "loss: 0.684116 [42000/60000]\n",
            "loss: 0.302449 [44000/60000]\n",
            "loss: 0.516099 [46000/60000]\n",
            "loss: 0.437486 [48000/60000]\n",
            "loss: 0.440569 [50000/60000]\n",
            "loss: 0.185016 [52000/60000]\n",
            "loss: 0.475875 [54000/60000]\n",
            "loss: 0.295432 [56000/60000]\n",
            "loss: 0.521236 [58000/60000]\n",
            "Avg Training Loss: 0.427467\n",
            "Test Error: \n",
            " Accuracy: 83.9%, Avg loss: 0.457995\n",
            "\n",
            "Epoch 25\n",
            "----------------------------------\n",
            "loss: 0.375222 [    0/60000]\n",
            "loss: 0.458895 [ 2000/60000]\n",
            "loss: 0.140779 [ 4000/60000]\n",
            "loss: 0.441594 [ 6000/60000]\n",
            "loss: 0.452878 [ 8000/60000]\n",
            "loss: 0.279935 [10000/60000]\n",
            "loss: 0.411965 [12000/60000]\n",
            "loss: 0.331845 [14000/60000]\n",
            "loss: 0.635838 [16000/60000]\n",
            "loss: 0.891938 [18000/60000]\n",
            "loss: 0.250164 [20000/60000]\n",
            "loss: 0.580241 [22000/60000]\n",
            "loss: 0.513595 [24000/60000]\n",
            "loss: 0.365042 [26000/60000]\n",
            "loss: 0.639887 [28000/60000]\n",
            "loss: 0.281404 [30000/60000]\n",
            "loss: 0.443366 [32000/60000]\n",
            "loss: 0.579026 [34000/60000]\n",
            "loss: 0.402913 [36000/60000]\n",
            "loss: 0.415013 [38000/60000]\n",
            "loss: 0.630198 [40000/60000]\n",
            "loss: 0.686243 [42000/60000]\n",
            "loss: 0.301564 [44000/60000]\n",
            "loss: 0.509015 [46000/60000]\n",
            "loss: 0.434646 [48000/60000]\n",
            "loss: 0.442784 [50000/60000]\n",
            "loss: 0.181067 [52000/60000]\n",
            "loss: 0.466642 [54000/60000]\n",
            "loss: 0.288121 [56000/60000]\n",
            "loss: 0.516158 [58000/60000]\n",
            "Avg Training Loss: 0.423760\n",
            "Test Error: \n",
            " Accuracy: 84.0%, Avg loss: 0.454761\n",
            "\n",
            "Epoch 26\n",
            "----------------------------------\n",
            "loss: 0.369722 [    0/60000]\n",
            "loss: 0.456116 [ 2000/60000]\n",
            "loss: 0.138753 [ 4000/60000]\n",
            "loss: 0.435296 [ 6000/60000]\n",
            "loss: 0.454561 [ 8000/60000]\n",
            "loss: 0.276960 [10000/60000]\n",
            "loss: 0.408345 [12000/60000]\n",
            "loss: 0.330110 [14000/60000]\n",
            "loss: 0.635355 [16000/60000]\n",
            "loss: 0.888203 [18000/60000]\n",
            "loss: 0.245081 [20000/60000]\n",
            "loss: 0.582828 [22000/60000]\n",
            "loss: 0.509565 [24000/60000]\n",
            "loss: 0.359532 [26000/60000]\n",
            "loss: 0.638120 [28000/60000]\n",
            "loss: 0.274245 [30000/60000]\n",
            "loss: 0.444297 [32000/60000]\n",
            "loss: 0.572545 [34000/60000]\n",
            "loss: 0.398966 [36000/60000]\n",
            "loss: 0.410232 [38000/60000]\n",
            "loss: 0.628967 [40000/60000]\n",
            "loss: 0.688888 [42000/60000]\n",
            "loss: 0.300632 [44000/60000]\n",
            "loss: 0.502584 [46000/60000]\n",
            "loss: 0.432544 [48000/60000]\n",
            "loss: 0.445727 [50000/60000]\n",
            "loss: 0.177417 [52000/60000]\n",
            "loss: 0.459042 [54000/60000]\n",
            "loss: 0.281748 [56000/60000]\n",
            "loss: 0.512312 [58000/60000]\n",
            "Avg Training Loss: 0.420215\n",
            "Test Error: \n",
            " Accuracy: 84.1%, Avg loss: 0.451716\n",
            "\n",
            "Epoch 27\n",
            "----------------------------------\n",
            "loss: 0.364460 [    0/60000]\n",
            "loss: 0.452159 [ 2000/60000]\n",
            "loss: 0.137163 [ 4000/60000]\n",
            "loss: 0.429808 [ 6000/60000]\n",
            "loss: 0.456113 [ 8000/60000]\n",
            "loss: 0.274007 [10000/60000]\n",
            "loss: 0.405154 [12000/60000]\n",
            "loss: 0.328934 [14000/60000]\n",
            "loss: 0.633962 [16000/60000]\n",
            "loss: 0.884242 [18000/60000]\n",
            "loss: 0.240031 [20000/60000]\n",
            "loss: 0.586379 [22000/60000]\n",
            "loss: 0.505408 [24000/60000]\n",
            "loss: 0.354612 [26000/60000]\n",
            "loss: 0.636779 [28000/60000]\n",
            "loss: 0.267696 [30000/60000]\n",
            "loss: 0.444407 [32000/60000]\n",
            "loss: 0.566284 [34000/60000]\n",
            "loss: 0.395348 [36000/60000]\n",
            "loss: 0.405696 [38000/60000]\n",
            "loss: 0.627854 [40000/60000]\n",
            "loss: 0.691475 [42000/60000]\n",
            "loss: 0.299231 [44000/60000]\n",
            "loss: 0.496220 [46000/60000]\n",
            "loss: 0.430324 [48000/60000]\n",
            "loss: 0.448817 [50000/60000]\n",
            "loss: 0.173935 [52000/60000]\n",
            "loss: 0.451536 [54000/60000]\n",
            "loss: 0.274538 [56000/60000]\n",
            "loss: 0.507831 [58000/60000]\n",
            "Avg Training Loss: 0.416835\n",
            "Test Error: \n",
            " Accuracy: 84.2%, Avg loss: 0.448837\n",
            "\n",
            "Epoch 28\n",
            "----------------------------------\n",
            "loss: 0.359347 [    0/60000]\n",
            "loss: 0.448981 [ 2000/60000]\n",
            "loss: 0.135687 [ 4000/60000]\n",
            "loss: 0.426145 [ 6000/60000]\n",
            "loss: 0.457692 [ 8000/60000]\n",
            "loss: 0.271195 [10000/60000]\n",
            "loss: 0.401723 [12000/60000]\n",
            "loss: 0.328701 [14000/60000]\n",
            "loss: 0.633197 [16000/60000]\n",
            "loss: 0.881134 [18000/60000]\n",
            "loss: 0.235559 [20000/60000]\n",
            "loss: 0.589680 [22000/60000]\n",
            "loss: 0.501143 [24000/60000]\n",
            "loss: 0.350246 [26000/60000]\n",
            "loss: 0.635431 [28000/60000]\n",
            "loss: 0.261703 [30000/60000]\n",
            "loss: 0.444888 [32000/60000]\n",
            "loss: 0.560865 [34000/60000]\n",
            "loss: 0.391950 [36000/60000]\n",
            "loss: 0.401292 [38000/60000]\n",
            "loss: 0.626721 [40000/60000]\n",
            "loss: 0.693533 [42000/60000]\n",
            "loss: 0.297671 [44000/60000]\n",
            "loss: 0.489965 [46000/60000]\n",
            "loss: 0.428109 [48000/60000]\n",
            "loss: 0.451729 [50000/60000]\n",
            "loss: 0.171016 [52000/60000]\n",
            "loss: 0.445088 [54000/60000]\n",
            "loss: 0.267874 [56000/60000]\n",
            "loss: 0.503476 [58000/60000]\n",
            "Avg Training Loss: 0.413586\n",
            "Test Error: \n",
            " Accuracy: 84.3%, Avg loss: 0.446043\n",
            "\n",
            "Epoch 29\n",
            "----------------------------------\n",
            "loss: 0.354674 [    0/60000]\n",
            "loss: 0.446109 [ 2000/60000]\n",
            "loss: 0.134262 [ 4000/60000]\n",
            "loss: 0.423433 [ 6000/60000]\n",
            "loss: 0.459392 [ 8000/60000]\n",
            "loss: 0.268630 [10000/60000]\n",
            "loss: 0.397856 [12000/60000]\n",
            "loss: 0.328453 [14000/60000]\n",
            "loss: 0.633409 [16000/60000]\n",
            "loss: 0.877907 [18000/60000]\n",
            "loss: 0.231083 [20000/60000]\n",
            "loss: 0.593004 [22000/60000]\n",
            "loss: 0.497379 [24000/60000]\n",
            "loss: 0.345849 [26000/60000]\n",
            "loss: 0.633918 [28000/60000]\n",
            "loss: 0.256204 [30000/60000]\n",
            "loss: 0.445350 [32000/60000]\n",
            "loss: 0.555751 [34000/60000]\n",
            "loss: 0.388479 [36000/60000]\n",
            "loss: 0.397094 [38000/60000]\n",
            "loss: 0.625818 [40000/60000]\n",
            "loss: 0.695895 [42000/60000]\n",
            "loss: 0.296090 [44000/60000]\n",
            "loss: 0.483946 [46000/60000]\n",
            "loss: 0.426072 [48000/60000]\n",
            "loss: 0.454313 [50000/60000]\n",
            "loss: 0.168276 [52000/60000]\n",
            "loss: 0.438435 [54000/60000]\n",
            "loss: 0.262134 [56000/60000]\n",
            "loss: 0.499292 [58000/60000]\n",
            "Avg Training Loss: 0.410468\n",
            "Test Error: \n",
            " Accuracy: 84.4%, Avg loss: 0.443396\n",
            "\n",
            "Epoch 30\n",
            "----------------------------------\n",
            "loss: 0.350211 [    0/60000]\n",
            "loss: 0.443240 [ 2000/60000]\n",
            "loss: 0.133013 [ 4000/60000]\n",
            "loss: 0.420401 [ 6000/60000]\n",
            "loss: 0.461297 [ 8000/60000]\n",
            "loss: 0.266004 [10000/60000]\n",
            "loss: 0.394242 [12000/60000]\n",
            "loss: 0.328257 [14000/60000]\n",
            "loss: 0.633448 [16000/60000]\n",
            "loss: 0.873981 [18000/60000]\n",
            "loss: 0.226912 [20000/60000]\n",
            "loss: 0.596492 [22000/60000]\n",
            "loss: 0.493707 [24000/60000]\n",
            "loss: 0.341732 [26000/60000]\n",
            "loss: 0.632467 [28000/60000]\n",
            "loss: 0.250733 [30000/60000]\n",
            "loss: 0.446073 [32000/60000]\n",
            "loss: 0.550741 [34000/60000]\n",
            "loss: 0.385039 [36000/60000]\n",
            "loss: 0.393627 [38000/60000]\n",
            "loss: 0.625406 [40000/60000]\n",
            "loss: 0.697714 [42000/60000]\n",
            "loss: 0.294477 [44000/60000]\n",
            "loss: 0.478350 [46000/60000]\n",
            "loss: 0.424231 [48000/60000]\n",
            "loss: 0.456742 [50000/60000]\n",
            "loss: 0.165491 [52000/60000]\n",
            "loss: 0.432993 [54000/60000]\n",
            "loss: 0.256865 [56000/60000]\n",
            "loss: 0.495167 [58000/60000]\n",
            "Avg Training Loss: 0.407470\n",
            "Test Error: \n",
            " Accuracy: 84.4%, Avg loss: 0.440825\n",
            "\n",
            "Epoch 31\n",
            "----------------------------------\n",
            "loss: 0.346211 [    0/60000]\n",
            "loss: 0.440532 [ 2000/60000]\n",
            "loss: 0.131805 [ 4000/60000]\n",
            "loss: 0.417916 [ 6000/60000]\n",
            "loss: 0.463235 [ 8000/60000]\n",
            "loss: 0.263644 [10000/60000]\n",
            "loss: 0.390182 [12000/60000]\n",
            "loss: 0.328368 [14000/60000]\n",
            "loss: 0.633522 [16000/60000]\n",
            "loss: 0.870843 [18000/60000]\n",
            "loss: 0.222956 [20000/60000]\n",
            "loss: 0.598510 [22000/60000]\n",
            "loss: 0.490094 [24000/60000]\n",
            "loss: 0.337765 [26000/60000]\n",
            "loss: 0.631123 [28000/60000]\n",
            "loss: 0.245849 [30000/60000]\n",
            "loss: 0.446513 [32000/60000]\n",
            "loss: 0.545965 [34000/60000]\n",
            "loss: 0.381523 [36000/60000]\n",
            "loss: 0.390231 [38000/60000]\n",
            "loss: 0.624960 [40000/60000]\n",
            "loss: 0.700069 [42000/60000]\n",
            "loss: 0.292731 [44000/60000]\n",
            "loss: 0.472986 [46000/60000]\n",
            "loss: 0.422033 [48000/60000]\n",
            "loss: 0.459210 [50000/60000]\n",
            "loss: 0.163060 [52000/60000]\n",
            "loss: 0.427666 [54000/60000]\n",
            "loss: 0.252103 [56000/60000]\n",
            "loss: 0.490671 [58000/60000]\n",
            "Avg Training Loss: 0.404565\n",
            "Test Error: \n",
            " Accuracy: 84.5%, Avg loss: 0.438355\n",
            "\n",
            "Epoch 32\n",
            "----------------------------------\n",
            "loss: 0.342503 [    0/60000]\n",
            "loss: 0.438182 [ 2000/60000]\n",
            "loss: 0.130787 [ 4000/60000]\n",
            "loss: 0.415454 [ 6000/60000]\n",
            "loss: 0.464810 [ 8000/60000]\n",
            "loss: 0.261287 [10000/60000]\n",
            "loss: 0.386708 [12000/60000]\n",
            "loss: 0.328927 [14000/60000]\n",
            "loss: 0.633666 [16000/60000]\n",
            "loss: 0.867967 [18000/60000]\n",
            "loss: 0.219298 [20000/60000]\n",
            "loss: 0.599530 [22000/60000]\n",
            "loss: 0.486664 [24000/60000]\n",
            "loss: 0.333548 [26000/60000]\n",
            "loss: 0.629673 [28000/60000]\n",
            "loss: 0.240764 [30000/60000]\n",
            "loss: 0.446643 [32000/60000]\n",
            "loss: 0.541571 [34000/60000]\n",
            "loss: 0.377920 [36000/60000]\n",
            "loss: 0.386954 [38000/60000]\n",
            "loss: 0.624057 [40000/60000]\n",
            "loss: 0.702695 [42000/60000]\n",
            "loss: 0.290871 [44000/60000]\n",
            "loss: 0.467498 [46000/60000]\n",
            "loss: 0.420146 [48000/60000]\n",
            "loss: 0.461628 [50000/60000]\n",
            "loss: 0.160674 [52000/60000]\n",
            "loss: 0.422551 [54000/60000]\n",
            "loss: 0.247838 [56000/60000]\n",
            "loss: 0.486548 [58000/60000]\n",
            "Avg Training Loss: 0.401741\n",
            "Test Error: \n",
            " Accuracy: 84.6%, Avg loss: 0.435949\n",
            "\n",
            "Epoch 33\n",
            "----------------------------------\n",
            "loss: 0.339386 [    0/60000]\n",
            "loss: 0.435844 [ 2000/60000]\n",
            "loss: 0.129836 [ 4000/60000]\n",
            "loss: 0.413418 [ 6000/60000]\n",
            "loss: 0.467342 [ 8000/60000]\n",
            "loss: 0.259113 [10000/60000]\n",
            "loss: 0.383026 [12000/60000]\n",
            "loss: 0.329288 [14000/60000]\n",
            "loss: 0.633892 [16000/60000]\n",
            "loss: 0.864632 [18000/60000]\n",
            "loss: 0.215611 [20000/60000]\n",
            "loss: 0.599809 [22000/60000]\n",
            "loss: 0.483158 [24000/60000]\n",
            "loss: 0.329751 [26000/60000]\n",
            "loss: 0.628673 [28000/60000]\n",
            "loss: 0.235674 [30000/60000]\n",
            "loss: 0.446963 [32000/60000]\n",
            "loss: 0.537675 [34000/60000]\n",
            "loss: 0.374267 [36000/60000]\n",
            "loss: 0.383705 [38000/60000]\n",
            "loss: 0.623617 [40000/60000]\n",
            "loss: 0.704767 [42000/60000]\n",
            "loss: 0.289316 [44000/60000]\n",
            "loss: 0.462260 [46000/60000]\n",
            "loss: 0.418534 [48000/60000]\n",
            "loss: 0.463863 [50000/60000]\n",
            "loss: 0.158533 [52000/60000]\n",
            "loss: 0.417702 [54000/60000]\n",
            "loss: 0.243729 [56000/60000]\n",
            "loss: 0.482336 [58000/60000]\n",
            "Avg Training Loss: 0.398998\n",
            "Test Error: \n",
            " Accuracy: 84.6%, Avg loss: 0.433618\n",
            "\n",
            "Epoch 34\n",
            "----------------------------------\n",
            "loss: 0.336766 [    0/60000]\n",
            "loss: 0.433341 [ 2000/60000]\n",
            "loss: 0.128939 [ 4000/60000]\n",
            "loss: 0.411362 [ 6000/60000]\n",
            "loss: 0.469491 [ 8000/60000]\n",
            "loss: 0.256912 [10000/60000]\n",
            "loss: 0.380034 [12000/60000]\n",
            "loss: 0.329945 [14000/60000]\n",
            "loss: 0.634257 [16000/60000]\n",
            "loss: 0.861381 [18000/60000]\n",
            "loss: 0.212361 [20000/60000]\n",
            "loss: 0.601041 [22000/60000]\n",
            "loss: 0.479771 [24000/60000]\n",
            "loss: 0.325970 [26000/60000]\n",
            "loss: 0.627538 [28000/60000]\n",
            "loss: 0.230827 [30000/60000]\n",
            "loss: 0.447279 [32000/60000]\n",
            "loss: 0.534368 [34000/60000]\n",
            "loss: 0.371233 [36000/60000]\n",
            "loss: 0.380529 [38000/60000]\n",
            "loss: 0.622966 [40000/60000]\n",
            "loss: 0.706979 [42000/60000]\n",
            "loss: 0.287685 [44000/60000]\n",
            "loss: 0.457753 [46000/60000]\n",
            "loss: 0.416600 [48000/60000]\n",
            "loss: 0.465960 [50000/60000]\n",
            "loss: 0.156315 [52000/60000]\n",
            "loss: 0.412367 [54000/60000]\n",
            "loss: 0.240121 [56000/60000]\n",
            "loss: 0.477999 [58000/60000]\n",
            "Avg Training Loss: 0.396337\n",
            "Test Error: \n",
            " Accuracy: 84.7%, Avg loss: 0.431407\n",
            "\n",
            "Epoch 35\n",
            "----------------------------------\n",
            "loss: 0.334350 [    0/60000]\n",
            "loss: 0.430410 [ 2000/60000]\n",
            "loss: 0.128218 [ 4000/60000]\n",
            "loss: 0.409682 [ 6000/60000]\n",
            "loss: 0.471347 [ 8000/60000]\n",
            "loss: 0.254971 [10000/60000]\n",
            "loss: 0.376884 [12000/60000]\n",
            "loss: 0.330510 [14000/60000]\n",
            "loss: 0.634976 [16000/60000]\n",
            "loss: 0.858460 [18000/60000]\n",
            "loss: 0.208762 [20000/60000]\n",
            "loss: 0.601172 [22000/60000]\n",
            "loss: 0.476591 [24000/60000]\n",
            "loss: 0.322558 [26000/60000]\n",
            "loss: 0.626538 [28000/60000]\n",
            "loss: 0.226475 [30000/60000]\n",
            "loss: 0.446678 [32000/60000]\n",
            "loss: 0.531169 [34000/60000]\n",
            "loss: 0.367961 [36000/60000]\n",
            "loss: 0.377643 [38000/60000]\n",
            "loss: 0.622782 [40000/60000]\n",
            "loss: 0.709172 [42000/60000]\n",
            "loss: 0.286281 [44000/60000]\n",
            "loss: 0.452861 [46000/60000]\n",
            "loss: 0.414640 [48000/60000]\n",
            "loss: 0.468371 [50000/60000]\n",
            "loss: 0.154061 [52000/60000]\n",
            "loss: 0.407509 [54000/60000]\n",
            "loss: 0.236681 [56000/60000]\n",
            "loss: 0.473820 [58000/60000]\n",
            "Avg Training Loss: 0.393759\n",
            "Test Error: \n",
            " Accuracy: 84.8%, Avg loss: 0.429276\n",
            "\n",
            "Epoch 36\n",
            "----------------------------------\n",
            "loss: 0.332216 [    0/60000]\n",
            "loss: 0.427774 [ 2000/60000]\n",
            "loss: 0.127575 [ 4000/60000]\n",
            "loss: 0.407974 [ 6000/60000]\n",
            "loss: 0.473019 [ 8000/60000]\n",
            "loss: 0.253064 [10000/60000]\n",
            "loss: 0.374196 [12000/60000]\n",
            "loss: 0.331614 [14000/60000]\n",
            "loss: 0.635489 [16000/60000]\n",
            "loss: 0.855654 [18000/60000]\n",
            "loss: 0.205709 [20000/60000]\n",
            "loss: 0.601203 [22000/60000]\n",
            "loss: 0.473919 [24000/60000]\n",
            "loss: 0.318990 [26000/60000]\n",
            "loss: 0.625511 [28000/60000]\n",
            "loss: 0.222188 [30000/60000]\n",
            "loss: 0.445995 [32000/60000]\n",
            "loss: 0.527641 [34000/60000]\n",
            "loss: 0.364668 [36000/60000]\n",
            "loss: 0.374885 [38000/60000]\n",
            "loss: 0.622743 [40000/60000]\n",
            "loss: 0.711644 [42000/60000]\n",
            "loss: 0.284790 [44000/60000]\n",
            "loss: 0.448361 [46000/60000]\n",
            "loss: 0.412563 [48000/60000]\n",
            "loss: 0.470767 [50000/60000]\n",
            "loss: 0.152290 [52000/60000]\n",
            "loss: 0.403431 [54000/60000]\n",
            "loss: 0.233263 [56000/60000]\n",
            "loss: 0.469686 [58000/60000]\n",
            "Avg Training Loss: 0.391258\n",
            "Test Error: \n",
            " Accuracy: 84.9%, Avg loss: 0.427171\n",
            "\n",
            "Epoch 37\n",
            "----------------------------------\n",
            "loss: 0.330069 [    0/60000]\n",
            "loss: 0.425516 [ 2000/60000]\n",
            "loss: 0.126975 [ 4000/60000]\n",
            "loss: 0.406554 [ 6000/60000]\n",
            "loss: 0.475068 [ 8000/60000]\n",
            "loss: 0.251084 [10000/60000]\n",
            "loss: 0.371671 [12000/60000]\n",
            "loss: 0.332526 [14000/60000]\n",
            "loss: 0.635925 [16000/60000]\n",
            "loss: 0.853116 [18000/60000]\n",
            "loss: 0.202619 [20000/60000]\n",
            "loss: 0.600678 [22000/60000]\n",
            "loss: 0.470820 [24000/60000]\n",
            "loss: 0.315429 [26000/60000]\n",
            "loss: 0.624773 [28000/60000]\n",
            "loss: 0.218192 [30000/60000]\n",
            "loss: 0.445206 [32000/60000]\n",
            "loss: 0.524457 [34000/60000]\n",
            "loss: 0.361247 [36000/60000]\n",
            "loss: 0.372303 [38000/60000]\n",
            "loss: 0.622615 [40000/60000]\n",
            "loss: 0.713480 [42000/60000]\n",
            "loss: 0.283334 [44000/60000]\n",
            "loss: 0.444776 [46000/60000]\n",
            "loss: 0.410608 [48000/60000]\n",
            "loss: 0.472940 [50000/60000]\n",
            "loss: 0.150590 [52000/60000]\n",
            "loss: 0.398991 [54000/60000]\n",
            "loss: 0.230149 [56000/60000]\n",
            "loss: 0.465674 [58000/60000]\n",
            "Avg Training Loss: 0.388828\n",
            "Test Error: \n",
            " Accuracy: 85.0%, Avg loss: 0.425150\n",
            "\n",
            "Epoch 38\n",
            "----------------------------------\n",
            "loss: 0.328521 [    0/60000]\n",
            "loss: 0.423244 [ 2000/60000]\n",
            "loss: 0.126557 [ 4000/60000]\n",
            "loss: 0.405500 [ 6000/60000]\n",
            "loss: 0.476247 [ 8000/60000]\n",
            "loss: 0.248978 [10000/60000]\n",
            "loss: 0.368729 [12000/60000]\n",
            "loss: 0.333444 [14000/60000]\n",
            "loss: 0.636728 [16000/60000]\n",
            "loss: 0.850981 [18000/60000]\n",
            "loss: 0.199744 [20000/60000]\n",
            "loss: 0.599593 [22000/60000]\n",
            "loss: 0.467360 [24000/60000]\n",
            "loss: 0.312070 [26000/60000]\n",
            "loss: 0.623647 [28000/60000]\n",
            "loss: 0.214604 [30000/60000]\n",
            "loss: 0.443615 [32000/60000]\n",
            "loss: 0.521672 [34000/60000]\n",
            "loss: 0.357656 [36000/60000]\n",
            "loss: 0.370288 [38000/60000]\n",
            "loss: 0.622309 [40000/60000]\n",
            "loss: 0.715057 [42000/60000]\n",
            "loss: 0.281832 [44000/60000]\n",
            "loss: 0.440766 [46000/60000]\n",
            "loss: 0.408989 [48000/60000]\n",
            "loss: 0.475442 [50000/60000]\n",
            "loss: 0.148611 [52000/60000]\n",
            "loss: 0.395414 [54000/60000]\n",
            "loss: 0.227399 [56000/60000]\n",
            "loss: 0.461224 [58000/60000]\n",
            "Avg Training Loss: 0.386460\n",
            "Test Error: \n",
            " Accuracy: 85.1%, Avg loss: 0.423182\n",
            "\n",
            "Epoch 39\n",
            "----------------------------------\n",
            "loss: 0.327041 [    0/60000]\n",
            "loss: 0.421156 [ 2000/60000]\n",
            "loss: 0.126095 [ 4000/60000]\n",
            "loss: 0.404416 [ 6000/60000]\n",
            "loss: 0.477585 [ 8000/60000]\n",
            "loss: 0.247167 [10000/60000]\n",
            "loss: 0.365625 [12000/60000]\n",
            "loss: 0.334068 [14000/60000]\n",
            "loss: 0.638195 [16000/60000]\n",
            "loss: 0.848817 [18000/60000]\n",
            "loss: 0.197046 [20000/60000]\n",
            "loss: 0.598790 [22000/60000]\n",
            "loss: 0.463810 [24000/60000]\n",
            "loss: 0.308788 [26000/60000]\n",
            "loss: 0.622235 [28000/60000]\n",
            "loss: 0.210818 [30000/60000]\n",
            "loss: 0.441509 [32000/60000]\n",
            "loss: 0.518308 [34000/60000]\n",
            "loss: 0.354427 [36000/60000]\n",
            "loss: 0.368136 [38000/60000]\n",
            "loss: 0.622213 [40000/60000]\n",
            "loss: 0.717314 [42000/60000]\n",
            "loss: 0.280170 [44000/60000]\n",
            "loss: 0.436569 [46000/60000]\n",
            "loss: 0.407364 [48000/60000]\n",
            "loss: 0.477981 [50000/60000]\n",
            "loss: 0.146595 [52000/60000]\n",
            "loss: 0.391944 [54000/60000]\n",
            "loss: 0.224846 [56000/60000]\n",
            "loss: 0.457223 [58000/60000]\n",
            "Avg Training Loss: 0.384156\n",
            "Test Error: \n",
            " Accuracy: 85.2%, Avg loss: 0.421311\n",
            "\n",
            "Epoch 40\n",
            "----------------------------------\n",
            "loss: 0.325617 [    0/60000]\n",
            "loss: 0.418935 [ 2000/60000]\n",
            "loss: 0.125590 [ 4000/60000]\n",
            "loss: 0.403668 [ 6000/60000]\n",
            "loss: 0.478634 [ 8000/60000]\n",
            "loss: 0.245459 [10000/60000]\n",
            "loss: 0.362316 [12000/60000]\n",
            "loss: 0.335242 [14000/60000]\n",
            "loss: 0.638796 [16000/60000]\n",
            "loss: 0.846809 [18000/60000]\n",
            "loss: 0.194298 [20000/60000]\n",
            "loss: 0.598857 [22000/60000]\n",
            "loss: 0.460533 [24000/60000]\n",
            "loss: 0.305391 [26000/60000]\n",
            "loss: 0.620982 [28000/60000]\n",
            "loss: 0.206763 [30000/60000]\n",
            "loss: 0.439398 [32000/60000]\n",
            "loss: 0.515343 [34000/60000]\n",
            "loss: 0.351092 [36000/60000]\n",
            "loss: 0.366314 [38000/60000]\n",
            "loss: 0.622343 [40000/60000]\n",
            "loss: 0.719401 [42000/60000]\n",
            "loss: 0.278617 [44000/60000]\n",
            "loss: 0.432815 [46000/60000]\n",
            "loss: 0.405566 [48000/60000]\n",
            "loss: 0.480552 [50000/60000]\n",
            "loss: 0.144703 [52000/60000]\n",
            "loss: 0.389303 [54000/60000]\n",
            "loss: 0.222464 [56000/60000]\n",
            "loss: 0.453355 [58000/60000]\n",
            "Avg Training Loss: 0.381916\n",
            "Test Error: \n",
            " Accuracy: 85.2%, Avg loss: 0.419436\n",
            "\n",
            "Epoch 41\n",
            "----------------------------------\n",
            "loss: 0.324242 [    0/60000]\n",
            "loss: 0.416854 [ 2000/60000]\n",
            "loss: 0.125153 [ 4000/60000]\n",
            "loss: 0.403104 [ 6000/60000]\n",
            "loss: 0.479772 [ 8000/60000]\n",
            "loss: 0.243942 [10000/60000]\n",
            "loss: 0.359319 [12000/60000]\n",
            "loss: 0.336121 [14000/60000]\n",
            "loss: 0.639713 [16000/60000]\n",
            "loss: 0.844382 [18000/60000]\n",
            "loss: 0.191521 [20000/60000]\n",
            "loss: 0.597741 [22000/60000]\n",
            "loss: 0.457369 [24000/60000]\n",
            "loss: 0.302276 [26000/60000]\n",
            "loss: 0.619919 [28000/60000]\n",
            "loss: 0.203505 [30000/60000]\n",
            "loss: 0.436420 [32000/60000]\n",
            "loss: 0.512952 [34000/60000]\n",
            "loss: 0.348064 [36000/60000]\n",
            "loss: 0.364441 [38000/60000]\n",
            "loss: 0.622680 [40000/60000]\n",
            "loss: 0.721019 [42000/60000]\n",
            "loss: 0.277066 [44000/60000]\n",
            "loss: 0.429438 [46000/60000]\n",
            "loss: 0.403520 [48000/60000]\n",
            "loss: 0.483339 [50000/60000]\n",
            "loss: 0.143111 [52000/60000]\n",
            "loss: 0.386496 [54000/60000]\n",
            "loss: 0.220015 [56000/60000]\n",
            "loss: 0.449404 [58000/60000]\n",
            "Avg Training Loss: 0.379731\n",
            "Test Error: \n",
            " Accuracy: 85.4%, Avg loss: 0.417677\n",
            "\n",
            "Epoch 42\n",
            "----------------------------------\n",
            "loss: 0.323027 [    0/60000]\n",
            "loss: 0.414987 [ 2000/60000]\n",
            "loss: 0.124654 [ 4000/60000]\n",
            "loss: 0.402641 [ 6000/60000]\n",
            "loss: 0.481134 [ 8000/60000]\n",
            "loss: 0.242429 [10000/60000]\n",
            "loss: 0.356296 [12000/60000]\n",
            "loss: 0.336996 [14000/60000]\n",
            "loss: 0.640598 [16000/60000]\n",
            "loss: 0.841948 [18000/60000]\n",
            "loss: 0.188976 [20000/60000]\n",
            "loss: 0.597093 [22000/60000]\n",
            "loss: 0.454559 [24000/60000]\n",
            "loss: 0.299256 [26000/60000]\n",
            "loss: 0.618771 [28000/60000]\n",
            "loss: 0.200126 [30000/60000]\n",
            "loss: 0.433293 [32000/60000]\n",
            "loss: 0.510674 [34000/60000]\n",
            "loss: 0.345070 [36000/60000]\n",
            "loss: 0.362409 [38000/60000]\n",
            "loss: 0.623113 [40000/60000]\n",
            "loss: 0.723177 [42000/60000]\n",
            "loss: 0.275589 [44000/60000]\n",
            "loss: 0.425739 [46000/60000]\n",
            "loss: 0.401113 [48000/60000]\n",
            "loss: 0.486031 [50000/60000]\n",
            "loss: 0.141418 [52000/60000]\n",
            "loss: 0.383645 [54000/60000]\n",
            "loss: 0.217783 [56000/60000]\n",
            "loss: 0.445895 [58000/60000]\n",
            "Avg Training Loss: 0.377599\n",
            "Test Error: \n",
            " Accuracy: 85.5%, Avg loss: 0.415963\n",
            "\n",
            "Epoch 43\n",
            "----------------------------------\n",
            "loss: 0.322015 [    0/60000]\n",
            "loss: 0.413031 [ 2000/60000]\n",
            "loss: 0.124113 [ 4000/60000]\n",
            "loss: 0.402415 [ 6000/60000]\n",
            "loss: 0.481946 [ 8000/60000]\n",
            "loss: 0.240928 [10000/60000]\n",
            "loss: 0.353050 [12000/60000]\n",
            "loss: 0.338017 [14000/60000]\n",
            "loss: 0.641428 [16000/60000]\n",
            "loss: 0.840137 [18000/60000]\n",
            "loss: 0.186837 [20000/60000]\n",
            "loss: 0.595837 [22000/60000]\n",
            "loss: 0.451936 [24000/60000]\n",
            "loss: 0.295969 [26000/60000]\n",
            "loss: 0.617629 [28000/60000]\n",
            "loss: 0.196992 [30000/60000]\n",
            "loss: 0.430178 [32000/60000]\n",
            "loss: 0.508097 [34000/60000]\n",
            "loss: 0.342231 [36000/60000]\n",
            "loss: 0.360906 [38000/60000]\n",
            "loss: 0.623734 [40000/60000]\n",
            "loss: 0.724842 [42000/60000]\n",
            "loss: 0.274251 [44000/60000]\n",
            "loss: 0.422497 [46000/60000]\n",
            "loss: 0.399113 [48000/60000]\n",
            "loss: 0.488371 [50000/60000]\n",
            "loss: 0.139595 [52000/60000]\n",
            "loss: 0.381062 [54000/60000]\n",
            "loss: 0.215730 [56000/60000]\n",
            "loss: 0.441993 [58000/60000]\n",
            "Avg Training Loss: 0.375522\n",
            "Test Error: \n",
            " Accuracy: 85.5%, Avg loss: 0.414290\n",
            "\n",
            "Epoch 44\n",
            "----------------------------------\n",
            "loss: 0.321028 [    0/60000]\n",
            "loss: 0.411185 [ 2000/60000]\n",
            "loss: 0.123608 [ 4000/60000]\n",
            "loss: 0.402443 [ 6000/60000]\n",
            "loss: 0.483234 [ 8000/60000]\n",
            "loss: 0.239341 [10000/60000]\n",
            "loss: 0.349991 [12000/60000]\n",
            "loss: 0.338542 [14000/60000]\n",
            "loss: 0.642540 [16000/60000]\n",
            "loss: 0.838206 [18000/60000]\n",
            "loss: 0.184474 [20000/60000]\n",
            "loss: 0.594553 [22000/60000]\n",
            "loss: 0.449551 [24000/60000]\n",
            "loss: 0.292972 [26000/60000]\n",
            "loss: 0.616104 [28000/60000]\n",
            "loss: 0.194261 [30000/60000]\n",
            "loss: 0.427200 [32000/60000]\n",
            "loss: 0.505433 [34000/60000]\n",
            "loss: 0.339522 [36000/60000]\n",
            "loss: 0.359764 [38000/60000]\n",
            "loss: 0.624045 [40000/60000]\n",
            "loss: 0.726363 [42000/60000]\n",
            "loss: 0.272673 [44000/60000]\n",
            "loss: 0.419293 [46000/60000]\n",
            "loss: 0.397327 [48000/60000]\n",
            "loss: 0.490809 [50000/60000]\n",
            "loss: 0.138000 [52000/60000]\n",
            "loss: 0.378427 [54000/60000]\n",
            "loss: 0.213709 [56000/60000]\n",
            "loss: 0.438430 [58000/60000]\n",
            "Avg Training Loss: 0.373491\n",
            "Test Error: \n",
            " Accuracy: 85.5%, Avg loss: 0.412698\n",
            "\n",
            "Epoch 45\n",
            "----------------------------------\n",
            "loss: 0.320243 [    0/60000]\n",
            "loss: 0.409744 [ 2000/60000]\n",
            "loss: 0.123056 [ 4000/60000]\n",
            "loss: 0.402720 [ 6000/60000]\n",
            "loss: 0.484819 [ 8000/60000]\n",
            "loss: 0.237956 [10000/60000]\n",
            "loss: 0.346870 [12000/60000]\n",
            "loss: 0.339146 [14000/60000]\n",
            "loss: 0.643424 [16000/60000]\n",
            "loss: 0.836020 [18000/60000]\n",
            "loss: 0.182147 [20000/60000]\n",
            "loss: 0.593808 [22000/60000]\n",
            "loss: 0.447440 [24000/60000]\n",
            "loss: 0.289870 [26000/60000]\n",
            "loss: 0.614927 [28000/60000]\n",
            "loss: 0.191547 [30000/60000]\n",
            "loss: 0.424387 [32000/60000]\n",
            "loss: 0.502885 [34000/60000]\n",
            "loss: 0.336925 [36000/60000]\n",
            "loss: 0.358381 [38000/60000]\n",
            "loss: 0.624545 [40000/60000]\n",
            "loss: 0.727880 [42000/60000]\n",
            "loss: 0.271225 [44000/60000]\n",
            "loss: 0.416234 [46000/60000]\n",
            "loss: 0.394930 [48000/60000]\n",
            "loss: 0.493368 [50000/60000]\n",
            "loss: 0.136324 [52000/60000]\n",
            "loss: 0.375684 [54000/60000]\n",
            "loss: 0.211651 [56000/60000]\n",
            "loss: 0.434813 [58000/60000]\n",
            "Avg Training Loss: 0.371511\n",
            "Test Error: \n",
            " Accuracy: 85.5%, Avg loss: 0.411121\n",
            "\n",
            "Epoch 46\n",
            "----------------------------------\n",
            "loss: 0.319297 [    0/60000]\n",
            "loss: 0.408402 [ 2000/60000]\n",
            "loss: 0.122624 [ 4000/60000]\n",
            "loss: 0.403385 [ 6000/60000]\n",
            "loss: 0.486310 [ 8000/60000]\n",
            "loss: 0.236568 [10000/60000]\n",
            "loss: 0.344180 [12000/60000]\n",
            "loss: 0.339999 [14000/60000]\n",
            "loss: 0.644459 [16000/60000]\n",
            "loss: 0.834073 [18000/60000]\n",
            "loss: 0.179960 [20000/60000]\n",
            "loss: 0.593029 [22000/60000]\n",
            "loss: 0.445085 [24000/60000]\n",
            "loss: 0.287626 [26000/60000]\n",
            "loss: 0.614019 [28000/60000]\n",
            "loss: 0.189045 [30000/60000]\n",
            "loss: 0.421382 [32000/60000]\n",
            "loss: 0.500362 [34000/60000]\n",
            "loss: 0.334351 [36000/60000]\n",
            "loss: 0.356535 [38000/60000]\n",
            "loss: 0.625035 [40000/60000]\n",
            "loss: 0.728697 [42000/60000]\n",
            "loss: 0.269925 [44000/60000]\n",
            "loss: 0.413613 [46000/60000]\n",
            "loss: 0.392614 [48000/60000]\n",
            "loss: 0.496090 [50000/60000]\n",
            "loss: 0.134721 [52000/60000]\n",
            "loss: 0.372795 [54000/60000]\n",
            "loss: 0.209719 [56000/60000]\n",
            "loss: 0.431268 [58000/60000]\n",
            "Avg Training Loss: 0.369575\n",
            "Test Error: \n",
            " Accuracy: 85.5%, Avg loss: 0.409592\n",
            "\n",
            "Epoch 47\n",
            "----------------------------------\n",
            "loss: 0.318544 [    0/60000]\n",
            "loss: 0.406906 [ 2000/60000]\n",
            "loss: 0.122238 [ 4000/60000]\n",
            "loss: 0.403786 [ 6000/60000]\n",
            "loss: 0.487483 [ 8000/60000]\n",
            "loss: 0.235140 [10000/60000]\n",
            "loss: 0.341267 [12000/60000]\n",
            "loss: 0.340891 [14000/60000]\n",
            "loss: 0.645550 [16000/60000]\n",
            "loss: 0.831828 [18000/60000]\n",
            "loss: 0.177903 [20000/60000]\n",
            "loss: 0.591863 [22000/60000]\n",
            "loss: 0.442843 [24000/60000]\n",
            "loss: 0.284864 [26000/60000]\n",
            "loss: 0.613009 [28000/60000]\n",
            "loss: 0.186732 [30000/60000]\n",
            "loss: 0.418583 [32000/60000]\n",
            "loss: 0.498009 [34000/60000]\n",
            "loss: 0.331852 [36000/60000]\n",
            "loss: 0.355392 [38000/60000]\n",
            "loss: 0.625324 [40000/60000]\n",
            "loss: 0.730353 [42000/60000]\n",
            "loss: 0.268315 [44000/60000]\n",
            "loss: 0.411271 [46000/60000]\n",
            "loss: 0.389898 [48000/60000]\n",
            "loss: 0.497963 [50000/60000]\n",
            "loss: 0.133278 [52000/60000]\n",
            "loss: 0.370781 [54000/60000]\n",
            "loss: 0.207997 [56000/60000]\n",
            "loss: 0.427651 [58000/60000]\n",
            "Avg Training Loss: 0.367677\n",
            "Test Error: \n",
            " Accuracy: 85.5%, Avg loss: 0.408063\n",
            "\n",
            "Epoch 48\n",
            "----------------------------------\n",
            "loss: 0.318094 [    0/60000]\n",
            "loss: 0.405665 [ 2000/60000]\n",
            "loss: 0.121706 [ 4000/60000]\n",
            "loss: 0.403840 [ 6000/60000]\n",
            "loss: 0.488613 [ 8000/60000]\n",
            "loss: 0.233714 [10000/60000]\n",
            "loss: 0.338522 [12000/60000]\n",
            "loss: 0.341314 [14000/60000]\n",
            "loss: 0.646606 [16000/60000]\n",
            "loss: 0.828968 [18000/60000]\n",
            "loss: 0.176048 [20000/60000]\n",
            "loss: 0.590303 [22000/60000]\n",
            "loss: 0.440991 [24000/60000]\n",
            "loss: 0.281624 [26000/60000]\n",
            "loss: 0.611824 [28000/60000]\n",
            "loss: 0.184147 [30000/60000]\n",
            "loss: 0.415799 [32000/60000]\n",
            "loss: 0.495349 [34000/60000]\n",
            "loss: 0.329701 [36000/60000]\n",
            "loss: 0.354171 [38000/60000]\n",
            "loss: 0.625466 [40000/60000]\n",
            "loss: 0.731861 [42000/60000]\n",
            "loss: 0.266711 [44000/60000]\n",
            "loss: 0.408822 [46000/60000]\n",
            "loss: 0.387838 [48000/60000]\n",
            "loss: 0.500274 [50000/60000]\n",
            "loss: 0.131640 [52000/60000]\n",
            "loss: 0.367783 [54000/60000]\n",
            "loss: 0.206300 [56000/60000]\n",
            "loss: 0.423861 [58000/60000]\n",
            "Avg Training Loss: 0.365797\n",
            "Test Error: \n",
            " Accuracy: 85.6%, Avg loss: 0.406558\n",
            "\n",
            "Epoch 49\n",
            "----------------------------------\n",
            "loss: 0.317628 [    0/60000]\n",
            "loss: 0.404986 [ 2000/60000]\n",
            "loss: 0.121325 [ 4000/60000]\n",
            "loss: 0.403883 [ 6000/60000]\n",
            "loss: 0.489123 [ 8000/60000]\n",
            "loss: 0.232187 [10000/60000]\n",
            "loss: 0.335547 [12000/60000]\n",
            "loss: 0.341980 [14000/60000]\n",
            "loss: 0.648006 [16000/60000]\n",
            "loss: 0.826392 [18000/60000]\n",
            "loss: 0.174336 [20000/60000]\n",
            "loss: 0.588317 [22000/60000]\n",
            "loss: 0.440088 [24000/60000]\n",
            "loss: 0.278598 [26000/60000]\n",
            "loss: 0.610723 [28000/60000]\n",
            "loss: 0.181963 [30000/60000]\n",
            "loss: 0.412831 [32000/60000]\n",
            "loss: 0.492626 [34000/60000]\n",
            "loss: 0.327544 [36000/60000]\n",
            "loss: 0.352761 [38000/60000]\n",
            "loss: 0.625648 [40000/60000]\n",
            "loss: 0.732966 [42000/60000]\n",
            "loss: 0.265191 [44000/60000]\n",
            "loss: 0.406564 [46000/60000]\n",
            "loss: 0.385451 [48000/60000]\n",
            "loss: 0.502592 [50000/60000]\n",
            "loss: 0.130215 [52000/60000]\n",
            "loss: 0.364264 [54000/60000]\n",
            "loss: 0.204537 [56000/60000]\n",
            "loss: 0.420260 [58000/60000]\n",
            "Avg Training Loss: 0.363952\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.405124\n",
            "\n",
            "Epoch 50\n",
            "----------------------------------\n",
            "loss: 0.316973 [    0/60000]\n",
            "loss: 0.404147 [ 2000/60000]\n",
            "loss: 0.120931 [ 4000/60000]\n",
            "loss: 0.403808 [ 6000/60000]\n",
            "loss: 0.490403 [ 8000/60000]\n",
            "loss: 0.230746 [10000/60000]\n",
            "loss: 0.332672 [12000/60000]\n",
            "loss: 0.342595 [14000/60000]\n",
            "loss: 0.648922 [16000/60000]\n",
            "loss: 0.823801 [18000/60000]\n",
            "loss: 0.172716 [20000/60000]\n",
            "loss: 0.586690 [22000/60000]\n",
            "loss: 0.439930 [24000/60000]\n",
            "loss: 0.275964 [26000/60000]\n",
            "loss: 0.609424 [28000/60000]\n",
            "loss: 0.180095 [30000/60000]\n",
            "loss: 0.410381 [32000/60000]\n",
            "loss: 0.490100 [34000/60000]\n",
            "loss: 0.325118 [36000/60000]\n",
            "loss: 0.351719 [38000/60000]\n",
            "loss: 0.625187 [40000/60000]\n",
            "loss: 0.734073 [42000/60000]\n",
            "loss: 0.263737 [44000/60000]\n",
            "loss: 0.404484 [46000/60000]\n",
            "loss: 0.383599 [48000/60000]\n",
            "loss: 0.504895 [50000/60000]\n",
            "loss: 0.128700 [52000/60000]\n",
            "loss: 0.361658 [54000/60000]\n",
            "loss: 0.203126 [56000/60000]\n",
            "loss: 0.416549 [58000/60000]\n",
            "Avg Training Loss: 0.362158\n",
            "Test Error: \n",
            " Accuracy: 85.8%, Avg loss: 0.403714\n",
            "\n",
            "Epoch 51\n",
            "----------------------------------\n",
            "loss: 0.316834 [    0/60000]\n",
            "loss: 0.403167 [ 2000/60000]\n",
            "loss: 0.120317 [ 4000/60000]\n",
            "loss: 0.404293 [ 6000/60000]\n",
            "loss: 0.491531 [ 8000/60000]\n",
            "loss: 0.229224 [10000/60000]\n",
            "loss: 0.329663 [12000/60000]\n",
            "loss: 0.343076 [14000/60000]\n",
            "loss: 0.650310 [16000/60000]\n",
            "loss: 0.821080 [18000/60000]\n",
            "loss: 0.170925 [20000/60000]\n",
            "loss: 0.584719 [22000/60000]\n",
            "loss: 0.439481 [24000/60000]\n",
            "loss: 0.273295 [26000/60000]\n",
            "loss: 0.608462 [28000/60000]\n",
            "loss: 0.177939 [30000/60000]\n",
            "loss: 0.407541 [32000/60000]\n",
            "loss: 0.487858 [34000/60000]\n",
            "loss: 0.322896 [36000/60000]\n",
            "loss: 0.350468 [38000/60000]\n",
            "loss: 0.625027 [40000/60000]\n",
            "loss: 0.734417 [42000/60000]\n",
            "loss: 0.262206 [44000/60000]\n",
            "loss: 0.401929 [46000/60000]\n",
            "loss: 0.381769 [48000/60000]\n",
            "loss: 0.506930 [50000/60000]\n",
            "loss: 0.127154 [52000/60000]\n",
            "loss: 0.359186 [54000/60000]\n",
            "loss: 0.201500 [56000/60000]\n",
            "loss: 0.413459 [58000/60000]\n",
            "Avg Training Loss: 0.360392\n",
            "Test Error: \n",
            " Accuracy: 85.8%, Avg loss: 0.402380\n",
            "\n",
            "Epoch 52\n",
            "----------------------------------\n",
            "loss: 0.316475 [    0/60000]\n",
            "loss: 0.402069 [ 2000/60000]\n",
            "loss: 0.119947 [ 4000/60000]\n",
            "loss: 0.403602 [ 6000/60000]\n",
            "loss: 0.492769 [ 8000/60000]\n",
            "loss: 0.227868 [10000/60000]\n",
            "loss: 0.326949 [12000/60000]\n",
            "loss: 0.343704 [14000/60000]\n",
            "loss: 0.651722 [16000/60000]\n",
            "loss: 0.817888 [18000/60000]\n",
            "loss: 0.169110 [20000/60000]\n",
            "loss: 0.582768 [22000/60000]\n",
            "loss: 0.439123 [24000/60000]\n",
            "loss: 0.271089 [26000/60000]\n",
            "loss: 0.607108 [28000/60000]\n",
            "loss: 0.176365 [30000/60000]\n",
            "loss: 0.404506 [32000/60000]\n",
            "loss: 0.485555 [34000/60000]\n",
            "loss: 0.320946 [36000/60000]\n",
            "loss: 0.349496 [38000/60000]\n",
            "loss: 0.625342 [40000/60000]\n",
            "loss: 0.735233 [42000/60000]\n",
            "loss: 0.260665 [44000/60000]\n",
            "loss: 0.399513 [46000/60000]\n",
            "loss: 0.379765 [48000/60000]\n",
            "loss: 0.508405 [50000/60000]\n",
            "loss: 0.125969 [52000/60000]\n",
            "loss: 0.356410 [54000/60000]\n",
            "loss: 0.199817 [56000/60000]\n",
            "loss: 0.410567 [58000/60000]\n",
            "Avg Training Loss: 0.358653\n",
            "Test Error: \n",
            " Accuracy: 85.9%, Avg loss: 0.401021\n",
            "\n",
            "Epoch 53\n",
            "----------------------------------\n",
            "loss: 0.316275 [    0/60000]\n",
            "loss: 0.401506 [ 2000/60000]\n",
            "loss: 0.119427 [ 4000/60000]\n",
            "loss: 0.403790 [ 6000/60000]\n",
            "loss: 0.493862 [ 8000/60000]\n",
            "loss: 0.226531 [10000/60000]\n",
            "loss: 0.324882 [12000/60000]\n",
            "loss: 0.344771 [14000/60000]\n",
            "loss: 0.652608 [16000/60000]\n",
            "loss: 0.815223 [18000/60000]\n",
            "loss: 0.167672 [20000/60000]\n",
            "loss: 0.580219 [22000/60000]\n",
            "loss: 0.438688 [24000/60000]\n",
            "loss: 0.269092 [26000/60000]\n",
            "loss: 0.606439 [28000/60000]\n",
            "loss: 0.175008 [30000/60000]\n",
            "loss: 0.401537 [32000/60000]\n",
            "loss: 0.483352 [34000/60000]\n",
            "loss: 0.318686 [36000/60000]\n",
            "loss: 0.348033 [38000/60000]\n",
            "loss: 0.625550 [40000/60000]\n",
            "loss: 0.735465 [42000/60000]\n",
            "loss: 0.258829 [44000/60000]\n",
            "loss: 0.397330 [46000/60000]\n",
            "loss: 0.378333 [48000/60000]\n",
            "loss: 0.509887 [50000/60000]\n",
            "loss: 0.124765 [52000/60000]\n",
            "loss: 0.354085 [54000/60000]\n",
            "loss: 0.198362 [56000/60000]\n",
            "loss: 0.407494 [58000/60000]\n",
            "Avg Training Loss: 0.356929\n",
            "Test Error: \n",
            " Accuracy: 85.9%, Avg loss: 0.399728\n",
            "\n",
            "Epoch 54\n",
            "----------------------------------\n",
            "loss: 0.316045 [    0/60000]\n",
            "loss: 0.400618 [ 2000/60000]\n",
            "loss: 0.118890 [ 4000/60000]\n",
            "loss: 0.403842 [ 6000/60000]\n",
            "loss: 0.494655 [ 8000/60000]\n",
            "loss: 0.224778 [10000/60000]\n",
            "loss: 0.322130 [12000/60000]\n",
            "loss: 0.345314 [14000/60000]\n",
            "loss: 0.653020 [16000/60000]\n",
            "loss: 0.811742 [18000/60000]\n",
            "loss: 0.165958 [20000/60000]\n",
            "loss: 0.578728 [22000/60000]\n",
            "loss: 0.438230 [24000/60000]\n",
            "loss: 0.267060 [26000/60000]\n",
            "loss: 0.605241 [28000/60000]\n",
            "loss: 0.173139 [30000/60000]\n",
            "loss: 0.398991 [32000/60000]\n",
            "loss: 0.481643 [34000/60000]\n",
            "loss: 0.316318 [36000/60000]\n",
            "loss: 0.347031 [38000/60000]\n",
            "loss: 0.626056 [40000/60000]\n",
            "loss: 0.735884 [42000/60000]\n",
            "loss: 0.257112 [44000/60000]\n",
            "loss: 0.395451 [46000/60000]\n",
            "loss: 0.376799 [48000/60000]\n",
            "loss: 0.512343 [50000/60000]\n",
            "loss: 0.123414 [52000/60000]\n",
            "loss: 0.351830 [54000/60000]\n",
            "loss: 0.196637 [56000/60000]\n",
            "loss: 0.403508 [58000/60000]\n",
            "Avg Training Loss: 0.355241\n",
            "Test Error: \n",
            " Accuracy: 86.0%, Avg loss: 0.398477\n",
            "\n",
            "Epoch 55\n",
            "----------------------------------\n",
            "loss: 0.315514 [    0/60000]\n",
            "loss: 0.400115 [ 2000/60000]\n",
            "loss: 0.118486 [ 4000/60000]\n",
            "loss: 0.403904 [ 6000/60000]\n",
            "loss: 0.495114 [ 8000/60000]\n",
            "loss: 0.223220 [10000/60000]\n",
            "loss: 0.319619 [12000/60000]\n",
            "loss: 0.345302 [14000/60000]\n",
            "loss: 0.653394 [16000/60000]\n",
            "loss: 0.807555 [18000/60000]\n",
            "loss: 0.164125 [20000/60000]\n",
            "loss: 0.577147 [22000/60000]\n",
            "loss: 0.438315 [24000/60000]\n",
            "loss: 0.264922 [26000/60000]\n",
            "loss: 0.604210 [28000/60000]\n",
            "loss: 0.171456 [30000/60000]\n",
            "loss: 0.396240 [32000/60000]\n",
            "loss: 0.479969 [34000/60000]\n",
            "loss: 0.314233 [36000/60000]\n",
            "loss: 0.345683 [38000/60000]\n",
            "loss: 0.626229 [40000/60000]\n",
            "loss: 0.736775 [42000/60000]\n",
            "loss: 0.255498 [44000/60000]\n",
            "loss: 0.393721 [46000/60000]\n",
            "loss: 0.375045 [48000/60000]\n",
            "loss: 0.513976 [50000/60000]\n",
            "loss: 0.122184 [52000/60000]\n",
            "loss: 0.349652 [54000/60000]\n",
            "loss: 0.194922 [56000/60000]\n",
            "loss: 0.400520 [58000/60000]\n",
            "Avg Training Loss: 0.353578\n",
            "Test Error: \n",
            " Accuracy: 86.1%, Avg loss: 0.397250\n",
            "\n",
            "Epoch 56\n",
            "----------------------------------\n",
            "loss: 0.315002 [    0/60000]\n",
            "loss: 0.399598 [ 2000/60000]\n",
            "loss: 0.118150 [ 4000/60000]\n",
            "loss: 0.403990 [ 6000/60000]\n",
            "loss: 0.494279 [ 8000/60000]\n",
            "loss: 0.221685 [10000/60000]\n",
            "loss: 0.317232 [12000/60000]\n",
            "loss: 0.345350 [14000/60000]\n",
            "loss: 0.653354 [16000/60000]\n",
            "loss: 0.804101 [18000/60000]\n",
            "loss: 0.162425 [20000/60000]\n",
            "loss: 0.575672 [22000/60000]\n",
            "loss: 0.438434 [24000/60000]\n",
            "loss: 0.262497 [26000/60000]\n",
            "loss: 0.603168 [28000/60000]\n",
            "loss: 0.170152 [30000/60000]\n",
            "loss: 0.393220 [32000/60000]\n",
            "loss: 0.477847 [34000/60000]\n",
            "loss: 0.312139 [36000/60000]\n",
            "loss: 0.344524 [38000/60000]\n",
            "loss: 0.626379 [40000/60000]\n",
            "loss: 0.737937 [42000/60000]\n",
            "loss: 0.253910 [44000/60000]\n",
            "loss: 0.392020 [46000/60000]\n",
            "loss: 0.373295 [48000/60000]\n",
            "loss: 0.515530 [50000/60000]\n",
            "loss: 0.121266 [52000/60000]\n",
            "loss: 0.347917 [54000/60000]\n",
            "loss: 0.193437 [56000/60000]\n",
            "loss: 0.397723 [58000/60000]\n",
            "Avg Training Loss: 0.351938\n",
            "Test Error: \n",
            " Accuracy: 86.1%, Avg loss: 0.396045\n",
            "\n",
            "Epoch 57\n",
            "----------------------------------\n",
            "loss: 0.314701 [    0/60000]\n",
            "loss: 0.399106 [ 2000/60000]\n",
            "loss: 0.117869 [ 4000/60000]\n",
            "loss: 0.404547 [ 6000/60000]\n",
            "loss: 0.495182 [ 8000/60000]\n",
            "loss: 0.220143 [10000/60000]\n",
            "loss: 0.315090 [12000/60000]\n",
            "loss: 0.345975 [14000/60000]\n",
            "loss: 0.654220 [16000/60000]\n",
            "loss: 0.800052 [18000/60000]\n",
            "loss: 0.160657 [20000/60000]\n",
            "loss: 0.573464 [22000/60000]\n",
            "loss: 0.438238 [24000/60000]\n",
            "loss: 0.260355 [26000/60000]\n",
            "loss: 0.602421 [28000/60000]\n",
            "loss: 0.168406 [30000/60000]\n",
            "loss: 0.390384 [32000/60000]\n",
            "loss: 0.475650 [34000/60000]\n",
            "loss: 0.310179 [36000/60000]\n",
            "loss: 0.343375 [38000/60000]\n",
            "loss: 0.626309 [40000/60000]\n",
            "loss: 0.738656 [42000/60000]\n",
            "loss: 0.252576 [44000/60000]\n",
            "loss: 0.390208 [46000/60000]\n",
            "loss: 0.371444 [48000/60000]\n",
            "loss: 0.517116 [50000/60000]\n",
            "loss: 0.120390 [52000/60000]\n",
            "loss: 0.345601 [54000/60000]\n",
            "loss: 0.191817 [56000/60000]\n",
            "loss: 0.394663 [58000/60000]\n",
            "Avg Training Loss: 0.350322\n",
            "Test Error: \n",
            " Accuracy: 86.1%, Avg loss: 0.394856\n",
            "\n",
            "Epoch 58\n",
            "----------------------------------\n",
            "loss: 0.314130 [    0/60000]\n",
            "loss: 0.398772 [ 2000/60000]\n",
            "loss: 0.117549 [ 4000/60000]\n",
            "loss: 0.405113 [ 6000/60000]\n",
            "loss: 0.495996 [ 8000/60000]\n",
            "loss: 0.218682 [10000/60000]\n",
            "loss: 0.313167 [12000/60000]\n",
            "loss: 0.346502 [14000/60000]\n",
            "loss: 0.654716 [16000/60000]\n",
            "loss: 0.795998 [18000/60000]\n",
            "loss: 0.159024 [20000/60000]\n",
            "loss: 0.571658 [22000/60000]\n",
            "loss: 0.438468 [24000/60000]\n",
            "loss: 0.258432 [26000/60000]\n",
            "loss: 0.601283 [28000/60000]\n",
            "loss: 0.166935 [30000/60000]\n",
            "loss: 0.387833 [32000/60000]\n",
            "loss: 0.473605 [34000/60000]\n",
            "loss: 0.308146 [36000/60000]\n",
            "loss: 0.342178 [38000/60000]\n",
            "loss: 0.626430 [40000/60000]\n",
            "loss: 0.739366 [42000/60000]\n",
            "loss: 0.251116 [44000/60000]\n",
            "loss: 0.388247 [46000/60000]\n",
            "loss: 0.369847 [48000/60000]\n",
            "loss: 0.518441 [50000/60000]\n",
            "loss: 0.119318 [52000/60000]\n",
            "loss: 0.344060 [54000/60000]\n",
            "loss: 0.190481 [56000/60000]\n",
            "loss: 0.391729 [58000/60000]\n",
            "Avg Training Loss: 0.348731\n",
            "Test Error: \n",
            " Accuracy: 86.2%, Avg loss: 0.393679\n",
            "\n",
            "Epoch 59\n",
            "----------------------------------\n",
            "loss: 0.313912 [    0/60000]\n",
            "loss: 0.398464 [ 2000/60000]\n",
            "loss: 0.117241 [ 4000/60000]\n",
            "loss: 0.405475 [ 6000/60000]\n",
            "loss: 0.497459 [ 8000/60000]\n",
            "loss: 0.217210 [10000/60000]\n",
            "loss: 0.311037 [12000/60000]\n",
            "loss: 0.346750 [14000/60000]\n",
            "loss: 0.654893 [16000/60000]\n",
            "loss: 0.791942 [18000/60000]\n",
            "loss: 0.157552 [20000/60000]\n",
            "loss: 0.570401 [22000/60000]\n",
            "loss: 0.438164 [24000/60000]\n",
            "loss: 0.256847 [26000/60000]\n",
            "loss: 0.600449 [28000/60000]\n",
            "loss: 0.165628 [30000/60000]\n",
            "loss: 0.384518 [32000/60000]\n",
            "loss: 0.471498 [34000/60000]\n",
            "loss: 0.306404 [36000/60000]\n",
            "loss: 0.341488 [38000/60000]\n",
            "loss: 0.626057 [40000/60000]\n",
            "loss: 0.739825 [42000/60000]\n",
            "loss: 0.250150 [44000/60000]\n",
            "loss: 0.386664 [46000/60000]\n",
            "loss: 0.367952 [48000/60000]\n",
            "loss: 0.520015 [50000/60000]\n",
            "loss: 0.118367 [52000/60000]\n",
            "loss: 0.341713 [54000/60000]\n",
            "loss: 0.189042 [56000/60000]\n",
            "loss: 0.389368 [58000/60000]\n",
            "Avg Training Loss: 0.347153\n",
            "Test Error: \n",
            " Accuracy: 86.2%, Avg loss: 0.392489\n",
            "\n",
            "Epoch 60\n",
            "----------------------------------\n",
            "loss: 0.313208 [    0/60000]\n",
            "loss: 0.398070 [ 2000/60000]\n",
            "loss: 0.116876 [ 4000/60000]\n",
            "loss: 0.405612 [ 6000/60000]\n",
            "loss: 0.497433 [ 8000/60000]\n",
            "loss: 0.215529 [10000/60000]\n",
            "loss: 0.308948 [12000/60000]\n",
            "loss: 0.347246 [14000/60000]\n",
            "loss: 0.654686 [16000/60000]\n",
            "loss: 0.787480 [18000/60000]\n",
            "loss: 0.155914 [20000/60000]\n",
            "loss: 0.568865 [22000/60000]\n",
            "loss: 0.438239 [24000/60000]\n",
            "loss: 0.255047 [26000/60000]\n",
            "loss: 0.599170 [28000/60000]\n",
            "loss: 0.164519 [30000/60000]\n",
            "loss: 0.381485 [32000/60000]\n",
            "loss: 0.468873 [34000/60000]\n",
            "loss: 0.304823 [36000/60000]\n",
            "loss: 0.340551 [38000/60000]\n",
            "loss: 0.625651 [40000/60000]\n",
            "loss: 0.740118 [42000/60000]\n",
            "loss: 0.248868 [44000/60000]\n",
            "loss: 0.385449 [46000/60000]\n",
            "loss: 0.366392 [48000/60000]\n",
            "loss: 0.522127 [50000/60000]\n",
            "loss: 0.117232 [52000/60000]\n",
            "loss: 0.339266 [54000/60000]\n",
            "loss: 0.187540 [56000/60000]\n",
            "loss: 0.386936 [58000/60000]\n",
            "Avg Training Loss: 0.345595\n",
            "Test Error: \n",
            " Accuracy: 86.3%, Avg loss: 0.391347\n",
            "\n",
            "Epoch 61\n",
            "----------------------------------\n",
            "loss: 0.312327 [    0/60000]\n",
            "loss: 0.397472 [ 2000/60000]\n",
            "loss: 0.116672 [ 4000/60000]\n",
            "loss: 0.405473 [ 6000/60000]\n",
            "loss: 0.496547 [ 8000/60000]\n",
            "loss: 0.214052 [10000/60000]\n",
            "loss: 0.306850 [12000/60000]\n",
            "loss: 0.346853 [14000/60000]\n",
            "loss: 0.654952 [16000/60000]\n",
            "loss: 0.783358 [18000/60000]\n",
            "loss: 0.154509 [20000/60000]\n",
            "loss: 0.566717 [22000/60000]\n",
            "loss: 0.438094 [24000/60000]\n",
            "loss: 0.253471 [26000/60000]\n",
            "loss: 0.598390 [28000/60000]\n",
            "loss: 0.163373 [30000/60000]\n",
            "loss: 0.378573 [32000/60000]\n",
            "loss: 0.466485 [34000/60000]\n",
            "loss: 0.303403 [36000/60000]\n",
            "loss: 0.339538 [38000/60000]\n",
            "loss: 0.625671 [40000/60000]\n",
            "loss: 0.740972 [42000/60000]\n",
            "loss: 0.247898 [44000/60000]\n",
            "loss: 0.384215 [46000/60000]\n",
            "loss: 0.364831 [48000/60000]\n",
            "loss: 0.524013 [50000/60000]\n",
            "loss: 0.115976 [52000/60000]\n",
            "loss: 0.337120 [54000/60000]\n",
            "loss: 0.186180 [56000/60000]\n",
            "loss: 0.384771 [58000/60000]\n",
            "Avg Training Loss: 0.344053\n",
            "Test Error: \n",
            " Accuracy: 86.3%, Avg loss: 0.390195\n",
            "\n",
            "Epoch 62\n",
            "----------------------------------\n",
            "loss: 0.311615 [    0/60000]\n",
            "loss: 0.397166 [ 2000/60000]\n",
            "loss: 0.116429 [ 4000/60000]\n",
            "loss: 0.405399 [ 6000/60000]\n",
            "loss: 0.497005 [ 8000/60000]\n",
            "loss: 0.212673 [10000/60000]\n",
            "loss: 0.304456 [12000/60000]\n",
            "loss: 0.347569 [14000/60000]\n",
            "loss: 0.656117 [16000/60000]\n",
            "loss: 0.778789 [18000/60000]\n",
            "loss: 0.153256 [20000/60000]\n",
            "loss: 0.564368 [22000/60000]\n",
            "loss: 0.438102 [24000/60000]\n",
            "loss: 0.252330 [26000/60000]\n",
            "loss: 0.597237 [28000/60000]\n",
            "loss: 0.162989 [30000/60000]\n",
            "loss: 0.375465 [32000/60000]\n",
            "loss: 0.464392 [34000/60000]\n",
            "loss: 0.301631 [36000/60000]\n",
            "loss: 0.338999 [38000/60000]\n",
            "loss: 0.624938 [40000/60000]\n",
            "loss: 0.741843 [42000/60000]\n",
            "loss: 0.246792 [44000/60000]\n",
            "loss: 0.382707 [46000/60000]\n",
            "loss: 0.363343 [48000/60000]\n",
            "loss: 0.525582 [50000/60000]\n",
            "loss: 0.114897 [52000/60000]\n",
            "loss: 0.335412 [54000/60000]\n",
            "loss: 0.184890 [56000/60000]\n",
            "loss: 0.382485 [58000/60000]\n",
            "Avg Training Loss: 0.342532\n",
            "Test Error: \n",
            " Accuracy: 86.4%, Avg loss: 0.389102\n",
            "\n",
            "Epoch 63\n",
            "----------------------------------\n",
            "loss: 0.310924 [    0/60000]\n",
            "loss: 0.396799 [ 2000/60000]\n",
            "loss: 0.116314 [ 4000/60000]\n",
            "loss: 0.405626 [ 6000/60000]\n",
            "loss: 0.496617 [ 8000/60000]\n",
            "loss: 0.211315 [10000/60000]\n",
            "loss: 0.302175 [12000/60000]\n",
            "loss: 0.346899 [14000/60000]\n",
            "loss: 0.655971 [16000/60000]\n",
            "loss: 0.774012 [18000/60000]\n",
            "loss: 0.151925 [20000/60000]\n",
            "loss: 0.562469 [22000/60000]\n",
            "loss: 0.438450 [24000/60000]\n",
            "loss: 0.250613 [26000/60000]\n",
            "loss: 0.596003 [28000/60000]\n",
            "loss: 0.162123 [30000/60000]\n",
            "loss: 0.372896 [32000/60000]\n",
            "loss: 0.462708 [34000/60000]\n",
            "loss: 0.299908 [36000/60000]\n",
            "loss: 0.337868 [38000/60000]\n",
            "loss: 0.624488 [40000/60000]\n",
            "loss: 0.742798 [42000/60000]\n",
            "loss: 0.245562 [44000/60000]\n",
            "loss: 0.381225 [46000/60000]\n",
            "loss: 0.361628 [48000/60000]\n",
            "loss: 0.527025 [50000/60000]\n",
            "loss: 0.113992 [52000/60000]\n",
            "loss: 0.333618 [54000/60000]\n",
            "loss: 0.183449 [56000/60000]\n",
            "loss: 0.379949 [58000/60000]\n",
            "Avg Training Loss: 0.341030\n",
            "Test Error: \n",
            " Accuracy: 86.4%, Avg loss: 0.388034\n",
            "\n",
            "Epoch 64\n",
            "----------------------------------\n",
            "loss: 0.310251 [    0/60000]\n",
            "loss: 0.396540 [ 2000/60000]\n",
            "loss: 0.116227 [ 4000/60000]\n",
            "loss: 0.405093 [ 6000/60000]\n",
            "loss: 0.496827 [ 8000/60000]\n",
            "loss: 0.209885 [10000/60000]\n",
            "loss: 0.299728 [12000/60000]\n",
            "loss: 0.347361 [14000/60000]\n",
            "loss: 0.656863 [16000/60000]\n",
            "loss: 0.769719 [18000/60000]\n",
            "loss: 0.150833 [20000/60000]\n",
            "loss: 0.560888 [22000/60000]\n",
            "loss: 0.437856 [24000/60000]\n",
            "loss: 0.249305 [26000/60000]\n",
            "loss: 0.595118 [28000/60000]\n",
            "loss: 0.161760 [30000/60000]\n",
            "loss: 0.369727 [32000/60000]\n",
            "loss: 0.460683 [34000/60000]\n",
            "loss: 0.298123 [36000/60000]\n",
            "loss: 0.336836 [38000/60000]\n",
            "loss: 0.624426 [40000/60000]\n",
            "loss: 0.742863 [42000/60000]\n",
            "loss: 0.244508 [44000/60000]\n",
            "loss: 0.379584 [46000/60000]\n",
            "loss: 0.359908 [48000/60000]\n",
            "loss: 0.528310 [50000/60000]\n",
            "loss: 0.113038 [52000/60000]\n",
            "loss: 0.331422 [54000/60000]\n",
            "loss: 0.182181 [56000/60000]\n",
            "loss: 0.377650 [58000/60000]\n",
            "Avg Training Loss: 0.339536\n",
            "Test Error: \n",
            " Accuracy: 86.4%, Avg loss: 0.386942\n",
            "\n",
            "Epoch 65\n",
            "----------------------------------\n",
            "loss: 0.309780 [    0/60000]\n",
            "loss: 0.396042 [ 2000/60000]\n",
            "loss: 0.116200 [ 4000/60000]\n",
            "loss: 0.404357 [ 6000/60000]\n",
            "loss: 0.496549 [ 8000/60000]\n",
            "loss: 0.208330 [10000/60000]\n",
            "loss: 0.297271 [12000/60000]\n",
            "loss: 0.346871 [14000/60000]\n",
            "loss: 0.656277 [16000/60000]\n",
            "loss: 0.766392 [18000/60000]\n",
            "loss: 0.150275 [20000/60000]\n",
            "loss: 0.558545 [22000/60000]\n",
            "loss: 0.437852 [24000/60000]\n",
            "loss: 0.247415 [26000/60000]\n",
            "loss: 0.593877 [28000/60000]\n",
            "loss: 0.161702 [30000/60000]\n",
            "loss: 0.366938 [32000/60000]\n",
            "loss: 0.458292 [34000/60000]\n",
            "loss: 0.296268 [36000/60000]\n",
            "loss: 0.335794 [38000/60000]\n",
            "loss: 0.623935 [40000/60000]\n",
            "loss: 0.743601 [42000/60000]\n",
            "loss: 0.243668 [44000/60000]\n",
            "loss: 0.378970 [46000/60000]\n",
            "loss: 0.358169 [48000/60000]\n",
            "loss: 0.529708 [50000/60000]\n",
            "loss: 0.112117 [52000/60000]\n",
            "loss: 0.329758 [54000/60000]\n",
            "loss: 0.180978 [56000/60000]\n",
            "loss: 0.375181 [58000/60000]\n",
            "Avg Training Loss: 0.338046\n",
            "Test Error: \n",
            " Accuracy: 86.4%, Avg loss: 0.385871\n",
            "\n",
            "Epoch 66\n",
            "----------------------------------\n",
            "loss: 0.308847 [    0/60000]\n",
            "loss: 0.395490 [ 2000/60000]\n",
            "loss: 0.115949 [ 4000/60000]\n",
            "loss: 0.404419 [ 6000/60000]\n",
            "loss: 0.497475 [ 8000/60000]\n",
            "loss: 0.206948 [10000/60000]\n",
            "loss: 0.294044 [12000/60000]\n",
            "loss: 0.347087 [14000/60000]\n",
            "loss: 0.656319 [16000/60000]\n",
            "loss: 0.762402 [18000/60000]\n",
            "loss: 0.149457 [20000/60000]\n",
            "loss: 0.555512 [22000/60000]\n",
            "loss: 0.437211 [24000/60000]\n",
            "loss: 0.246556 [26000/60000]\n",
            "loss: 0.592203 [28000/60000]\n",
            "loss: 0.160903 [30000/60000]\n",
            "loss: 0.363463 [32000/60000]\n",
            "loss: 0.456093 [34000/60000]\n",
            "loss: 0.293945 [36000/60000]\n",
            "loss: 0.334498 [38000/60000]\n",
            "loss: 0.622181 [40000/60000]\n",
            "loss: 0.744369 [42000/60000]\n",
            "loss: 0.242901 [44000/60000]\n",
            "loss: 0.377260 [46000/60000]\n",
            "loss: 0.356765 [48000/60000]\n",
            "loss: 0.530302 [50000/60000]\n",
            "loss: 0.111086 [52000/60000]\n",
            "loss: 0.328192 [54000/60000]\n",
            "loss: 0.179889 [56000/60000]\n",
            "loss: 0.372647 [58000/60000]\n",
            "Avg Training Loss: 0.336525\n",
            "Test Error: \n",
            " Accuracy: 86.5%, Avg loss: 0.384844\n",
            "\n",
            "Epoch 67\n",
            "----------------------------------\n",
            "loss: 0.307561 [    0/60000]\n",
            "loss: 0.394013 [ 2000/60000]\n",
            "loss: 0.115719 [ 4000/60000]\n",
            "loss: 0.404389 [ 6000/60000]\n",
            "loss: 0.498381 [ 8000/60000]\n",
            "loss: 0.205323 [10000/60000]\n",
            "loss: 0.291592 [12000/60000]\n",
            "loss: 0.346764 [14000/60000]\n",
            "loss: 0.655540 [16000/60000]\n",
            "loss: 0.759723 [18000/60000]\n",
            "loss: 0.148455 [20000/60000]\n",
            "loss: 0.554336 [22000/60000]\n",
            "loss: 0.435149 [24000/60000]\n",
            "loss: 0.246062 [26000/60000]\n",
            "loss: 0.591258 [28000/60000]\n",
            "loss: 0.160550 [30000/60000]\n",
            "loss: 0.360273 [32000/60000]\n",
            "loss: 0.452935 [34000/60000]\n",
            "loss: 0.292145 [36000/60000]\n",
            "loss: 0.333487 [38000/60000]\n",
            "loss: 0.621357 [40000/60000]\n",
            "loss: 0.745524 [42000/60000]\n",
            "loss: 0.241546 [44000/60000]\n",
            "loss: 0.376032 [46000/60000]\n",
            "loss: 0.355102 [48000/60000]\n",
            "loss: 0.532060 [50000/60000]\n",
            "loss: 0.110336 [52000/60000]\n",
            "loss: 0.326042 [54000/60000]\n",
            "loss: 0.178593 [56000/60000]\n",
            "loss: 0.370618 [58000/60000]\n",
            "Avg Training Loss: 0.335037\n",
            "Test Error: \n",
            " Accuracy: 86.5%, Avg loss: 0.383827\n",
            "\n",
            "Epoch 68\n",
            "----------------------------------\n",
            "loss: 0.306599 [    0/60000]\n",
            "loss: 0.393480 [ 2000/60000]\n",
            "loss: 0.115499 [ 4000/60000]\n",
            "loss: 0.403625 [ 6000/60000]\n",
            "loss: 0.499526 [ 8000/60000]\n",
            "loss: 0.203627 [10000/60000]\n",
            "loss: 0.289004 [12000/60000]\n",
            "loss: 0.346551 [14000/60000]\n",
            "loss: 0.655315 [16000/60000]\n",
            "loss: 0.756285 [18000/60000]\n",
            "loss: 0.147460 [20000/60000]\n",
            "loss: 0.551961 [22000/60000]\n",
            "loss: 0.434010 [24000/60000]\n",
            "loss: 0.245149 [26000/60000]\n",
            "loss: 0.590462 [28000/60000]\n",
            "loss: 0.159908 [30000/60000]\n",
            "loss: 0.357466 [32000/60000]\n",
            "loss: 0.451356 [34000/60000]\n",
            "loss: 0.290403 [36000/60000]\n",
            "loss: 0.332871 [38000/60000]\n",
            "loss: 0.620679 [40000/60000]\n",
            "loss: 0.745753 [42000/60000]\n",
            "loss: 0.240017 [44000/60000]\n",
            "loss: 0.374924 [46000/60000]\n",
            "loss: 0.354115 [48000/60000]\n",
            "loss: 0.532639 [50000/60000]\n",
            "loss: 0.109439 [52000/60000]\n",
            "loss: 0.324064 [54000/60000]\n",
            "loss: 0.177640 [56000/60000]\n",
            "loss: 0.368342 [58000/60000]\n",
            "Avg Training Loss: 0.333579\n",
            "Test Error: \n",
            " Accuracy: 86.5%, Avg loss: 0.382823\n",
            "\n",
            "Epoch 69\n",
            "----------------------------------\n",
            "loss: 0.305325 [    0/60000]\n",
            "loss: 0.392885 [ 2000/60000]\n",
            "loss: 0.115071 [ 4000/60000]\n",
            "loss: 0.402550 [ 6000/60000]\n",
            "loss: 0.498846 [ 8000/60000]\n",
            "loss: 0.202147 [10000/60000]\n",
            "loss: 0.286868 [12000/60000]\n",
            "loss: 0.346632 [14000/60000]\n",
            "loss: 0.655396 [16000/60000]\n",
            "loss: 0.751625 [18000/60000]\n",
            "loss: 0.146314 [20000/60000]\n",
            "loss: 0.548952 [22000/60000]\n",
            "loss: 0.433558 [24000/60000]\n",
            "loss: 0.243575 [26000/60000]\n",
            "loss: 0.589276 [28000/60000]\n",
            "loss: 0.159585 [30000/60000]\n",
            "loss: 0.354734 [32000/60000]\n",
            "loss: 0.449273 [34000/60000]\n",
            "loss: 0.288381 [36000/60000]\n",
            "loss: 0.332752 [38000/60000]\n",
            "loss: 0.620091 [40000/60000]\n",
            "loss: 0.746452 [42000/60000]\n",
            "loss: 0.238469 [44000/60000]\n",
            "loss: 0.373028 [46000/60000]\n",
            "loss: 0.352221 [48000/60000]\n",
            "loss: 0.533766 [50000/60000]\n",
            "loss: 0.108765 [52000/60000]\n",
            "loss: 0.322234 [54000/60000]\n",
            "loss: 0.176379 [56000/60000]\n",
            "loss: 0.366519 [58000/60000]\n",
            "Avg Training Loss: 0.332149\n",
            "Test Error: \n",
            " Accuracy: 86.5%, Avg loss: 0.381894\n",
            "\n",
            "Epoch 70\n",
            "----------------------------------\n",
            "loss: 0.304478 [    0/60000]\n",
            "loss: 0.392285 [ 2000/60000]\n",
            "loss: 0.114844 [ 4000/60000]\n",
            "loss: 0.401952 [ 6000/60000]\n",
            "loss: 0.499339 [ 8000/60000]\n",
            "loss: 0.200683 [10000/60000]\n",
            "loss: 0.284835 [12000/60000]\n",
            "loss: 0.346134 [14000/60000]\n",
            "loss: 0.655326 [16000/60000]\n",
            "loss: 0.747167 [18000/60000]\n",
            "loss: 0.145312 [20000/60000]\n",
            "loss: 0.546043 [22000/60000]\n",
            "loss: 0.432453 [24000/60000]\n",
            "loss: 0.242242 [26000/60000]\n",
            "loss: 0.587775 [28000/60000]\n",
            "loss: 0.158858 [30000/60000]\n",
            "loss: 0.352106 [32000/60000]\n",
            "loss: 0.447192 [34000/60000]\n",
            "loss: 0.286282 [36000/60000]\n",
            "loss: 0.331529 [38000/60000]\n",
            "loss: 0.618881 [40000/60000]\n",
            "loss: 0.745706 [42000/60000]\n",
            "loss: 0.236949 [44000/60000]\n",
            "loss: 0.371672 [46000/60000]\n",
            "loss: 0.350854 [48000/60000]\n",
            "loss: 0.534444 [50000/60000]\n",
            "loss: 0.107767 [52000/60000]\n",
            "loss: 0.320682 [54000/60000]\n",
            "loss: 0.175494 [56000/60000]\n",
            "loss: 0.364268 [58000/60000]\n",
            "Avg Training Loss: 0.330730\n",
            "Test Error: \n",
            " Accuracy: 86.6%, Avg loss: 0.380923\n",
            "\n",
            "Epoch 71\n",
            "----------------------------------\n",
            "loss: 0.303773 [    0/60000]\n",
            "loss: 0.391811 [ 2000/60000]\n",
            "loss: 0.114629 [ 4000/60000]\n",
            "loss: 0.401143 [ 6000/60000]\n",
            "loss: 0.499158 [ 8000/60000]\n",
            "loss: 0.198967 [10000/60000]\n",
            "loss: 0.282796 [12000/60000]\n",
            "loss: 0.345083 [14000/60000]\n",
            "loss: 0.655155 [16000/60000]\n",
            "loss: 0.743045 [18000/60000]\n",
            "loss: 0.144093 [20000/60000]\n",
            "loss: 0.543662 [22000/60000]\n",
            "loss: 0.430477 [24000/60000]\n",
            "loss: 0.241206 [26000/60000]\n",
            "loss: 0.586630 [28000/60000]\n",
            "loss: 0.158430 [30000/60000]\n",
            "loss: 0.349058 [32000/60000]\n",
            "loss: 0.445414 [34000/60000]\n",
            "loss: 0.284718 [36000/60000]\n",
            "loss: 0.331566 [38000/60000]\n",
            "loss: 0.618882 [40000/60000]\n",
            "loss: 0.746203 [42000/60000]\n",
            "loss: 0.235698 [44000/60000]\n",
            "loss: 0.370354 [46000/60000]\n",
            "loss: 0.348838 [48000/60000]\n",
            "loss: 0.535319 [50000/60000]\n",
            "loss: 0.106840 [52000/60000]\n",
            "loss: 0.318681 [54000/60000]\n",
            "loss: 0.174638 [56000/60000]\n",
            "loss: 0.362698 [58000/60000]\n",
            "Avg Training Loss: 0.329319\n",
            "Test Error: \n",
            " Accuracy: 86.6%, Avg loss: 0.380020\n",
            "\n",
            "Epoch 72\n",
            "----------------------------------\n",
            "loss: 0.302735 [    0/60000]\n",
            "loss: 0.391362 [ 2000/60000]\n",
            "loss: 0.114304 [ 4000/60000]\n",
            "loss: 0.400322 [ 6000/60000]\n",
            "loss: 0.498607 [ 8000/60000]\n",
            "loss: 0.197366 [10000/60000]\n",
            "loss: 0.280684 [12000/60000]\n",
            "loss: 0.344890 [14000/60000]\n",
            "loss: 0.653584 [16000/60000]\n",
            "loss: 0.738410 [18000/60000]\n",
            "loss: 0.143019 [20000/60000]\n",
            "loss: 0.541879 [22000/60000]\n",
            "loss: 0.429922 [24000/60000]\n",
            "loss: 0.239536 [26000/60000]\n",
            "loss: 0.585409 [28000/60000]\n",
            "loss: 0.157556 [30000/60000]\n",
            "loss: 0.346046 [32000/60000]\n",
            "loss: 0.442494 [34000/60000]\n",
            "loss: 0.282848 [36000/60000]\n",
            "loss: 0.330780 [38000/60000]\n",
            "loss: 0.617871 [40000/60000]\n",
            "loss: 0.746721 [42000/60000]\n",
            "loss: 0.234380 [44000/60000]\n",
            "loss: 0.369598 [46000/60000]\n",
            "loss: 0.347363 [48000/60000]\n",
            "loss: 0.536506 [50000/60000]\n",
            "loss: 0.105997 [52000/60000]\n",
            "loss: 0.316781 [54000/60000]\n",
            "loss: 0.173950 [56000/60000]\n",
            "loss: 0.360434 [58000/60000]\n",
            "Avg Training Loss: 0.327927\n",
            "Test Error: \n",
            " Accuracy: 86.6%, Avg loss: 0.379083\n",
            "\n",
            "Epoch 73\n",
            "----------------------------------\n",
            "loss: 0.301536 [    0/60000]\n",
            "loss: 0.391012 [ 2000/60000]\n",
            "loss: 0.113999 [ 4000/60000]\n",
            "loss: 0.399220 [ 6000/60000]\n",
            "loss: 0.497670 [ 8000/60000]\n",
            "loss: 0.195704 [10000/60000]\n",
            "loss: 0.278434 [12000/60000]\n",
            "loss: 0.344512 [14000/60000]\n",
            "loss: 0.653146 [16000/60000]\n",
            "loss: 0.732993 [18000/60000]\n",
            "loss: 0.142070 [20000/60000]\n",
            "loss: 0.539580 [22000/60000]\n",
            "loss: 0.428556 [24000/60000]\n",
            "loss: 0.238049 [26000/60000]\n",
            "loss: 0.584187 [28000/60000]\n",
            "loss: 0.157009 [30000/60000]\n",
            "loss: 0.342687 [32000/60000]\n",
            "loss: 0.440205 [34000/60000]\n",
            "loss: 0.281283 [36000/60000]\n",
            "loss: 0.330235 [38000/60000]\n",
            "loss: 0.616878 [40000/60000]\n",
            "loss: 0.747482 [42000/60000]\n",
            "loss: 0.233045 [44000/60000]\n",
            "loss: 0.367686 [46000/60000]\n",
            "loss: 0.346329 [48000/60000]\n",
            "loss: 0.537197 [50000/60000]\n",
            "loss: 0.105153 [52000/60000]\n",
            "loss: 0.314730 [54000/60000]\n",
            "loss: 0.173113 [56000/60000]\n",
            "loss: 0.358581 [58000/60000]\n",
            "Avg Training Loss: 0.326537\n",
            "Test Error: \n",
            " Accuracy: 86.7%, Avg loss: 0.378213\n",
            "\n",
            "Epoch 74\n",
            "----------------------------------\n",
            "loss: 0.300134 [    0/60000]\n",
            "loss: 0.391005 [ 2000/60000]\n",
            "loss: 0.113711 [ 4000/60000]\n",
            "loss: 0.398202 [ 6000/60000]\n",
            "loss: 0.498427 [ 8000/60000]\n",
            "loss: 0.194339 [10000/60000]\n",
            "loss: 0.276334 [12000/60000]\n",
            "loss: 0.344168 [14000/60000]\n",
            "loss: 0.652387 [16000/60000]\n",
            "loss: 0.728185 [18000/60000]\n",
            "loss: 0.141294 [20000/60000]\n",
            "loss: 0.536490 [22000/60000]\n",
            "loss: 0.427666 [24000/60000]\n",
            "loss: 0.237144 [26000/60000]\n",
            "loss: 0.583233 [28000/60000]\n",
            "loss: 0.156290 [30000/60000]\n",
            "loss: 0.339515 [32000/60000]\n",
            "loss: 0.437350 [34000/60000]\n",
            "loss: 0.279198 [36000/60000]\n",
            "loss: 0.329757 [38000/60000]\n",
            "loss: 0.616368 [40000/60000]\n",
            "loss: 0.748109 [42000/60000]\n",
            "loss: 0.231996 [44000/60000]\n",
            "loss: 0.366801 [46000/60000]\n",
            "loss: 0.344764 [48000/60000]\n",
            "loss: 0.537630 [50000/60000]\n",
            "loss: 0.104198 [52000/60000]\n",
            "loss: 0.313127 [54000/60000]\n",
            "loss: 0.172298 [56000/60000]\n",
            "loss: 0.356666 [58000/60000]\n",
            "Avg Training Loss: 0.325149\n",
            "Test Error: \n",
            " Accuracy: 86.7%, Avg loss: 0.377261\n",
            "\n",
            "Epoch 75\n",
            "----------------------------------\n",
            "loss: 0.297956 [    0/60000]\n",
            "loss: 0.390579 [ 2000/60000]\n",
            "loss: 0.113458 [ 4000/60000]\n",
            "loss: 0.397884 [ 6000/60000]\n",
            "loss: 0.498729 [ 8000/60000]\n",
            "loss: 0.192722 [10000/60000]\n",
            "loss: 0.274292 [12000/60000]\n",
            "loss: 0.343443 [14000/60000]\n",
            "loss: 0.651182 [16000/60000]\n",
            "loss: 0.723903 [18000/60000]\n",
            "loss: 0.140236 [20000/60000]\n",
            "loss: 0.533943 [22000/60000]\n",
            "loss: 0.426761 [24000/60000]\n",
            "loss: 0.236378 [26000/60000]\n",
            "loss: 0.581644 [28000/60000]\n",
            "loss: 0.155404 [30000/60000]\n",
            "loss: 0.336707 [32000/60000]\n",
            "loss: 0.434815 [34000/60000]\n",
            "loss: 0.277150 [36000/60000]\n",
            "loss: 0.329938 [38000/60000]\n",
            "loss: 0.614598 [40000/60000]\n",
            "loss: 0.748588 [42000/60000]\n",
            "loss: 0.230862 [44000/60000]\n",
            "loss: 0.365197 [46000/60000]\n",
            "loss: 0.343659 [48000/60000]\n",
            "loss: 0.537789 [50000/60000]\n",
            "loss: 0.103620 [52000/60000]\n",
            "loss: 0.311171 [54000/60000]\n",
            "loss: 0.171360 [56000/60000]\n",
            "loss: 0.355398 [58000/60000]\n",
            "Avg Training Loss: 0.323779\n",
            "Test Error: \n",
            " Accuracy: 86.7%, Avg loss: 0.376401\n",
            "\n",
            "Epoch 76\n",
            "----------------------------------\n",
            "loss: 0.297047 [    0/60000]\n",
            "loss: 0.390314 [ 2000/60000]\n",
            "loss: 0.113144 [ 4000/60000]\n",
            "loss: 0.396724 [ 6000/60000]\n",
            "loss: 0.499179 [ 8000/60000]\n",
            "loss: 0.191405 [10000/60000]\n",
            "loss: 0.272761 [12000/60000]\n",
            "loss: 0.342647 [14000/60000]\n",
            "loss: 0.651495 [16000/60000]\n",
            "loss: 0.718851 [18000/60000]\n",
            "loss: 0.139534 [20000/60000]\n",
            "loss: 0.530718 [22000/60000]\n",
            "loss: 0.425811 [24000/60000]\n",
            "loss: 0.235757 [26000/60000]\n",
            "loss: 0.580341 [28000/60000]\n",
            "loss: 0.155125 [30000/60000]\n",
            "loss: 0.334047 [32000/60000]\n",
            "loss: 0.433172 [34000/60000]\n",
            "loss: 0.275336 [36000/60000]\n",
            "loss: 0.330097 [38000/60000]\n",
            "loss: 0.614262 [40000/60000]\n",
            "loss: 0.748434 [42000/60000]\n",
            "loss: 0.229436 [44000/60000]\n",
            "loss: 0.364593 [46000/60000]\n",
            "loss: 0.342108 [48000/60000]\n",
            "loss: 0.538168 [50000/60000]\n",
            "loss: 0.102402 [52000/60000]\n",
            "loss: 0.309189 [54000/60000]\n",
            "loss: 0.170755 [56000/60000]\n",
            "loss: 0.354121 [58000/60000]\n",
            "Avg Training Loss: 0.322416\n",
            "Test Error: \n",
            " Accuracy: 86.7%, Avg loss: 0.375435\n",
            "\n",
            "Epoch 77\n",
            "----------------------------------\n",
            "loss: 0.295474 [    0/60000]\n",
            "loss: 0.389907 [ 2000/60000]\n",
            "loss: 0.113068 [ 4000/60000]\n",
            "loss: 0.395509 [ 6000/60000]\n",
            "loss: 0.498960 [ 8000/60000]\n",
            "loss: 0.189818 [10000/60000]\n",
            "loss: 0.270883 [12000/60000]\n",
            "loss: 0.341414 [14000/60000]\n",
            "loss: 0.651628 [16000/60000]\n",
            "loss: 0.714452 [18000/60000]\n",
            "loss: 0.138849 [20000/60000]\n",
            "loss: 0.527682 [22000/60000]\n",
            "loss: 0.424953 [24000/60000]\n",
            "loss: 0.234949 [26000/60000]\n",
            "loss: 0.578555 [28000/60000]\n",
            "loss: 0.154730 [30000/60000]\n",
            "loss: 0.331051 [32000/60000]\n",
            "loss: 0.430866 [34000/60000]\n",
            "loss: 0.273529 [36000/60000]\n",
            "loss: 0.329459 [38000/60000]\n",
            "loss: 0.613219 [40000/60000]\n",
            "loss: 0.748609 [42000/60000]\n",
            "loss: 0.228075 [44000/60000]\n",
            "loss: 0.364185 [46000/60000]\n",
            "loss: 0.340620 [48000/60000]\n",
            "loss: 0.538439 [50000/60000]\n",
            "loss: 0.101635 [52000/60000]\n",
            "loss: 0.306931 [54000/60000]\n",
            "loss: 0.169973 [56000/60000]\n",
            "loss: 0.352868 [58000/60000]\n",
            "Avg Training Loss: 0.321066\n",
            "Test Error: \n",
            " Accuracy: 86.8%, Avg loss: 0.374592\n",
            "\n",
            "Epoch 78\n",
            "----------------------------------\n",
            "loss: 0.294549 [    0/60000]\n",
            "loss: 0.389291 [ 2000/60000]\n",
            "loss: 0.112695 [ 4000/60000]\n",
            "loss: 0.394202 [ 6000/60000]\n",
            "loss: 0.498756 [ 8000/60000]\n",
            "loss: 0.188369 [10000/60000]\n",
            "loss: 0.269232 [12000/60000]\n",
            "loss: 0.340276 [14000/60000]\n",
            "loss: 0.651579 [16000/60000]\n",
            "loss: 0.710836 [18000/60000]\n",
            "loss: 0.137877 [20000/60000]\n",
            "loss: 0.524411 [22000/60000]\n",
            "loss: 0.424100 [24000/60000]\n",
            "loss: 0.234220 [26000/60000]\n",
            "loss: 0.577322 [28000/60000]\n",
            "loss: 0.154396 [30000/60000]\n",
            "loss: 0.328353 [32000/60000]\n",
            "loss: 0.428941 [34000/60000]\n",
            "loss: 0.271730 [36000/60000]\n",
            "loss: 0.329154 [38000/60000]\n",
            "loss: 0.611517 [40000/60000]\n",
            "loss: 0.749334 [42000/60000]\n",
            "loss: 0.227008 [44000/60000]\n",
            "loss: 0.362713 [46000/60000]\n",
            "loss: 0.338731 [48000/60000]\n",
            "loss: 0.538490 [50000/60000]\n",
            "loss: 0.101131 [52000/60000]\n",
            "loss: 0.305415 [54000/60000]\n",
            "loss: 0.169203 [56000/60000]\n",
            "loss: 0.350907 [58000/60000]\n",
            "Avg Training Loss: 0.319723\n",
            "Test Error: \n",
            " Accuracy: 86.8%, Avg loss: 0.373765\n",
            "\n",
            "Epoch 79\n",
            "----------------------------------\n",
            "loss: 0.293434 [    0/60000]\n",
            "loss: 0.389078 [ 2000/60000]\n",
            "loss: 0.112663 [ 4000/60000]\n",
            "loss: 0.393492 [ 6000/60000]\n",
            "loss: 0.499784 [ 8000/60000]\n",
            "loss: 0.186997 [10000/60000]\n",
            "loss: 0.267780 [12000/60000]\n",
            "loss: 0.339821 [14000/60000]\n",
            "loss: 0.651908 [16000/60000]\n",
            "loss: 0.706099 [18000/60000]\n",
            "loss: 0.137353 [20000/60000]\n",
            "loss: 0.520480 [22000/60000]\n",
            "loss: 0.422883 [24000/60000]\n",
            "loss: 0.233671 [26000/60000]\n",
            "loss: 0.576462 [28000/60000]\n",
            "loss: 0.153915 [30000/60000]\n",
            "loss: 0.325855 [32000/60000]\n",
            "loss: 0.426976 [34000/60000]\n",
            "loss: 0.269769 [36000/60000]\n",
            "loss: 0.329517 [38000/60000]\n",
            "loss: 0.610047 [40000/60000]\n",
            "loss: 0.749503 [42000/60000]\n",
            "loss: 0.225801 [44000/60000]\n",
            "loss: 0.362473 [46000/60000]\n",
            "loss: 0.337898 [48000/60000]\n",
            "loss: 0.538384 [50000/60000]\n",
            "loss: 0.100861 [52000/60000]\n",
            "loss: 0.303849 [54000/60000]\n",
            "loss: 0.168248 [56000/60000]\n",
            "loss: 0.350645 [58000/60000]\n",
            "Avg Training Loss: 0.318396\n",
            "Test Error: \n",
            " Accuracy: 86.8%, Avg loss: 0.372952\n",
            "\n",
            "Epoch 80\n",
            "----------------------------------\n",
            "loss: 0.292613 [    0/60000]\n",
            "loss: 0.388537 [ 2000/60000]\n",
            "loss: 0.112514 [ 4000/60000]\n",
            "loss: 0.392349 [ 6000/60000]\n",
            "loss: 0.500243 [ 8000/60000]\n",
            "loss: 0.185457 [10000/60000]\n",
            "loss: 0.265958 [12000/60000]\n",
            "loss: 0.339566 [14000/60000]\n",
            "loss: 0.651464 [16000/60000]\n",
            "loss: 0.702430 [18000/60000]\n",
            "loss: 0.136726 [20000/60000]\n",
            "loss: 0.518214 [22000/60000]\n",
            "loss: 0.422697 [24000/60000]\n",
            "loss: 0.232511 [26000/60000]\n",
            "loss: 0.575134 [28000/60000]\n",
            "loss: 0.153318 [30000/60000]\n",
            "loss: 0.323372 [32000/60000]\n",
            "loss: 0.424662 [34000/60000]\n",
            "loss: 0.268130 [36000/60000]\n",
            "loss: 0.328634 [38000/60000]\n",
            "loss: 0.608892 [40000/60000]\n",
            "loss: 0.749299 [42000/60000]\n",
            "loss: 0.224829 [44000/60000]\n",
            "loss: 0.361833 [46000/60000]\n",
            "loss: 0.336402 [48000/60000]\n",
            "loss: 0.538441 [50000/60000]\n",
            "loss: 0.100187 [52000/60000]\n",
            "loss: 0.302116 [54000/60000]\n",
            "loss: 0.167754 [56000/60000]\n",
            "loss: 0.349095 [58000/60000]\n",
            "Avg Training Loss: 0.317081\n",
            "Test Error: \n",
            " Accuracy: 86.8%, Avg loss: 0.372095\n",
            "\n",
            "Epoch 81\n",
            "----------------------------------\n",
            "loss: 0.292063 [    0/60000]\n",
            "loss: 0.388270 [ 2000/60000]\n",
            "loss: 0.112397 [ 4000/60000]\n",
            "loss: 0.391837 [ 6000/60000]\n",
            "loss: 0.499548 [ 8000/60000]\n",
            "loss: 0.184064 [10000/60000]\n",
            "loss: 0.264165 [12000/60000]\n",
            "loss: 0.339979 [14000/60000]\n",
            "loss: 0.651453 [16000/60000]\n",
            "loss: 0.697217 [18000/60000]\n",
            "loss: 0.136218 [20000/60000]\n",
            "loss: 0.515451 [22000/60000]\n",
            "loss: 0.422019 [24000/60000]\n",
            "loss: 0.231619 [26000/60000]\n",
            "loss: 0.573881 [28000/60000]\n",
            "loss: 0.153054 [30000/60000]\n",
            "loss: 0.320287 [32000/60000]\n",
            "loss: 0.422247 [34000/60000]\n",
            "loss: 0.266211 [36000/60000]\n",
            "loss: 0.328867 [38000/60000]\n",
            "loss: 0.607190 [40000/60000]\n",
            "loss: 0.749520 [42000/60000]\n",
            "loss: 0.223896 [44000/60000]\n",
            "loss: 0.361544 [46000/60000]\n",
            "loss: 0.334759 [48000/60000]\n",
            "loss: 0.538622 [50000/60000]\n",
            "loss: 0.099818 [52000/60000]\n",
            "loss: 0.300131 [54000/60000]\n",
            "loss: 0.166936 [56000/60000]\n",
            "loss: 0.347884 [58000/60000]\n",
            "Avg Training Loss: 0.315776\n",
            "Test Error: \n",
            " Accuracy: 86.9%, Avg loss: 0.371283\n",
            "\n",
            "Epoch 82\n",
            "----------------------------------\n",
            "loss: 0.290994 [    0/60000]\n",
            "loss: 0.387566 [ 2000/60000]\n",
            "loss: 0.112215 [ 4000/60000]\n",
            "loss: 0.391317 [ 6000/60000]\n",
            "loss: 0.499098 [ 8000/60000]\n",
            "loss: 0.182760 [10000/60000]\n",
            "loss: 0.262176 [12000/60000]\n",
            "loss: 0.339214 [14000/60000]\n",
            "loss: 0.651025 [16000/60000]\n",
            "loss: 0.693076 [18000/60000]\n",
            "loss: 0.135694 [20000/60000]\n",
            "loss: 0.512513 [22000/60000]\n",
            "loss: 0.420156 [24000/60000]\n",
            "loss: 0.230834 [26000/60000]\n",
            "loss: 0.572409 [28000/60000]\n",
            "loss: 0.152987 [30000/60000]\n",
            "loss: 0.317744 [32000/60000]\n",
            "loss: 0.420158 [34000/60000]\n",
            "loss: 0.264738 [36000/60000]\n",
            "loss: 0.328868 [38000/60000]\n",
            "loss: 0.605101 [40000/60000]\n",
            "loss: 0.749581 [42000/60000]\n",
            "loss: 0.222761 [44000/60000]\n",
            "loss: 0.361541 [46000/60000]\n",
            "loss: 0.333703 [48000/60000]\n",
            "loss: 0.539234 [50000/60000]\n",
            "loss: 0.099094 [52000/60000]\n",
            "loss: 0.298835 [54000/60000]\n",
            "loss: 0.166180 [56000/60000]\n",
            "loss: 0.345594 [58000/60000]\n",
            "Avg Training Loss: 0.314472\n",
            "Test Error: \n",
            " Accuracy: 87.0%, Avg loss: 0.370380\n",
            "\n",
            "Epoch 83\n",
            "----------------------------------\n",
            "loss: 0.289598 [    0/60000]\n",
            "loss: 0.386943 [ 2000/60000]\n",
            "loss: 0.112232 [ 4000/60000]\n",
            "loss: 0.390976 [ 6000/60000]\n",
            "loss: 0.498995 [ 8000/60000]\n",
            "loss: 0.181195 [10000/60000]\n",
            "loss: 0.260479 [12000/60000]\n",
            "loss: 0.338127 [14000/60000]\n",
            "loss: 0.650267 [16000/60000]\n",
            "loss: 0.689405 [18000/60000]\n",
            "loss: 0.135026 [20000/60000]\n",
            "loss: 0.509867 [22000/60000]\n",
            "loss: 0.419038 [24000/60000]\n",
            "loss: 0.230589 [26000/60000]\n",
            "loss: 0.571134 [28000/60000]\n",
            "loss: 0.152440 [30000/60000]\n",
            "loss: 0.314959 [32000/60000]\n",
            "loss: 0.418408 [34000/60000]\n",
            "loss: 0.262973 [36000/60000]\n",
            "loss: 0.328615 [38000/60000]\n",
            "loss: 0.603155 [40000/60000]\n",
            "loss: 0.750249 [42000/60000]\n",
            "loss: 0.221904 [44000/60000]\n",
            "loss: 0.360732 [46000/60000]\n",
            "loss: 0.332430 [48000/60000]\n",
            "loss: 0.539507 [50000/60000]\n",
            "loss: 0.098430 [52000/60000]\n",
            "loss: 0.297399 [54000/60000]\n",
            "loss: 0.165284 [56000/60000]\n",
            "loss: 0.345016 [58000/60000]\n",
            "Avg Training Loss: 0.313175\n",
            "Test Error: \n",
            " Accuracy: 87.0%, Avg loss: 0.369569\n",
            "\n",
            "Epoch 84\n",
            "----------------------------------\n",
            "loss: 0.288394 [    0/60000]\n",
            "loss: 0.386694 [ 2000/60000]\n",
            "loss: 0.112125 [ 4000/60000]\n",
            "loss: 0.390573 [ 6000/60000]\n",
            "loss: 0.498258 [ 8000/60000]\n",
            "loss: 0.179854 [10000/60000]\n",
            "loss: 0.258897 [12000/60000]\n",
            "loss: 0.337797 [14000/60000]\n",
            "loss: 0.649862 [16000/60000]\n",
            "loss: 0.684878 [18000/60000]\n",
            "loss: 0.134429 [20000/60000]\n",
            "loss: 0.506827 [22000/60000]\n",
            "loss: 0.418423 [24000/60000]\n",
            "loss: 0.229950 [26000/60000]\n",
            "loss: 0.569773 [28000/60000]\n",
            "loss: 0.151721 [30000/60000]\n",
            "loss: 0.312539 [32000/60000]\n",
            "loss: 0.416545 [34000/60000]\n",
            "loss: 0.261276 [36000/60000]\n",
            "loss: 0.328358 [38000/60000]\n",
            "loss: 0.601852 [40000/60000]\n",
            "loss: 0.750836 [42000/60000]\n",
            "loss: 0.220688 [44000/60000]\n",
            "loss: 0.360431 [46000/60000]\n",
            "loss: 0.331517 [48000/60000]\n",
            "loss: 0.538788 [50000/60000]\n",
            "loss: 0.098104 [52000/60000]\n",
            "loss: 0.295955 [54000/60000]\n",
            "loss: 0.164254 [56000/60000]\n",
            "loss: 0.343527 [58000/60000]\n",
            "Avg Training Loss: 0.311885\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.368757\n",
            "\n",
            "Epoch 85\n",
            "----------------------------------\n",
            "loss: 0.287738 [    0/60000]\n",
            "loss: 0.385928 [ 2000/60000]\n",
            "loss: 0.111830 [ 4000/60000]\n",
            "loss: 0.389856 [ 6000/60000]\n",
            "loss: 0.498091 [ 8000/60000]\n",
            "loss: 0.178221 [10000/60000]\n",
            "loss: 0.257105 [12000/60000]\n",
            "loss: 0.337240 [14000/60000]\n",
            "loss: 0.649717 [16000/60000]\n",
            "loss: 0.680500 [18000/60000]\n",
            "loss: 0.133887 [20000/60000]\n",
            "loss: 0.504165 [22000/60000]\n",
            "loss: 0.417072 [24000/60000]\n",
            "loss: 0.229208 [26000/60000]\n",
            "loss: 0.568393 [28000/60000]\n",
            "loss: 0.151154 [30000/60000]\n",
            "loss: 0.309499 [32000/60000]\n",
            "loss: 0.413755 [34000/60000]\n",
            "loss: 0.259259 [36000/60000]\n",
            "loss: 0.328237 [38000/60000]\n",
            "loss: 0.600139 [40000/60000]\n",
            "loss: 0.751522 [42000/60000]\n",
            "loss: 0.219861 [44000/60000]\n",
            "loss: 0.359618 [46000/60000]\n",
            "loss: 0.330288 [48000/60000]\n",
            "loss: 0.538657 [50000/60000]\n",
            "loss: 0.097353 [52000/60000]\n",
            "loss: 0.295199 [54000/60000]\n",
            "loss: 0.163524 [56000/60000]\n",
            "loss: 0.342733 [58000/60000]\n",
            "Avg Training Loss: 0.310605\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.367925\n",
            "\n",
            "Epoch 86\n",
            "----------------------------------\n",
            "loss: 0.287293 [    0/60000]\n",
            "loss: 0.385448 [ 2000/60000]\n",
            "loss: 0.111761 [ 4000/60000]\n",
            "loss: 0.388816 [ 6000/60000]\n",
            "loss: 0.497567 [ 8000/60000]\n",
            "loss: 0.176960 [10000/60000]\n",
            "loss: 0.255465 [12000/60000]\n",
            "loss: 0.337052 [14000/60000]\n",
            "loss: 0.649102 [16000/60000]\n",
            "loss: 0.675799 [18000/60000]\n",
            "loss: 0.133402 [20000/60000]\n",
            "loss: 0.502216 [22000/60000]\n",
            "loss: 0.416012 [24000/60000]\n",
            "loss: 0.228529 [26000/60000]\n",
            "loss: 0.566935 [28000/60000]\n",
            "loss: 0.150769 [30000/60000]\n",
            "loss: 0.305920 [32000/60000]\n",
            "loss: 0.410996 [34000/60000]\n",
            "loss: 0.257014 [36000/60000]\n",
            "loss: 0.328002 [38000/60000]\n",
            "loss: 0.598474 [40000/60000]\n",
            "loss: 0.752167 [42000/60000]\n",
            "loss: 0.218602 [44000/60000]\n",
            "loss: 0.360297 [46000/60000]\n",
            "loss: 0.329729 [48000/60000]\n",
            "loss: 0.539104 [50000/60000]\n",
            "loss: 0.096782 [52000/60000]\n",
            "loss: 0.293390 [54000/60000]\n",
            "loss: 0.162681 [56000/60000]\n",
            "loss: 0.342377 [58000/60000]\n",
            "Avg Training Loss: 0.309331\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.367104\n",
            "\n",
            "Epoch 87\n",
            "----------------------------------\n",
            "loss: 0.286643 [    0/60000]\n",
            "loss: 0.384811 [ 2000/60000]\n",
            "loss: 0.111635 [ 4000/60000]\n",
            "loss: 0.387891 [ 6000/60000]\n",
            "loss: 0.497825 [ 8000/60000]\n",
            "loss: 0.175480 [10000/60000]\n",
            "loss: 0.253629 [12000/60000]\n",
            "loss: 0.336343 [14000/60000]\n",
            "loss: 0.649472 [16000/60000]\n",
            "loss: 0.671436 [18000/60000]\n",
            "loss: 0.133207 [20000/60000]\n",
            "loss: 0.498780 [22000/60000]\n",
            "loss: 0.415220 [24000/60000]\n",
            "loss: 0.228305 [26000/60000]\n",
            "loss: 0.565263 [28000/60000]\n",
            "loss: 0.150118 [30000/60000]\n",
            "loss: 0.302903 [32000/60000]\n",
            "loss: 0.408434 [34000/60000]\n",
            "loss: 0.255251 [36000/60000]\n",
            "loss: 0.327055 [38000/60000]\n",
            "loss: 0.596729 [40000/60000]\n",
            "loss: 0.752401 [42000/60000]\n",
            "loss: 0.217554 [44000/60000]\n",
            "loss: 0.359691 [46000/60000]\n",
            "loss: 0.328999 [48000/60000]\n",
            "loss: 0.539161 [50000/60000]\n",
            "loss: 0.096048 [52000/60000]\n",
            "loss: 0.292815 [54000/60000]\n",
            "loss: 0.161794 [56000/60000]\n",
            "loss: 0.341887 [58000/60000]\n",
            "Avg Training Loss: 0.308062\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.366304\n",
            "\n",
            "Epoch 88\n",
            "----------------------------------\n",
            "loss: 0.286337 [    0/60000]\n",
            "loss: 0.384286 [ 2000/60000]\n",
            "loss: 0.111501 [ 4000/60000]\n",
            "loss: 0.387760 [ 6000/60000]\n",
            "loss: 0.498229 [ 8000/60000]\n",
            "loss: 0.173909 [10000/60000]\n",
            "loss: 0.251723 [12000/60000]\n",
            "loss: 0.336786 [14000/60000]\n",
            "loss: 0.649647 [16000/60000]\n",
            "loss: 0.667938 [18000/60000]\n",
            "loss: 0.132750 [20000/60000]\n",
            "loss: 0.495457 [22000/60000]\n",
            "loss: 0.414690 [24000/60000]\n",
            "loss: 0.228052 [26000/60000]\n",
            "loss: 0.564024 [28000/60000]\n",
            "loss: 0.149550 [30000/60000]\n",
            "loss: 0.300185 [32000/60000]\n",
            "loss: 0.406147 [34000/60000]\n",
            "loss: 0.253153 [36000/60000]\n",
            "loss: 0.327073 [38000/60000]\n",
            "loss: 0.594699 [40000/60000]\n",
            "loss: 0.752216 [42000/60000]\n",
            "loss: 0.216266 [44000/60000]\n",
            "loss: 0.359461 [46000/60000]\n",
            "loss: 0.327493 [48000/60000]\n",
            "loss: 0.538874 [50000/60000]\n",
            "loss: 0.095910 [52000/60000]\n",
            "loss: 0.291195 [54000/60000]\n",
            "loss: 0.160899 [56000/60000]\n",
            "loss: 0.340778 [58000/60000]\n",
            "Avg Training Loss: 0.306809\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.365503\n",
            "\n",
            "Epoch 89\n",
            "----------------------------------\n",
            "loss: 0.285192 [    0/60000]\n",
            "loss: 0.383368 [ 2000/60000]\n",
            "loss: 0.111274 [ 4000/60000]\n",
            "loss: 0.386930 [ 6000/60000]\n",
            "loss: 0.497494 [ 8000/60000]\n",
            "loss: 0.172465 [10000/60000]\n",
            "loss: 0.250374 [12000/60000]\n",
            "loss: 0.335928 [14000/60000]\n",
            "loss: 0.650143 [16000/60000]\n",
            "loss: 0.664229 [18000/60000]\n",
            "loss: 0.132526 [20000/60000]\n",
            "loss: 0.492121 [22000/60000]\n",
            "loss: 0.414175 [24000/60000]\n",
            "loss: 0.227846 [26000/60000]\n",
            "loss: 0.562960 [28000/60000]\n",
            "loss: 0.148755 [30000/60000]\n",
            "loss: 0.297893 [32000/60000]\n",
            "loss: 0.404181 [34000/60000]\n",
            "loss: 0.251202 [36000/60000]\n",
            "loss: 0.327607 [38000/60000]\n",
            "loss: 0.593061 [40000/60000]\n",
            "loss: 0.753136 [42000/60000]\n",
            "loss: 0.215014 [44000/60000]\n",
            "loss: 0.358351 [46000/60000]\n",
            "loss: 0.326354 [48000/60000]\n",
            "loss: 0.537973 [50000/60000]\n",
            "loss: 0.095607 [52000/60000]\n",
            "loss: 0.289793 [54000/60000]\n",
            "loss: 0.160053 [56000/60000]\n",
            "loss: 0.340145 [58000/60000]\n",
            "Avg Training Loss: 0.305550\n",
            "Test Error: \n",
            " Accuracy: 87.2%, Avg loss: 0.364726\n",
            "\n",
            "Epoch 90\n",
            "----------------------------------\n",
            "loss: 0.284038 [    0/60000]\n",
            "loss: 0.382811 [ 2000/60000]\n",
            "loss: 0.111025 [ 4000/60000]\n",
            "loss: 0.385913 [ 6000/60000]\n",
            "loss: 0.496633 [ 8000/60000]\n",
            "loss: 0.171167 [10000/60000]\n",
            "loss: 0.248816 [12000/60000]\n",
            "loss: 0.335869 [14000/60000]\n",
            "loss: 0.650222 [16000/60000]\n",
            "loss: 0.660357 [18000/60000]\n",
            "loss: 0.132155 [20000/60000]\n",
            "loss: 0.488625 [22000/60000]\n",
            "loss: 0.412843 [24000/60000]\n",
            "loss: 0.227751 [26000/60000]\n",
            "loss: 0.562043 [28000/60000]\n",
            "loss: 0.148771 [30000/60000]\n",
            "loss: 0.296593 [32000/60000]\n",
            "loss: 0.402254 [34000/60000]\n",
            "loss: 0.249443 [36000/60000]\n",
            "loss: 0.327231 [38000/60000]\n",
            "loss: 0.591351 [40000/60000]\n",
            "loss: 0.753424 [42000/60000]\n",
            "loss: 0.213652 [44000/60000]\n",
            "loss: 0.358222 [46000/60000]\n",
            "loss: 0.325220 [48000/60000]\n",
            "loss: 0.536857 [50000/60000]\n",
            "loss: 0.095304 [52000/60000]\n",
            "loss: 0.288634 [54000/60000]\n",
            "loss: 0.159213 [56000/60000]\n",
            "loss: 0.339634 [58000/60000]\n",
            "Avg Training Loss: 0.304292\n",
            "Test Error: \n",
            " Accuracy: 87.2%, Avg loss: 0.363963\n",
            "\n",
            "Epoch 91\n",
            "----------------------------------\n",
            "loss: 0.282252 [    0/60000]\n",
            "loss: 0.382203 [ 2000/60000]\n",
            "loss: 0.110503 [ 4000/60000]\n",
            "loss: 0.385408 [ 6000/60000]\n",
            "loss: 0.495358 [ 8000/60000]\n",
            "loss: 0.169573 [10000/60000]\n",
            "loss: 0.247454 [12000/60000]\n",
            "loss: 0.335230 [14000/60000]\n",
            "loss: 0.650205 [16000/60000]\n",
            "loss: 0.656295 [18000/60000]\n",
            "loss: 0.131602 [20000/60000]\n",
            "loss: 0.485505 [22000/60000]\n",
            "loss: 0.411457 [24000/60000]\n",
            "loss: 0.225935 [26000/60000]\n",
            "loss: 0.560058 [28000/60000]\n",
            "loss: 0.147844 [30000/60000]\n",
            "loss: 0.294334 [32000/60000]\n",
            "loss: 0.399250 [34000/60000]\n",
            "loss: 0.247680 [36000/60000]\n",
            "loss: 0.327056 [38000/60000]\n",
            "loss: 0.590676 [40000/60000]\n",
            "loss: 0.753785 [42000/60000]\n",
            "loss: 0.212188 [44000/60000]\n",
            "loss: 0.356897 [46000/60000]\n",
            "loss: 0.324060 [48000/60000]\n",
            "loss: 0.535410 [50000/60000]\n",
            "loss: 0.095033 [52000/60000]\n",
            "loss: 0.286831 [54000/60000]\n",
            "loss: 0.158327 [56000/60000]\n",
            "loss: 0.338471 [58000/60000]\n",
            "Avg Training Loss: 0.303050\n",
            "Test Error: \n",
            " Accuracy: 87.2%, Avg loss: 0.363276\n",
            "\n",
            "Epoch 92\n",
            "----------------------------------\n",
            "loss: 0.281453 [    0/60000]\n",
            "loss: 0.381911 [ 2000/60000]\n",
            "loss: 0.110208 [ 4000/60000]\n",
            "loss: 0.385011 [ 6000/60000]\n",
            "loss: 0.493900 [ 8000/60000]\n",
            "loss: 0.168097 [10000/60000]\n",
            "loss: 0.245909 [12000/60000]\n",
            "loss: 0.334543 [14000/60000]\n",
            "loss: 0.649904 [16000/60000]\n",
            "loss: 0.653077 [18000/60000]\n",
            "loss: 0.131203 [20000/60000]\n",
            "loss: 0.482273 [22000/60000]\n",
            "loss: 0.410190 [24000/60000]\n",
            "loss: 0.225888 [26000/60000]\n",
            "loss: 0.559225 [28000/60000]\n",
            "loss: 0.147275 [30000/60000]\n",
            "loss: 0.292182 [32000/60000]\n",
            "loss: 0.396886 [34000/60000]\n",
            "loss: 0.245817 [36000/60000]\n",
            "loss: 0.326599 [38000/60000]\n",
            "loss: 0.588954 [40000/60000]\n",
            "loss: 0.753229 [42000/60000]\n",
            "loss: 0.210718 [44000/60000]\n",
            "loss: 0.356703 [46000/60000]\n",
            "loss: 0.323477 [48000/60000]\n",
            "loss: 0.534989 [50000/60000]\n",
            "loss: 0.094459 [52000/60000]\n",
            "loss: 0.285609 [54000/60000]\n",
            "loss: 0.157526 [56000/60000]\n",
            "loss: 0.338316 [58000/60000]\n",
            "Avg Training Loss: 0.301825\n",
            "Test Error: \n",
            " Accuracy: 87.2%, Avg loss: 0.362495\n",
            "\n",
            "Epoch 93\n",
            "----------------------------------\n",
            "loss: 0.280623 [    0/60000]\n",
            "loss: 0.381647 [ 2000/60000]\n",
            "loss: 0.110120 [ 4000/60000]\n",
            "loss: 0.383489 [ 6000/60000]\n",
            "loss: 0.494083 [ 8000/60000]\n",
            "loss: 0.166667 [10000/60000]\n",
            "loss: 0.244711 [12000/60000]\n",
            "loss: 0.333369 [14000/60000]\n",
            "loss: 0.650369 [16000/60000]\n",
            "loss: 0.649700 [18000/60000]\n",
            "loss: 0.130683 [20000/60000]\n",
            "loss: 0.479257 [22000/60000]\n",
            "loss: 0.408260 [24000/60000]\n",
            "loss: 0.225125 [26000/60000]\n",
            "loss: 0.557900 [28000/60000]\n",
            "loss: 0.146495 [30000/60000]\n",
            "loss: 0.290396 [32000/60000]\n",
            "loss: 0.394298 [34000/60000]\n",
            "loss: 0.243883 [36000/60000]\n",
            "loss: 0.326297 [38000/60000]\n",
            "loss: 0.587370 [40000/60000]\n",
            "loss: 0.753609 [42000/60000]\n",
            "loss: 0.209318 [44000/60000]\n",
            "loss: 0.356201 [46000/60000]\n",
            "loss: 0.322440 [48000/60000]\n",
            "loss: 0.534446 [50000/60000]\n",
            "loss: 0.094287 [52000/60000]\n",
            "loss: 0.283324 [54000/60000]\n",
            "loss: 0.156684 [56000/60000]\n",
            "loss: 0.337623 [58000/60000]\n",
            "Avg Training Loss: 0.300599\n",
            "Test Error: \n",
            " Accuracy: 87.3%, Avg loss: 0.361818\n",
            "\n",
            "Epoch 94\n",
            "----------------------------------\n",
            "loss: 0.279614 [    0/60000]\n",
            "loss: 0.381233 [ 2000/60000]\n",
            "loss: 0.109896 [ 4000/60000]\n",
            "loss: 0.382509 [ 6000/60000]\n",
            "loss: 0.494692 [ 8000/60000]\n",
            "loss: 0.165243 [10000/60000]\n",
            "loss: 0.243379 [12000/60000]\n",
            "loss: 0.332000 [14000/60000]\n",
            "loss: 0.650270 [16000/60000]\n",
            "loss: 0.645215 [18000/60000]\n",
            "loss: 0.130164 [20000/60000]\n",
            "loss: 0.477518 [22000/60000]\n",
            "loss: 0.405828 [24000/60000]\n",
            "loss: 0.224599 [26000/60000]\n",
            "loss: 0.557167 [28000/60000]\n",
            "loss: 0.146026 [30000/60000]\n",
            "loss: 0.288839 [32000/60000]\n",
            "loss: 0.392672 [34000/60000]\n",
            "loss: 0.242316 [36000/60000]\n",
            "loss: 0.326170 [38000/60000]\n",
            "loss: 0.585694 [40000/60000]\n",
            "loss: 0.753447 [42000/60000]\n",
            "loss: 0.207518 [44000/60000]\n",
            "loss: 0.356422 [46000/60000]\n",
            "loss: 0.321357 [48000/60000]\n",
            "loss: 0.533374 [50000/60000]\n",
            "loss: 0.093678 [52000/60000]\n",
            "loss: 0.281965 [54000/60000]\n",
            "loss: 0.155948 [56000/60000]\n",
            "loss: 0.336544 [58000/60000]\n",
            "Avg Training Loss: 0.299364\n",
            "Test Error: \n",
            " Accuracy: 87.2%, Avg loss: 0.361133\n",
            "\n",
            "Epoch 95\n",
            "----------------------------------\n",
            "loss: 0.277211 [    0/60000]\n",
            "loss: 0.381098 [ 2000/60000]\n",
            "loss: 0.109520 [ 4000/60000]\n",
            "loss: 0.380917 [ 6000/60000]\n",
            "loss: 0.491999 [ 8000/60000]\n",
            "loss: 0.163608 [10000/60000]\n",
            "loss: 0.242239 [12000/60000]\n",
            "loss: 0.330192 [14000/60000]\n",
            "loss: 0.649883 [16000/60000]\n",
            "loss: 0.642387 [18000/60000]\n",
            "loss: 0.129685 [20000/60000]\n",
            "loss: 0.473611 [22000/60000]\n",
            "loss: 0.403766 [24000/60000]\n",
            "loss: 0.223756 [26000/60000]\n",
            "loss: 0.555511 [28000/60000]\n",
            "loss: 0.145433 [30000/60000]\n",
            "loss: 0.286282 [32000/60000]\n",
            "loss: 0.389984 [34000/60000]\n",
            "loss: 0.240701 [36000/60000]\n",
            "loss: 0.326304 [38000/60000]\n",
            "loss: 0.583439 [40000/60000]\n",
            "loss: 0.754238 [42000/60000]\n",
            "loss: 0.206578 [44000/60000]\n",
            "loss: 0.355990 [46000/60000]\n",
            "loss: 0.320423 [48000/60000]\n",
            "loss: 0.532781 [50000/60000]\n",
            "loss: 0.093724 [52000/60000]\n",
            "loss: 0.280117 [54000/60000]\n",
            "loss: 0.155202 [56000/60000]\n",
            "loss: 0.336178 [58000/60000]\n",
            "Avg Training Loss: 0.298141\n",
            "Test Error: \n",
            " Accuracy: 87.2%, Avg loss: 0.360417\n",
            "\n",
            "Epoch 96\n",
            "----------------------------------\n",
            "loss: 0.277067 [    0/60000]\n",
            "loss: 0.380886 [ 2000/60000]\n",
            "loss: 0.109329 [ 4000/60000]\n",
            "loss: 0.380051 [ 6000/60000]\n",
            "loss: 0.490069 [ 8000/60000]\n",
            "loss: 0.162166 [10000/60000]\n",
            "loss: 0.241401 [12000/60000]\n",
            "loss: 0.329237 [14000/60000]\n",
            "loss: 0.650035 [16000/60000]\n",
            "loss: 0.638295 [18000/60000]\n",
            "loss: 0.129249 [20000/60000]\n",
            "loss: 0.470935 [22000/60000]\n",
            "loss: 0.402907 [24000/60000]\n",
            "loss: 0.222434 [26000/60000]\n",
            "loss: 0.554020 [28000/60000]\n",
            "loss: 0.144712 [30000/60000]\n",
            "loss: 0.283859 [32000/60000]\n",
            "loss: 0.387280 [34000/60000]\n",
            "loss: 0.239126 [36000/60000]\n",
            "loss: 0.325952 [38000/60000]\n",
            "loss: 0.581202 [40000/60000]\n",
            "loss: 0.755020 [42000/60000]\n",
            "loss: 0.205584 [44000/60000]\n",
            "loss: 0.355198 [46000/60000]\n",
            "loss: 0.319413 [48000/60000]\n",
            "loss: 0.531787 [50000/60000]\n",
            "loss: 0.093794 [52000/60000]\n",
            "loss: 0.278065 [54000/60000]\n",
            "loss: 0.154752 [56000/60000]\n",
            "loss: 0.335214 [58000/60000]\n",
            "Avg Training Loss: 0.296932\n",
            "Test Error: \n",
            " Accuracy: 87.3%, Avg loss: 0.359681\n",
            "\n",
            "Epoch 97\n",
            "----------------------------------\n",
            "loss: 0.274848 [    0/60000]\n",
            "loss: 0.380656 [ 2000/60000]\n",
            "loss: 0.109150 [ 4000/60000]\n",
            "loss: 0.378674 [ 6000/60000]\n",
            "loss: 0.489798 [ 8000/60000]\n",
            "loss: 0.160794 [10000/60000]\n",
            "loss: 0.239981 [12000/60000]\n",
            "loss: 0.328375 [14000/60000]\n",
            "loss: 0.650802 [16000/60000]\n",
            "loss: 0.635299 [18000/60000]\n",
            "loss: 0.129021 [20000/60000]\n",
            "loss: 0.466460 [22000/60000]\n",
            "loss: 0.401194 [24000/60000]\n",
            "loss: 0.222578 [26000/60000]\n",
            "loss: 0.553149 [28000/60000]\n",
            "loss: 0.144120 [30000/60000]\n",
            "loss: 0.281792 [32000/60000]\n",
            "loss: 0.385231 [34000/60000]\n",
            "loss: 0.237263 [36000/60000]\n",
            "loss: 0.325305 [38000/60000]\n",
            "loss: 0.578577 [40000/60000]\n",
            "loss: 0.755035 [42000/60000]\n",
            "loss: 0.204774 [44000/60000]\n",
            "loss: 0.354991 [46000/60000]\n",
            "loss: 0.317948 [48000/60000]\n",
            "loss: 0.531543 [50000/60000]\n",
            "loss: 0.093740 [52000/60000]\n",
            "loss: 0.276303 [54000/60000]\n",
            "loss: 0.154118 [56000/60000]\n",
            "loss: 0.334159 [58000/60000]\n",
            "Avg Training Loss: 0.295720\n",
            "Test Error: \n",
            " Accuracy: 87.3%, Avg loss: 0.358998\n",
            "\n",
            "Epoch 98\n",
            "----------------------------------\n",
            "loss: 0.273573 [    0/60000]\n",
            "loss: 0.380776 [ 2000/60000]\n",
            "loss: 0.108821 [ 4000/60000]\n",
            "loss: 0.377878 [ 6000/60000]\n",
            "loss: 0.488856 [ 8000/60000]\n",
            "loss: 0.159613 [10000/60000]\n",
            "loss: 0.238791 [12000/60000]\n",
            "loss: 0.328660 [14000/60000]\n",
            "loss: 0.650051 [16000/60000]\n",
            "loss: 0.631471 [18000/60000]\n",
            "loss: 0.128851 [20000/60000]\n",
            "loss: 0.463236 [22000/60000]\n",
            "loss: 0.400184 [24000/60000]\n",
            "loss: 0.222003 [26000/60000]\n",
            "loss: 0.552621 [28000/60000]\n",
            "loss: 0.143010 [30000/60000]\n",
            "loss: 0.280075 [32000/60000]\n",
            "loss: 0.383622 [34000/60000]\n",
            "loss: 0.236013 [36000/60000]\n",
            "loss: 0.325811 [38000/60000]\n",
            "loss: 0.577402 [40000/60000]\n",
            "loss: 0.755216 [42000/60000]\n",
            "loss: 0.203737 [44000/60000]\n",
            "loss: 0.354052 [46000/60000]\n",
            "loss: 0.316761 [48000/60000]\n",
            "loss: 0.530779 [50000/60000]\n",
            "loss: 0.093838 [52000/60000]\n",
            "loss: 0.274245 [54000/60000]\n",
            "loss: 0.153260 [56000/60000]\n",
            "loss: 0.333761 [58000/60000]\n",
            "Avg Training Loss: 0.294522\n",
            "Test Error: \n",
            " Accuracy: 87.3%, Avg loss: 0.358379\n",
            "\n",
            "Epoch 99\n",
            "----------------------------------\n",
            "loss: 0.273238 [    0/60000]\n",
            "loss: 0.380586 [ 2000/60000]\n",
            "loss: 0.108721 [ 4000/60000]\n",
            "loss: 0.377453 [ 6000/60000]\n",
            "loss: 0.487927 [ 8000/60000]\n",
            "loss: 0.158280 [10000/60000]\n",
            "loss: 0.237498 [12000/60000]\n",
            "loss: 0.327652 [14000/60000]\n",
            "loss: 0.649947 [16000/60000]\n",
            "loss: 0.628814 [18000/60000]\n",
            "loss: 0.128603 [20000/60000]\n",
            "loss: 0.459495 [22000/60000]\n",
            "loss: 0.398794 [24000/60000]\n",
            "loss: 0.221418 [26000/60000]\n",
            "loss: 0.551445 [28000/60000]\n",
            "loss: 0.141929 [30000/60000]\n",
            "loss: 0.278431 [32000/60000]\n",
            "loss: 0.381427 [34000/60000]\n",
            "loss: 0.233977 [36000/60000]\n",
            "loss: 0.325996 [38000/60000]\n",
            "loss: 0.574353 [40000/60000]\n",
            "loss: 0.755420 [42000/60000]\n",
            "loss: 0.202951 [44000/60000]\n",
            "loss: 0.353582 [46000/60000]\n",
            "loss: 0.315812 [48000/60000]\n",
            "loss: 0.530020 [50000/60000]\n",
            "loss: 0.093828 [52000/60000]\n",
            "loss: 0.272889 [54000/60000]\n",
            "loss: 0.152738 [56000/60000]\n",
            "loss: 0.333103 [58000/60000]\n",
            "Avg Training Loss: 0.293334\n",
            "Test Error: \n",
            " Accuracy: 87.4%, Avg loss: 0.357715\n",
            "\n",
            "Epoch 100\n",
            "----------------------------------\n",
            "loss: 0.272913 [    0/60000]\n",
            "loss: 0.380167 [ 2000/60000]\n",
            "loss: 0.108421 [ 4000/60000]\n",
            "loss: 0.377063 [ 6000/60000]\n",
            "loss: 0.488643 [ 8000/60000]\n",
            "loss: 0.156937 [10000/60000]\n",
            "loss: 0.235707 [12000/60000]\n",
            "loss: 0.327928 [14000/60000]\n",
            "loss: 0.649043 [16000/60000]\n",
            "loss: 0.624781 [18000/60000]\n",
            "loss: 0.128212 [20000/60000]\n",
            "loss: 0.455486 [22000/60000]\n",
            "loss: 0.396877 [24000/60000]\n",
            "loss: 0.221061 [26000/60000]\n",
            "loss: 0.550324 [28000/60000]\n",
            "loss: 0.141159 [30000/60000]\n",
            "loss: 0.276934 [32000/60000]\n",
            "loss: 0.379557 [34000/60000]\n",
            "loss: 0.232388 [36000/60000]\n",
            "loss: 0.325818 [38000/60000]\n",
            "loss: 0.572263 [40000/60000]\n",
            "loss: 0.755058 [42000/60000]\n",
            "loss: 0.201459 [44000/60000]\n",
            "loss: 0.353281 [46000/60000]\n",
            "loss: 0.315164 [48000/60000]\n",
            "loss: 0.529482 [50000/60000]\n",
            "loss: 0.094015 [52000/60000]\n",
            "loss: 0.271408 [54000/60000]\n",
            "loss: 0.152355 [56000/60000]\n",
            "loss: 0.332208 [58000/60000]\n",
            "Avg Training Loss: 0.292156\n",
            "Test Error: \n",
            " Accuracy: 87.3%, Avg loss: 0.357027\n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Save the moodel\n",
        "\n",
        "torch.save(model.state_dict(),\"model.pth\")\n",
        "print(\"Model Saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-b6-A9tgav5",
        "outputId": "0bb845fa-7784-4cbd-decd-7575214bf14d"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model\n",
        "\n",
        "model = NeuralNetworks()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEg-EBqOwXpt",
        "outputId": "c7aa4994-770d-4410-a2b6-8257b6ccd0b4"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-87-c4d7903090cb>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"model.pth\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction classes :\n",
        "\n",
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]"
      ],
      "metadata": {
        "id": "9yCwwNCBwlQK"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X50LT4m2xLWU",
        "outputId": "f715eb9a-1367-4001-b150-7d73063a99c4"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XCMfdEDB0Nfr",
        "outputId": "6073de1e-b3bd-418d-f3a7-6337f294becd"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dress'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBWIqYPXxOPj",
        "outputId": "e9aec771-b1bc-426f-a909-c20226ace223"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetworks(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear_relue_stack): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = test_data[0][0], test_data[0][1]\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Q5Cm6zc4xQBn",
        "outputId": "eec95128-f659-41cd-ce0a-a8d2648f9051"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  pred = model(x)\n",
        "  predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "  print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dT9YGiT5x3ot",
        "outputId": "f63860e9-ca97-4be2-8ba4-b87811b8db5f"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torchvision\n",
        "\n",
        "for images,labels in train_dataloader:\n",
        "  break\n",
        "\n",
        "images = images.numpy()\n",
        "\n",
        "#Plot the images\n",
        "fig , axes = plt.subplots(nrows=4,ncols=4,figsize=(10,10))\n",
        "for i , ax in enumerate(axes.flat):\n",
        "  ax.imshow(np.transpose(images[i],(1,2,0)))\n",
        "  ax.set_title(classes[labels[i]])\n",
        "  ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZtjNegbIzIRw",
        "outputId": "71ce8763-93ff-4398-8a94-da5a618a04ee"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ah2Sqw_Lz_rj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}